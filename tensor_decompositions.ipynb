{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1d4dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 109, 91, 550)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load a .npy file\n",
    "arr = np.load(r'C:\\Users\\h\\Desktop\\PET_Recons\\100307_rfMRI_REST1_LR_norm_550.npy')\n",
    "print(arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d19a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 109, 91)\n"
     ]
    }
   ],
   "source": [
    "# first_volume = arr\n",
    "# first_volume = arr[:, :, :, 0:32]\n",
    "first_volume = arr[:, :, :, 0]\n",
    "# first_volume = np.random.rand(3, 4, 5, 6, 7)\n",
    "\n",
    "print(first_volume.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "280663c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "first_volume = sigmoid(first_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b3c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def visualize_volume_cross_sections_comparison(original, reconstruction):\n",
    "    \"\"\"\n",
    "    Create an interactive plotly visualization comparing original and reconstructed 3D volumes.\n",
    "    \n",
    "    Parameters:\n",
    "    original (numpy.ndarray): 3D numpy array with shape (91, 109, 91)\n",
    "    reconstruction (numpy.ndarray): 3D numpy array with same shape as original\n",
    "    \n",
    "    Returns:\n",
    "    plotly.graph_objects.Figure: Interactive figure with comparison and error visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate inputs\n",
    "    if original.shape != reconstruction.shape:\n",
    "        raise ValueError(\"Original and reconstruction must have the same shape\")\n",
    "    \n",
    "    # Get volume dimensions\n",
    "    d0, d1, d2 = original.shape\n",
    "    \n",
    "    # Calculate error volume\n",
    "    error = original - reconstruction\n",
    "    \n",
    "    # Calculate color scale ranges\n",
    "    vol_min = min(original.min(), reconstruction.min())\n",
    "    vol_max = max(original.max(), reconstruction.max())\n",
    "    error_abs_max = max(abs(error.min()), abs(error.max()))\n",
    "    \n",
    "    # Create 3x3 subplots\n",
    "    subplot_titles = [\n",
    "        'Original YZ', 'Original XZ', 'Original XY',\n",
    "        'Reconstruction YZ', 'Reconstruction XZ', 'Reconstruction XY', \n",
    "        'Error YZ', 'Error XZ', 'Error XY'\n",
    "    ]\n",
    "    \n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=3,\n",
    "        subplot_titles=subplot_titles,\n",
    "        vertical_spacing=0.08,\n",
    "        horizontal_spacing=0.05\n",
    "    )\n",
    "    \n",
    "    # Initialize with middle slices\n",
    "    mid0, mid1, mid2 = d0//2, d1//2, d2//2\n",
    "    \n",
    "    # Add original volume heatmaps (top row)\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=original[mid0, :, :],\n",
    "            colorscale='Viridis',\n",
    "            zmin=vol_min, zmax=vol_max,\n",
    "            showscale=False,\n",
    "            name='Original YZ'\n",
    "        ), row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=original[:, mid1, :],\n",
    "            colorscale='Viridis',\n",
    "            zmin=vol_min, zmax=vol_max,\n",
    "            showscale=False,\n",
    "            name='Original XZ'\n",
    "        ), row=1, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=original[:, :, mid2],\n",
    "            colorscale='Viridis',\n",
    "            zmin=vol_min, zmax=vol_max,\n",
    "            showscale=True,\n",
    "            colorbar=dict(x=0.32, len=0.3, y=0.85),\n",
    "            name='Original XY'\n",
    "        ), row=1, col=3\n",
    "    )\n",
    "    \n",
    "    # Add reconstruction heatmaps (middle row)\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=reconstruction[mid0, :, :],\n",
    "            colorscale='Viridis',\n",
    "            zmin=vol_min, zmax=vol_max,\n",
    "            showscale=False,\n",
    "            name='Reconstruction YZ'\n",
    "        ), row=2, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=reconstruction[:, mid1, :],\n",
    "            colorscale='Viridis',\n",
    "            zmin=vol_min, zmax=vol_max,\n",
    "            showscale=False,\n",
    "            name='Reconstruction XZ'\n",
    "        ), row=2, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=reconstruction[:, :, mid2],\n",
    "            colorscale='Viridis',\n",
    "            zmin=vol_min, zmax=vol_max,\n",
    "            showscale=False,\n",
    "            name='Reconstruction XY'\n",
    "        ), row=2, col=3\n",
    "    )\n",
    "    \n",
    "    # Add error heatmaps (bottom row)\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=error[mid0, :, :],\n",
    "            colorscale='RdBu',\n",
    "            zmin=-error_abs_max, zmax=error_abs_max,\n",
    "            showscale=False,\n",
    "            name='Error YZ'\n",
    "        ), row=3, col=1\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=error[:, mid1, :],\n",
    "            colorscale='RdBu',\n",
    "            zmin=-error_abs_max, zmax=error_abs_max,\n",
    "            showscale=False,\n",
    "            name='Error XZ'\n",
    "        ), row=3, col=2\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            z=error[:, :, mid2],\n",
    "            colorscale='RdBu',\n",
    "            zmin=-error_abs_max, zmax=error_abs_max,\n",
    "            showscale=True,\n",
    "            colorbar=dict(x=1.02, len=0.3, y=0.15),\n",
    "            name='Error XY'\n",
    "        ), row=3, col=3\n",
    "    )\n",
    "    \n",
    "    # Create synchronized slider steps\n",
    "    steps = []\n",
    "    for axis in range(3):\n",
    "        axis_steps = []\n",
    "        axis_size = [d0, d1, d2][axis]\n",
    "        \n",
    "        for i in range(axis_size):\n",
    "            if axis == 0:  # YZ plane\n",
    "                z_data = [\n",
    "                    original[i, :, :], original[:, mid1, :], original[:, :, mid2],\n",
    "                    reconstruction[i, :, :], reconstruction[:, mid1, :], reconstruction[:, :, mid2],\n",
    "                    error[i, :, :], error[:, mid1, :], error[:, :, mid2]\n",
    "                ]\n",
    "            elif axis == 1:  # XZ plane\n",
    "                z_data = [\n",
    "                    original[mid0, :, :], original[:, i, :], original[:, :, mid2],\n",
    "                    reconstruction[mid0, :, :], reconstruction[:, i, :], reconstruction[:, :, mid2],\n",
    "                    error[mid0, :, :], error[:, i, :], error[:, :, mid2]\n",
    "                ]\n",
    "            else:  # XY plane\n",
    "                z_data = [\n",
    "                    original[mid0, :, :], original[:, mid1, :], original[:, :, i],\n",
    "                    reconstruction[mid0, :, :], reconstruction[:, mid1, :], reconstruction[:, :, i],\n",
    "                    error[mid0, :, :], error[:, mid1, :], error[:, :, i]\n",
    "                ]\n",
    "            \n",
    "            step = dict(\n",
    "                method=\"restyle\",\n",
    "                args=[{\"z\": z_data}],\n",
    "                label=str(i)\n",
    "            )\n",
    "            axis_steps.append(step)\n",
    "        \n",
    "        steps.append(axis_steps)\n",
    "    \n",
    "    # Create sliders\n",
    "    sliders = [\n",
    "        dict(\n",
    "            active=mid0,\n",
    "            currentvalue={\"prefix\": \"Axis 0 slice: \"},\n",
    "            pad={\"t\": 50},\n",
    "            steps=steps[0],\n",
    "            len=0.25,\n",
    "            x=0.02,\n",
    "            y=0.02\n",
    "        ),\n",
    "        dict(\n",
    "            active=mid1,\n",
    "            currentvalue={\"prefix\": \"Axis 1 slice: \"},\n",
    "            pad={\"t\": 50},\n",
    "            steps=steps[1],\n",
    "            len=0.25,\n",
    "            x=0.37,\n",
    "            y=0.02\n",
    "        ),\n",
    "        dict(\n",
    "            active=mid2,\n",
    "            currentvalue={\"prefix\": \"Axis 2 slice: \"},\n",
    "            pad={\"t\": 50},\n",
    "            steps=steps[2],\n",
    "            len=0.25,\n",
    "            x=0.72,\n",
    "            y=0.02\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=\"Original vs Reconstruction Comparison with Error Analysis\",\n",
    "        sliders=sliders,\n",
    "        height=900,\n",
    "        margin=dict(b=150, t=100),\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    # Remove axis labels for cleaner look\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3d9f8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tensorly as tl\n",
    "# from tensorly.decomposition import tensor_train\n",
    "# from tensorly.tt_tensor import tt_to_tensor\n",
    "# import torch\n",
    "\n",
    "# # Set PyTorch backend and GPU\n",
    "# tl.set_backend('pytorch')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# TT_RANKS_TO_TEST = [1, 2, 5, 32, 64, 512]\n",
    "\n",
    "# def calculate_compression_ratio(original_tensor, tt_cores):\n",
    "#    original_size = original_tensor.numel()\n",
    "#    compressed_size = sum(core.numel() for core in tt_cores)\n",
    "#    ratio = compressed_size / original_size\n",
    "#    return ratio\n",
    "\n",
    "# # Move tensor to GPU\n",
    "# image_tensor_gpu = torch.tensor(first_volume, dtype=torch.float32, device=device)\n",
    "\n",
    "# print(f\"Original image tensor shape: {image_tensor_gpu.shape}\")\n",
    "# print(f\"Total elements in original image: {image_tensor_gpu.numel()}\\n\")\n",
    "\n",
    "# reconstructed_images = []\n",
    "# compression_ratios = []\n",
    "# tensor_train_cores = []\n",
    "\n",
    "# for rank in TT_RANKS_TO_TEST:\n",
    "#    print(f\"--- Processing for Rank={rank} ---\")\n",
    "\n",
    "#    tt_cores = tensor_train(image_tensor_gpu, rank=rank)\n",
    "#    tensor_train_cores.append(tt_cores)\n",
    "\n",
    "#    reconstructed_tensor = tt_to_tensor(tt_cores)\n",
    "#    reconstructed_images.append(reconstructed_tensor)\n",
    "\n",
    "#    ratio = calculate_compression_ratio(image_tensor_gpu, tt_cores)\n",
    "#    compression_ratios.append(ratio)\n",
    "   \n",
    "#    print(f\"Compressed size (sum of elements in cores): {sum(c.numel() for c in tt_cores)}\")\n",
    "#    print(f\"Compression Ratio: {ratio:.4f} (Compressed is {ratio*100:.2f}% of Original size)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a00bf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image tensor shape: (91, 109, 91)\n",
      "Total elements in original image: 902629\n",
      "\n",
      "--- Processing for Rank=1 ---\n",
      "Compressed size (sum of elements in cores): 291\n",
      "Compression Ratio: 0.0003 (Compressed is 0.03% of Original size)\n",
      "\n",
      "--- Processing for Rank=2 ---\n",
      "Compressed size (sum of elements in cores): 800\n",
      "Compression Ratio: 0.0009 (Compressed is 0.09% of Original size)\n",
      "\n",
      "--- Processing for Rank=5 ---\n",
      "Compressed size (sum of elements in cores): 3635\n",
      "Compression Ratio: 0.0040 (Compressed is 0.40% of Original size)\n",
      "\n",
      "--- Processing for Rank=32 ---\n",
      "Compressed size (sum of elements in cores): 117440\n",
      "Compression Ratio: 0.1301 (Compressed is 13.01% of Original size)\n",
      "\n",
      "--- Processing for Rank=64 ---\n",
      "Compressed size (sum of elements in cores): 458112\n",
      "Compression Ratio: 0.5075 (Compressed is 50.75% of Original size)\n",
      "\n",
      "--- Processing for Rank=512 ---\n",
      "Compressed size (sum of elements in cores): 919191\n",
      "Compression Ratio: 1.0183 (Compressed is 101.83% of Original size)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tensor_train\n",
    "from tensorly.tt_tensor import tt_to_tensor\n",
    "\n",
    "# Lower rank = more compression, but lower quality.\n",
    "# Higher rank = less compression, but higher quality.\n",
    "TT_RANKS_TO_TEST = [1, 2, 5, 32, 64, 512]\n",
    "\n",
    "def calculate_compression_ratio(original_tensor, tt_cores):\n",
    "    \"\"\"Calculates the compression ratio.\"\"\"\n",
    "    original_size = original_tensor.size\n",
    "    compressed_size = sum(core.size for core in tt_cores)\n",
    "    ratio = compressed_size / original_size\n",
    "    return ratio\n",
    "\n",
    "image_tensor_float = first_volume\n",
    "\n",
    "print(f\"Original image tensor shape: {image_tensor_float.shape}\")\n",
    "print(f\"Total elements in original image: {image_tensor_float.size}\\n\")\n",
    "\n",
    "reconstructed_images = []\n",
    "compression_ratios = []\n",
    "tensor_train_cores = []\n",
    "\n",
    "for rank in TT_RANKS_TO_TEST:\n",
    "    print(f\"--- Processing for Rank={rank} ---\")\n",
    "\n",
    "    # Perform Tensor Train decomposition\n",
    "    tt_cores = tensor_train(image_tensor_float, rank=rank)\n",
    "    tensor_train_cores.append(tt_cores)\n",
    "\n",
    "    # Reconstruct the tensor from the compressed TT-cores\n",
    "    reconstructed_tensor = tt_to_tensor(tt_cores)\n",
    "    reconstructed_images.append(reconstructed_tensor)\n",
    "\n",
    "    # Calculate and store compression info\n",
    "    ratio = calculate_compression_ratio(image_tensor_float, tt_cores)\n",
    "    compression_ratios.append(ratio)\n",
    "    \n",
    "    print(f\"Compressed size (sum of elements in cores): {sum(c.size for c in tt_cores)}\")\n",
    "    print(f\"Compression Ratio: {ratio:.4f} (Compressed is {ratio*100:.2f}% of Original size)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652b3706",
   "metadata": {},
   "outputs": [],
   "source": [
    "th = 3\n",
    "visualize_volume_cross_sections_comparison(original=first_volume, reconstruction=reconstructed_images[th])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb36633b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 91, 32)\n",
      "(32, 109, 32)\n",
      "(32, 91, 1)\n"
     ]
    }
   ],
   "source": [
    "for core in tensor_train_cores[th]:\n",
    "    print(core.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54158100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target shape: [91, 109, 91]\n",
      "Tensor core shapes: [(1, 91, 32), (32, 109, 32), (32, 91, 1)]\n",
      "Compression ratio: 7.69\n",
      "Reconstructed tensor shape: torch.Size([91, 109, 91])\n",
      "✓ Tensor train created successfully!\n",
      "Total parameters: 117,440\n",
      "\n",
      "Second example - Target: [50, 100, 75, 25], Reconstructed: torch.Size([50, 100, 75, 25])\n",
      "Compression ratio: 203.80\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import List, Tuple\n",
    "\n",
    "class TensorTrain(nn.Module):\n",
    "    \"\"\"\n",
    "    Tensor Train decomposition module that creates learnable tensor cores\n",
    "    for efficient representation of high-dimensional tensors.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, shape: List[int], rank: int):\n",
    "        \"\"\"\n",
    "        Initialize tensor train with specified output shape and rank.\n",
    "        \n",
    "        Args:\n",
    "            shape: List of dimensions for the target tensor (e.g., [91, 109, 91])\n",
    "            rank: Rank of the tensor train (internal bond dimension)\n",
    "        \"\"\"\n",
    "        super(TensorTrain, self).__init__()\n",
    "        \n",
    "        self.shape = shape\n",
    "        self.rank = rank\n",
    "        self.n_dims = len(shape)\n",
    "        \n",
    "        if self.n_dims < 2:\n",
    "            raise ValueError(\"Tensor train requires at least 2 dimensions\")\n",
    "        \n",
    "        # Create tensor cores\n",
    "        self.cores = nn.ParameterList()\n",
    "        \n",
    "        for i, dim in enumerate(shape):\n",
    "            if i == 0:  # First core: (1, d_i, rank)\n",
    "                core_shape = (1, dim, rank)\n",
    "            elif i == self.n_dims - 1:  # Last core: (rank, d_i, 1)\n",
    "                core_shape = (rank, dim, 1)\n",
    "            else:  # Middle cores: (rank, d_i, rank)\n",
    "                core_shape = (rank, dim, rank)\n",
    "            \n",
    "            # Initialize with Xavier uniform for stable gradients\n",
    "            core = nn.Parameter(torch.empty(core_shape))\n",
    "            nn.init.xavier_uniform_(core)\n",
    "            self.cores.append(core)\n",
    "    \n",
    "    def forward(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reconstruct the full tensor from tensor train cores.\n",
    "        \n",
    "        Returns:\n",
    "            Reconstructed tensor of shape specified during initialization\n",
    "        \"\"\"\n",
    "        # Start with the first core, remove the first dimension (which is 1)\n",
    "        result = self.cores[0].squeeze(0)  # Shape: (d_0, rank)\n",
    "        \n",
    "        # Contract with middle cores\n",
    "        for i in range(1, self.n_dims - 1):\n",
    "            # result shape: (..., rank)\n",
    "            # core shape: (rank, d_i, rank)\n",
    "            result = torch.einsum('...r,rdr->...dr', result, self.cores[i])\n",
    "        \n",
    "        # Contract with the last core and remove the last dimension (which is 1)\n",
    "        # result shape: (..., rank)\n",
    "        # last core shape: (rank, d_n, 1)\n",
    "        result = torch.einsum('...r,rd->...d', result, self.cores[-1].squeeze(-1))\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_core_shapes(self) -> List[Tuple[int, ...]]:\n",
    "        \"\"\"Return the shapes of all tensor cores.\"\"\"\n",
    "        return [tuple(core.shape) for core in self.cores]\n",
    "    \n",
    "    def get_compression_ratio(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate compression ratio compared to storing the full tensor.\n",
    "        \n",
    "        Returns:\n",
    "            Ratio of full tensor size to tensor train parameter count\n",
    "        \"\"\"\n",
    "        full_size = torch.prod(torch.tensor(self.shape)).item()\n",
    "        tt_size = sum(torch.prod(torch.tensor(core.shape)).item() for core in self.cores)\n",
    "        return full_size / tt_size\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create tensor train for your specific case\n",
    "    tt = TensorTrain(shape=[91, 109, 91], rank=32)\n",
    "    \n",
    "    print(f\"Target shape: {tt.shape}\")\n",
    "    print(f\"Tensor core shapes: {tt.get_core_shapes()}\")\n",
    "    print(f\"Compression ratio: {tt.get_compression_ratio():.2f}\")\n",
    "    \n",
    "    # Reconstruct tensor\n",
    "    reconstructed = tt()\n",
    "    print(f\"Reconstructed tensor shape: {reconstructed.shape}\")\n",
    "    \n",
    "    # Verify it matches expected shape\n",
    "    assert reconstructed.shape == tuple(tt.shape), f\"Shape mismatch: {reconstructed.shape} vs {tuple(tt.shape)}\"\n",
    "    \n",
    "    print(\"✓ Tensor train created successfully!\")\n",
    "    \n",
    "    # Show parameter count\n",
    "    total_params = sum(p.numel() for p in tt.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    \n",
    "    # Example with different shape and rank\n",
    "    tt2 = TensorTrain(shape=[50, 100, 75, 25], rank=16)\n",
    "    reconstructed2 = tt2()\n",
    "    print(f\"\\nSecond example - Target: {tt2.shape}, Reconstructed: {reconstructed2.shape}\")\n",
    "    print(f\"Compression ratio: {tt2.get_compression_ratio():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6604271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Tensor train rank (16) exceeds minimum kernel dimension (3). Using rank=3 instead.\n",
      "Input shape: torch.Size([4, 64, 32, 32])\n",
      "Output shape: torch.Size([4, 128, 32, 32])\n",
      "Kernel compression ratio: 74.02\n",
      "Total compression ratio: 65.71\n",
      "TT Conv parameters: 1124\n",
      "Standard Conv parameters: 73856\n",
      "\n",
      "Compression ratios for different configurations:\n",
      "Warning: Tensor train rank (4) exceeds minimum kernel dimension (1). Using rank=1 instead.\n",
      "Kernel=1x1, Rank=4: 42.23x compression\n",
      "Warning: Tensor train rank (8) exceeds minimum kernel dimension (1). Using rank=1 instead.\n",
      "Kernel=1x1, Rank=8: 42.23x compression\n",
      "Warning: Tensor train rank (16) exceeds minimum kernel dimension (1). Using rank=1 instead.\n",
      "Kernel=1x1, Rank=16: 42.23x compression\n",
      "Warning: Tensor train rank (32) exceeds minimum kernel dimension (1). Using rank=1 instead.\n",
      "Kernel=1x1, Rank=32: 42.23x compression\n",
      "Warning: Tensor train rank (4) exceeds minimum kernel dimension (3). Using rank=3 instead.\n",
      "Kernel=3x3, Rank=4: 74.02x compression\n",
      "Warning: Tensor train rank (8) exceeds minimum kernel dimension (3). Using rank=3 instead.\n",
      "Kernel=3x3, Rank=8: 74.02x compression\n",
      "Warning: Tensor train rank (16) exceeds minimum kernel dimension (3). Using rank=3 instead.\n",
      "Kernel=3x3, Rank=16: 74.02x compression\n",
      "Warning: Tensor train rank (32) exceeds minimum kernel dimension (3). Using rank=3 instead.\n",
      "Kernel=3x3, Rank=32: 74.02x compression\n",
      "Kernel=5x5, Rank=4: 125.18x compression\n",
      "Warning: Tensor train rank (8) exceeds minimum kernel dimension (5). Using rank=5 instead.\n",
      "Kernel=5x5, Rank=8: 85.69x compression\n",
      "Warning: Tensor train rank (16) exceeds minimum kernel dimension (5). Using rank=5 instead.\n",
      "Kernel=5x5, Rank=16: 85.69x compression\n",
      "Warning: Tensor train rank (32) exceeds minimum kernel dimension (5). Using rank=5 instead.\n",
      "Kernel=5x5, Rank=32: 85.69x compression\n",
      "Kernel=7x7, Rank=4: 239.50x compression\n",
      "Warning: Tensor train rank (8) exceeds minimum kernel dimension (7). Using rank=7 instead.\n",
      "Kernel=7x7, Rank=8: 90.73x compression\n",
      "Warning: Tensor train rank (16) exceeds minimum kernel dimension (7). Using rank=7 instead.\n",
      "Kernel=7x7, Rank=16: 90.73x compression\n",
      "Warning: Tensor train rank (32) exceeds minimum kernel dimension (7). Using rank=7 instead.\n",
      "Kernel=7x7, Rank=32: 90.73x compression\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Tuple\n",
    "\n",
    "class TensorTrainConv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    2D Convolution with Tensor Train decomposed kernel for parameter efficiency.\n",
    "    \n",
    "    Uses tensor train decomposition to represent the 4D convolution kernel\n",
    "    [out_channels, in_channels, kernel_height, kernel_width] with fewer parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[int, Tuple[int, int]],\n",
    "        rank: int,\n",
    "        stride: Union[int, Tuple[int, int]] = 1,\n",
    "        padding: Union[int, Tuple[int, int], str] = 0,\n",
    "        dilation: Union[int, Tuple[int, int]] = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        padding_mode: str = 'zeros'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize TensorTrain Conv2D layer.\n",
    "        \n",
    "        Args:\n",
    "            in_channels: Number of input channels\n",
    "            out_channels: Number of output channels  \n",
    "            kernel_size: Size of convolution kernel\n",
    "            rank: Tensor train rank (controls parameter efficiency)\n",
    "            stride: Stride of convolution\n",
    "            padding: Padding applied to input\n",
    "            dilation: Spacing between kernel elements\n",
    "            groups: Number of blocked connections from input to output channels\n",
    "            bias: If True, adds a learnable bias\n",
    "            padding_mode: Padding mode ('zeros', 'reflect', 'replicate', 'circular')\n",
    "        \"\"\"\n",
    "        super(TensorTrainConv2d, self).__init__()\n",
    "        \n",
    "        # Handle kernel_size as int or tuple\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        \n",
    "        # Validate groups\n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError(f\"in_channels ({in_channels}) must be divisible by groups ({groups})\")\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError(f\"out_channels ({out_channels}) must be divisible by groups ({groups})\")\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        \n",
    "        # Store original requested rank for reference\n",
    "        self.requested_rank = rank\n",
    "        self.rank = rank\n",
    "        \n",
    "        # Tensor train kernel shape: [out_channels, in_channels//groups, kernel_h, kernel_w]\n",
    "        kernel_shape = [out_channels, in_channels // groups, kernel_size[0], kernel_size[1]]\n",
    "        \n",
    "        # Validate and adjust rank if necessary\n",
    "        min_dim = min(kernel_shape)\n",
    "        if rank > min_dim:\n",
    "            original_rank = rank\n",
    "            rank = min_dim\n",
    "            print(f\"Warning: Tensor train rank ({original_rank}) exceeds minimum kernel dimension ({min_dim}). \"\n",
    "                  f\"Using rank={rank} instead.\")\n",
    "        \n",
    "        self.rank = rank  # Update stored rank to actual value used\n",
    "        \n",
    "        # Create tensor train for the kernel\n",
    "        self.kernel_tt = TensorTrain(kernel_shape, rank)\n",
    "        \n",
    "        # Optional bias parameter\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        \n",
    "        # Cache for reconstructed kernel (optional optimization)\n",
    "        self._cached_kernel = None\n",
    "        self._cache_valid = False\n",
    "    \n",
    "    def get_kernel(self) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Reconstruct the convolution kernel from tensor train cores.\n",
    "        \n",
    "        Returns:\n",
    "            4D kernel tensor of shape [out_channels, in_channels//groups, kernel_h, kernel_w]\n",
    "        \"\"\"\n",
    "        # Use caching to avoid redundant reconstruction\n",
    "        if not self._cache_valid:\n",
    "            self._cached_kernel = self.kernel_tt()\n",
    "            self._cache_valid = True\n",
    "        return self._cached_kernel\n",
    "    \n",
    "    def _invalidate_cache(self):\n",
    "        \"\"\"Invalidate kernel cache when parameters change.\"\"\"\n",
    "        self._cache_valid = False\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through tensor train convolution.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape [batch, in_channels, height, width]\n",
    "            \n",
    "        Returns:\n",
    "            Output tensor after convolution\n",
    "        \"\"\"\n",
    "        # Reconstruct kernel from tensor train\n",
    "        kernel = self.get_kernel()\n",
    "        \n",
    "        # Perform convolution\n",
    "        return F.conv2d(\n",
    "            x, \n",
    "            kernel, \n",
    "            self.bias,\n",
    "            self.stride,\n",
    "            self.padding,\n",
    "            self.dilation,\n",
    "            self.groups\n",
    "        )\n",
    "    \n",
    "    def get_compression_ratio(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate compression ratio compared to standard Conv2d.\n",
    "        \n",
    "        Returns:\n",
    "            Ratio of standard conv parameters to tensor train parameters\n",
    "        \"\"\"\n",
    "        # Standard conv2d kernel size\n",
    "        standard_kernel_params = self.out_channels * (self.in_channels // self.groups) * \\\n",
    "                               self.kernel_size[0] * self.kernel_size[1]\n",
    "        \n",
    "        # Tensor train parameters (from kernel only, excluding bias)\n",
    "        tt_kernel_params = sum(torch.prod(torch.tensor(core.shape)).item() \n",
    "                              for core in self.kernel_tt.cores)\n",
    "        \n",
    "        return standard_kernel_params / tt_kernel_params\n",
    "    \n",
    "    def get_total_compression_ratio(self) -> float:\n",
    "        \"\"\"\n",
    "        Calculate total compression ratio including bias terms.\n",
    "        \n",
    "        Returns:\n",
    "            Ratio of total standard conv parameters to tensor train parameters\n",
    "        \"\"\"\n",
    "        # Standard conv2d total parameters\n",
    "        standard_total = self.out_channels * (self.in_channels // self.groups) * \\\n",
    "                        self.kernel_size[0] * self.kernel_size[1]\n",
    "        if self.bias is not None:\n",
    "            standard_total += self.out_channels\n",
    "        \n",
    "        # Tensor train total parameters\n",
    "        tt_total = sum(torch.prod(torch.tensor(core.shape)).item() \n",
    "                      for core in self.kernel_tt.cores)\n",
    "        if self.bias is not None:\n",
    "            tt_total += self.out_channels\n",
    "            \n",
    "        return standard_total / tt_total\n",
    "    \n",
    "    def extra_repr(self) -> str:\n",
    "        \"\"\"String representation with key parameters.\"\"\"\n",
    "        return (f'in_channels={self.in_channels}, out_channels={self.out_channels}, '\n",
    "                f'kernel_size={self.kernel_size}, rank={self.rank}, stride={self.stride}, '\n",
    "                f'padding={self.padding}, dilation={self.dilation}, groups={self.groups}, '\n",
    "                f'bias={self.bias is not None}, compression_ratio={self.get_compression_ratio():.2f}')\n",
    "\n",
    "\n",
    "# Example usage and testing\n",
    "if __name__ == \"__main__\":\n",
    "    # Create tensor train conv2d layer\n",
    "    tt_conv = TensorTrainConv2d(\n",
    "        in_channels=64,\n",
    "        out_channels=128, \n",
    "        kernel_size=3,\n",
    "        rank=16,  # Will be automatically reduced to 3 for 3x3 kernel\n",
    "        padding=1\n",
    "    )\n",
    "    \n",
    "    # Test forward pass\n",
    "    x = torch.randn(4, 64, 32, 32)  # [batch, channels, height, width]\n",
    "    output = tt_conv(x)\n",
    "    \n",
    "    print(f\"Input shape: {x.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Kernel compression ratio: {tt_conv.get_compression_ratio():.2f}\")\n",
    "    print(f\"Total compression ratio: {tt_conv.get_total_compression_ratio():.2f}\")\n",
    "    print(f\"TT Conv parameters: {sum(p.numel() for p in tt_conv.parameters())}\")\n",
    "    \n",
    "    # Compare with standard conv2d\n",
    "    standard_conv = nn.Conv2d(64, 128, 3, padding=1)\n",
    "    print(f\"Standard Conv parameters: {sum(p.numel() for p in standard_conv.parameters())}\")\n",
    "    \n",
    "    # Test different kernel sizes and ranks\n",
    "    print(\"\\nCompression ratios for different configurations:\")\n",
    "    for kernel_size in [1, 3, 5, 7]:\n",
    "        for rank in [4, 8, 16, 32]:\n",
    "            try:\n",
    "                conv = TensorTrainConv2d(64, 128, kernel_size, rank)\n",
    "                print(f\"Kernel={kernel_size}x{kernel_size}, Rank={rank}: {conv.get_compression_ratio():.2f}x compression\")\n",
    "            except ValueError as e:\n",
    "                print(f\"Kernel={kernel_size}x{kernel_size}, Rank={rank}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytomography_env_cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
