{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2618e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# A TOF coords adaptation of the listmode PET scan reconstruction from: https://pytomography.readthedocs.io/en/latest/notebooks/t_PETGATE_scat_lm.html\n",
    "\n",
    "from __future__ import annotations\n",
    "import torch\n",
    "import pytomography\n",
    "from pytomography.metadata import ObjectMeta\n",
    "from pytomography.metadata.PET import PETLMProjMeta\n",
    "from pytomography.projectors.PET import PETLMSystemMatrix\n",
    "from pytomography.algorithms import OSEM, MLEM\n",
    "from pytomography.io.PET import gate, shared\n",
    "from pytomography.likelihoods import PoissonLogLikelihood\n",
    "import os\n",
    "from pytomography.transforms.shared import GaussianFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from pytomography.utils import sss\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "# torch.cuda.is_available = lambda: False\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "# pytomography.device = 'cpu'\n",
    "print(f\"Current device: {pytomography.device}\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef607c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualisation Functions\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "\n",
    "def visualize_voxel_tensor_3d(voxel_tensor, initial_min_threshold=None, initial_max_threshold=None, \n",
    "                               voxel_size_mm=1.0, world_origin=None, min_threshold=None, max_threshold=None):\n",
    "    \"\"\"\n",
    "    Interactive 3D visualization of voxel tensor with dual threshold sliders.\n",
    "\n",
    "    Args:\n",
    "        voxel_tensor: (nx, ny, nz) numpy array with voxel counts\n",
    "        initial_min_threshold: Initial minimum threshold value for the slider (default: min_val)\n",
    "        initial_max_threshold: Initial maximum threshold value for the slider (default: max_val)\n",
    "        voxel_size_mm: Size of each voxel in mm (default: 1.0mm)\n",
    "        world_origin: (x_min, y_min, z_min) world coordinates of voxel (0,0,0) (optional)\n",
    "        min_threshold: Minimum threshold value for slider range (optional)\n",
    "        max_threshold: Maximum threshold value for slider range (optional)\n",
    "    \"\"\"\n",
    "    # Extract non-zero voxel coordinates and values\n",
    "    coords = np.where(voxel_tensor > 0)\n",
    "    x_coords, y_coords, z_coords = coords\n",
    "    values = voxel_tensor[coords]\n",
    "\n",
    "    # Convert voxel indices to world coordinates if world_origin provided\n",
    "    if world_origin is not None:\n",
    "        x_min, y_min, z_min = world_origin\n",
    "        x_coords_world = x_coords * voxel_size_mm + x_min\n",
    "        y_coords_world = y_coords * voxel_size_mm + y_min\n",
    "        z_coords_world = z_coords * voxel_size_mm + z_min\n",
    "        coord_suffix = \" (mm)\"\n",
    "    else:\n",
    "        x_coords_world = x_coords * voxel_size_mm\n",
    "        y_coords_world = y_coords * voxel_size_mm\n",
    "        z_coords_world = z_coords * voxel_size_mm\n",
    "        coord_suffix = f\" (×{voxel_size_mm}mm)\"\n",
    "\n",
    "    # Get value range for sliders\n",
    "    min_val = float(np.min(values))\n",
    "    max_val = float(np.max(values))\n",
    "\n",
    "    # Use user-specified min/max threshold range if provided\n",
    "    slider_min = min_threshold if min_threshold is not None else min_val\n",
    "    slider_max = max_threshold if max_threshold is not None else max_val\n",
    "\n",
    "    # Set initial thresholds with defaults\n",
    "    if initial_min_threshold is None:\n",
    "        initial_min_threshold = slider_min\n",
    "    else:\n",
    "        initial_min_threshold = max(slider_min, min(slider_max, float(initial_min_threshold)))\n",
    "    \n",
    "    if initial_max_threshold is None:\n",
    "        initial_max_threshold = slider_max\n",
    "    else:\n",
    "        initial_max_threshold = max(slider_min, min(slider_max, float(initial_max_threshold)))\n",
    "\n",
    "    # Ensure min <= max\n",
    "    if initial_min_threshold > initial_max_threshold:\n",
    "        initial_min_threshold, initial_max_threshold = initial_max_threshold, initial_min_threshold\n",
    "\n",
    "    print(f\"Voxel value range: {min_val} to {max_val}\")\n",
    "    print(f\"Total non-zero voxels: {len(values)}\")\n",
    "    print(f\"Initial thresholds: {initial_min_threshold} to {initial_max_threshold}\")\n",
    "    print(f\"Slider range: {slider_min} to {slider_max}\")\n",
    "    print(f\"Voxel resolution: {voxel_size_mm}mm\")\n",
    "\n",
    "    def update_plot(min_thresh, max_thresh):\n",
    "        # Ensure min <= max\n",
    "        if min_thresh > max_thresh:\n",
    "            min_thresh, max_thresh = max_thresh, min_thresh\n",
    "\n",
    "        # Filter voxels within threshold range\n",
    "        mask = (values >= min_thresh) & (values <= max_thresh)\n",
    "        if not np.any(mask):\n",
    "            print(f\"No voxels in threshold range [{min_thresh}, {max_thresh}]\")\n",
    "            return\n",
    "\n",
    "        filtered_x = x_coords_world[mask]\n",
    "        filtered_y = y_coords_world[mask]\n",
    "        filtered_z = z_coords_world[mask]\n",
    "        filtered_values = values[mask]\n",
    "\n",
    "        # Create 3D scatter plot\n",
    "        fig = go.Figure(data=go.Scatter3d(\n",
    "            x=filtered_x,\n",
    "            y=filtered_y,\n",
    "            z=filtered_z,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=1,\n",
    "                color=filtered_values,\n",
    "                colorscale='Viridis',\n",
    "                opacity=0.8,\n",
    "                colorbar=dict(title=\"Voxel Count\"),\n",
    "                line=dict(width=0)\n",
    "            ),\n",
    "            text=[f'Count: {v}' for v in filtered_values],\n",
    "            hovertemplate='<b>Voxel (%{x:.1f}, %{y:.1f}, %{z:.1f})</b><br>%{text}<extra></extra>'\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f'3D Voxel Visualization (Range: [{min_thresh:.6f}, {max_thresh:.6f}], Showing: {len(filtered_values)} voxels)',\n",
    "            scene=dict(\n",
    "                xaxis_title=f'X{coord_suffix}',\n",
    "                yaxis_title=f'Y{coord_suffix}',\n",
    "                zaxis_title=f'Z{coord_suffix}',\n",
    "                camera=dict(\n",
    "                    eye=dict(x=1.5, y=1.5, z=1.5)\n",
    "                ),\n",
    "                aspectmode='cube'\n",
    "            ),\n",
    "            width=800,\n",
    "            height=600\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    # Create interactive sliders with linked constraints\n",
    "    min_threshold_slider = FloatSlider(\n",
    "        value=initial_min_threshold,\n",
    "        min=slider_min,\n",
    "        max=slider_max,\n",
    "        step=0.01,\n",
    "        description='Min Threshold:',\n",
    "        continuous_update=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    max_threshold_slider = FloatSlider(\n",
    "        value=initial_max_threshold,\n",
    "        min=slider_min,\n",
    "        max=slider_max,\n",
    "        step=0.01,\n",
    "        description='Max Threshold:',\n",
    "        continuous_update=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Link sliders to maintain min <= max constraint\n",
    "    def on_min_change(change):\n",
    "        if change['new'] > max_threshold_slider.value:\n",
    "            max_threshold_slider.value = change['new']\n",
    "\n",
    "    def on_max_change(change):\n",
    "        if change['new'] < min_threshold_slider.value:\n",
    "            min_threshold_slider.value = change['new']\n",
    "\n",
    "    min_threshold_slider.observe(on_min_change, names='value')\n",
    "    max_threshold_slider.observe(on_max_change, names='value')\n",
    "\n",
    "    interact(update_plot, \n",
    "             min_thresh=min_threshold_slider, \n",
    "             max_thresh=max_threshold_slider)\n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "def plot_cross_sections_interactive(numpy_array, vmax=None, title=\"Orthogonal Cross Sections\"):\n",
    "    \"\"\"\n",
    "    Create an interactive 3D cross-section viewer for a 3D numpy array.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    numpy_array : np.ndarray\n",
    "        3D numpy array to visualize (shape: nx, ny, nz)\n",
    "    vmax : float, optional\n",
    "        Maximum value for color scale. If None, uses array maximum\n",
    "    title : str, optional\n",
    "        Title for the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure input is numpy array\n",
    "    if not isinstance(numpy_array, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array\")\n",
    "    \n",
    "    if numpy_array.ndim != 3:\n",
    "        raise ValueError(\"Input must be a 3D array\")\n",
    "    \n",
    "    nx, ny, nz = numpy_array.shape\n",
    "    \n",
    "    # Set default vmax if not provided\n",
    "    if vmax is None:\n",
    "        vmax = numpy_array.max()\n",
    "    \n",
    "    def plot_cross_sections_horizontal(x_idx=nx//2, y_idx=ny//2, z_idx=nz//2, \n",
    "                                     vmax_slider=vmax, cmap='Magma'):\n",
    "        fig = make_subplots(rows=1, cols=3, subplot_titles=[\n",
    "            f'XY plane @ z={z_idx}',\n",
    "            f'XZ plane @ y={y_idx}',\n",
    "            f'YZ plane @ x={x_idx}'\n",
    "        ])\n",
    "\n",
    "        # XY plane at z=z_idx\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=numpy_array[:, :, z_idx].T,\n",
    "            colorscale=cmap,\n",
    "            zmax=vmax_slider,\n",
    "            zmin=0,\n",
    "            showscale=True,\n",
    "            name=f'XY @ z={z_idx}'\n",
    "        ), row=1, col=1)\n",
    "\n",
    "        # XZ plane at y=y_idx\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=numpy_array[:, y_idx, :].T,\n",
    "            colorscale=cmap,\n",
    "            zmax=vmax_slider,\n",
    "            zmin=0,\n",
    "            showscale=True,\n",
    "            name=f'XZ @ y={y_idx}'\n",
    "        ), row=1, col=2)\n",
    "\n",
    "        # YZ plane at x=x_idx\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=numpy_array[x_idx, :, :].T,\n",
    "            colorscale=cmap,\n",
    "            zmax=vmax_slider,\n",
    "            zmin=0,\n",
    "            showscale=True,\n",
    "            name=f'YZ @ x={x_idx}'\n",
    "        ), row=1, col=3)\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=1200,\n",
    "            height=400,\n",
    "            title_text=title\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "    # Create interactive widget\n",
    "    interact(\n",
    "        plot_cross_sections_horizontal,\n",
    "        x_idx=IntSlider(min=0, max=nx-1, step=1, value=nx//2, description='X index'),\n",
    "        y_idx=IntSlider(min=0, max=ny-1, step=1, value=ny//2, description='Y index'),\n",
    "        z_idx=IntSlider(min=0, max=nz-1, step=1, value=nz//2, description='Z index'),\n",
    "        vmax_slider=FloatSlider(min=0, max=numpy_array.max(), step=0.01, value=vmax, description='vmax'),\n",
    "        cmap=['Magma','Greys', 'Viridis', 'Cividis', 'Plasma']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Loading, Filtering, and Coordinate Range Calculation\n",
    "import numpy as np\n",
    "\n",
    "# Load coordinates\n",
    "coordinates = np.load(fr\"C:\\Users\\h\\Desktop\\PET_Recons\\Reconstructions\\ground_truth.npy\")\n",
    "\n",
    "# Confirm shape should be (pairs, coords=6), coords are (x1, y1, z1, x2, y2, z2)\n",
    "print(f\"\\nData Shape (pairs, coords) : {coordinates.shape}\\n\")  \n",
    "\n",
    "# Remove pairs where any coordinate value is exactly 0\n",
    "filtered_coordinates = coordinates[~np.any(coordinates == 0, axis=1)]\n",
    "filtered_coordinates = torch.from_numpy(filtered_coordinates).float()\n",
    "# filtered_coordinates = filtered_coordinates[:100,:]\n",
    "print(f\"Filtered shape: {filtered_coordinates.shape}\\n\")\n",
    "\n",
    "# Extract all x, y, z pairs - Coordinates are in the order (x1, y1, z1, x2, y2, z2)\n",
    "all_xyz = filtered_coordinates.reshape(-1, 3) # Reshape to (pairs, 3) for (x, y, z)\n",
    "x_vals, y_vals, z_vals = all_xyz[:, 0], all_xyz[:, 1], all_xyz[:, 2]\n",
    "print(f\"x range: min={x_vals.min()}, max={x_vals.max()}\")\n",
    "print(f\"y range: min={y_vals.min()}, max={y_vals.max()}\")\n",
    "print(f\"z range: min={z_vals.min()}, max={z_vals.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf1478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "def create_intersecting_lines(counts=1000, intersection_point=(0, 0, 0), coord_range=(100, 100, 100)):\n",
    "    \"\"\"\n",
    "    Create a torch tensor of shape (counts, 6) containing lines that all intersect EXACTLY at a specified point.\n",
    "    \n",
    "    Args:\n",
    "        counts: Number of lines to generate\n",
    "        intersection_point: (x, y, z) coordinates where all lines intersect\n",
    "        coord_range: (x_range, y_range, z_range) maximum absolute values for coordinates\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Shape (counts, 6) with format [x1, y1, z1, x2, y2, z2] per row\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to tensors\n",
    "    intersection = torch.tensor(intersection_point, dtype=torch.float32)\n",
    "    ranges = torch.tensor(coord_range, dtype=torch.float32)\n",
    "    \n",
    "    # Generate random unit directions for each line\n",
    "    directions = torch.randn(counts, 3)\n",
    "    directions = directions / torch.norm(directions, dim=1, keepdim=True)\n",
    "    \n",
    "    lines = torch.zeros(counts, 6, dtype=torch.float32)\n",
    "    \n",
    "    for i in range(counts):\n",
    "        direction = directions[i]\n",
    "        \n",
    "        # Calculate maximum possible distances in positive and negative directions\n",
    "        # while staying within coordinate bounds\n",
    "        pos_distances = torch.where(direction > 0, \n",
    "                                  (ranges - intersection) / direction,\n",
    "                                  torch.where(direction < 0,\n",
    "                                            (intersection + ranges) / (-direction),\n",
    "                                            torch.tensor(float('inf'))))\n",
    "        \n",
    "        neg_distances = torch.where(direction < 0,\n",
    "                                  (ranges - intersection) / (-direction),\n",
    "                                  torch.where(direction > 0,\n",
    "                                            (intersection + ranges) / direction,\n",
    "                                            torch.tensor(float('inf'))))\n",
    "        \n",
    "        # Use the minimum constraint for each direction\n",
    "        max_pos_distance = torch.min(pos_distances)\n",
    "        max_neg_distance = torch.min(neg_distances)\n",
    "        \n",
    "        # Generate random distances within valid bounds\n",
    "        # Ensure we don't go to zero distance (which would make both endpoints the same)\n",
    "        min_distance = 0.1  # Small minimum distance to avoid degenerate lines\n",
    "        \n",
    "        if max_pos_distance > min_distance:\n",
    "            pos_distance = torch.rand(1) * (max_pos_distance - min_distance) + min_distance\n",
    "        else:\n",
    "            pos_distance = torch.tensor([min_distance])\n",
    "            \n",
    "        if max_neg_distance > min_distance:\n",
    "            neg_distance = torch.rand(1) * (max_neg_distance - min_distance) + min_distance\n",
    "        else:\n",
    "            neg_distance = torch.tensor([min_distance])\n",
    "        \n",
    "        # Calculate endpoints\n",
    "        endpoint1 = intersection + pos_distance * direction\n",
    "        endpoint2 = intersection - neg_distance * direction\n",
    "        \n",
    "        # Store in tensor\n",
    "        lines[i, :3] = endpoint1\n",
    "        lines[i, 3:] = endpoint2\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def verify_intersection(lines, intersection_point=(0, 0, 0), tolerance=1e-6):\n",
    "    \"\"\"\n",
    "    Verify that lines pass EXACTLY through the intersection point\n",
    "    \"\"\"\n",
    "    intersection = torch.tensor(intersection_point, dtype=torch.float32)\n",
    "    \n",
    "    max_error = 0.0\n",
    "    for i in range(len(lines)):\n",
    "        p1 = lines[i, :3]\n",
    "        p2 = lines[i, 3:]\n",
    "        \n",
    "        # Parametric line equation: point = p1 + t*(p2-p1)\n",
    "        # Find t where line passes through intersection\n",
    "        direction = p2 - p1\n",
    "        to_intersection = intersection - p1\n",
    "        \n",
    "        # Solve: p1 + t*(p2-p1) = intersection\n",
    "        # t = dot(to_intersection, direction) / dot(direction, direction)\n",
    "        t = torch.dot(to_intersection, direction) / torch.dot(direction, direction)\n",
    "        point_on_line = p1 + t * direction\n",
    "        \n",
    "        error = torch.norm(point_on_line - intersection).item()\n",
    "        max_error = max(max_error, error)\n",
    "        \n",
    "        if i < 5:  # Print first 5 for verification\n",
    "            print(f\"Line {i}: error = {error:.10f}, t = {t:.6f}\")\n",
    "    \n",
    "    print(f\"Maximum error across all lines: {max_error:.10f}\")\n",
    "    print(f\"All lines pass through intersection: {max_error < tolerance}\")\n",
    "    return max_error < tolerance\n",
    "\n",
    "# # Test the corrected function\n",
    "# print(\"Testing exact intersecting lines:\")\n",
    "# lines_tensor = create_intersecting_lines(counts=1000)\n",
    "# print(f\"Generated tensor shape: {lines_tensor.shape}\")\n",
    "\n",
    "# print(\"\\nVerification (should be exactly 0 or very close):\")\n",
    "# verify_intersection(lines_tensor)\n",
    "\n",
    "# # Test with custom intersection point\n",
    "# print(\"\\n\" + \"=\"*50)\n",
    "# print(\"Testing with custom intersection point:\")\n",
    "# custom_lines = create_intersecting_lines(\n",
    "#     counts=5000, \n",
    "#     intersection_point=(10, -5, 20), \n",
    "#     coord_range=(50, 75, 30)\n",
    "# )\n",
    "# print(f\"Custom tensor shape: {custom_lines.shape}\")\n",
    "# verify_intersection(custom_lines, intersection_point=(10, -5, 20))\n",
    "# filtered_coordinates = custom_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shape extraction and basic 3d backprojection\n",
    "voxel_size = 3.0\n",
    "\n",
    "def binary_rasterize_lors_3d_dda(pairs_coords, voxel_size_mm=1.0):\n",
    "    \"\"\"\n",
    "    Rasterize lines of response into 3D voxel space using exact 3D DDA traversal.\n",
    "    \n",
    "    Args:\n",
    "        pairs_coords: (N, 6) array where each row is [x1,y1,z1,x2,y2,z2]\n",
    "        voxel_size_mm: Size of each voxel in mm (default: 1.0mm)\n",
    "    \n",
    "    Returns:\n",
    "        voxel_tensor: (nx, ny, nz) array with line traversal counts\n",
    "    \"\"\"\n",
    "    # World coordinate ranges (mm)\n",
    "    all_xyz = pairs_coords.reshape(-1, 3) # Reshape to (pairs, 3) for (x, y, z)\n",
    "    x_vals, y_vals, z_vals = all_xyz[:, 0], all_xyz[:, 1], all_xyz[:, 2]\n",
    "\n",
    "    x_min = x_vals.min()\n",
    "    x_max = x_vals.max()\n",
    "    y_min = y_vals.min()\n",
    "    y_max = y_vals.max()\n",
    "    z_min = z_vals.min()\n",
    "    z_max = z_vals.max()\n",
    "\n",
    "    # Round the min and max values to voxel boundaries\n",
    "    x_min = np.floor(x_min / voxel_size_mm) * voxel_size_mm\n",
    "    x_max = np.ceil(x_max / voxel_size_mm) * voxel_size_mm\n",
    "    y_min = np.floor(y_min / voxel_size_mm) * voxel_size_mm\n",
    "    y_max = np.ceil(y_max / voxel_size_mm) * voxel_size_mm\n",
    "    z_min = np.floor(z_min / voxel_size_mm) * voxel_size_mm\n",
    "    z_max = np.ceil(z_max / voxel_size_mm) * voxel_size_mm\n",
    "\n",
    "    # Calculate voxel tensor shape based on resolution\n",
    "    nx = int((x_max - x_min) / voxel_size_mm)\n",
    "    ny = int((y_max - y_min) / voxel_size_mm)\n",
    "    nz = int((z_max - z_min) / voxel_size_mm)\n",
    "    \n",
    "    voxel_shape = (nx, ny, nz)\n",
    "    print(f\"Voxel size: {voxel_size_mm}mm\")\n",
    "    print(f\"Voxel shape: {voxel_shape} (nx, ny, nz)\")\n",
    "    \n",
    "    voxel_tensor = np.zeros(voxel_shape, dtype=np.int32)\n",
    "    \n",
    "    # Coordinate transformation: world -> voxel indices\n",
    "    def world_to_voxel(coords):\n",
    "        x, y, z = coords[:, 0], coords[:, 1], coords[:, 2]\n",
    "        vx = (x - x_min) / voxel_size_mm\n",
    "        vy = (y - y_min) / voxel_size_mm\n",
    "        vz = (z - z_min) / voxel_size_mm\n",
    "        return np.column_stack([vx, vy, vz])\n",
    "    \n",
    "    def dda_3d(p1, p2):\n",
    "        \"\"\"3D DDA algorithm - returns list of (x,y,z) voxel indices along line\"\"\"\n",
    "        x1, y1, z1 = p1\n",
    "        x2, y2, z2 = p2\n",
    "        \n",
    "        # Direction and step sizes\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        dz = z2 - z1\n",
    "        \n",
    "        # Number of steps is maximum of absolute differences\n",
    "        steps = int(max(abs(dx), abs(dy), abs(dz)))\n",
    "        if steps == 0:\n",
    "            return [(int(round(x1)), int(round(y1)), int(round(z1)))]\n",
    "        \n",
    "        # Step increments\n",
    "        x_inc = dx / steps\n",
    "        y_inc = dy / steps\n",
    "        z_inc = dz / steps\n",
    "        \n",
    "        voxels = []\n",
    "        x, y, z = x1, y1, z1\n",
    "        \n",
    "        for _ in range(steps + 1):\n",
    "            vx, vy, vz = int(round(x)), int(round(y)), int(round(z))\n",
    "            \n",
    "            # Check bounds\n",
    "            if 0 <= vx < nx and 0 <= vy < ny and 0 <= vz < nz:\n",
    "                voxels.append((vx, vy, vz))\n",
    "            \n",
    "            x += x_inc\n",
    "            y += y_inc\n",
    "            z += z_inc\n",
    "        \n",
    "        return voxels\n",
    "    \n",
    "    # Transform all coordinates to voxel space\n",
    "    points1 = world_to_voxel(pairs_coords[:, :3])  # First points\n",
    "    points2 = world_to_voxel(pairs_coords[:, 3:])  # Second points\n",
    "    \n",
    "    # Process each LOR\n",
    "    for i in range(len(pairs_coords)):\n",
    "        p1 = points1[i]\n",
    "        p2 = points2[i]\n",
    "        \n",
    "        # Get voxels along this line\n",
    "        voxels = dda_3d(p1, p2)\n",
    "        \n",
    "        # Increment voxel counts\n",
    "        for vx, vy, vz in voxels:\n",
    "            voxel_tensor[vx, vy, vz] += 1\n",
    "    \n",
    "    return voxel_tensor\n",
    "\n",
    "voxel_tensor = binary_rasterize_lors_3d_dda(filtered_coordinates, voxel_size_mm=voxel_size)\n",
    "print(f\"Voxel tensor shape: {voxel_tensor.shape}\")\n",
    "\n",
    "# Specify object space for reconstruction\n",
    "# voxel_space = voxel_tensor.shape # voxels\n",
    "voxel_space = voxel_tensor.shape # voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a187f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import FigureWidget\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from ipywidgets import interact, IntSlider, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize_lors_and_detectors_3d(coordinates, scanner_info=None, sample_lors=None, \n",
    "                                   highlight_detector_ids=None, highlight_color='green',\n",
    "                                   validate_lor_index=None, verbose=True, \n",
    "                                   distance_threshold=5.0):\n",
    "    \"\"\"\n",
    "    3D visualization of LOR endpoints and PET detector positions with interactive slider for LOR validation.\n",
    "    Camera orientation is preserved during slider interactions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    coordinates : numpy.ndarray\n",
    "        Shape (n_lors, 6) containing [x1, y1, z1, x2, y2, z2] for each LOR\n",
    "    scanner_info : dict, optional\n",
    "        Dictionary containing scanner geometry parameters. If None, only LOR endpoints are visualized.\n",
    "    sample_lors : int, optional\n",
    "        Number of LORs to sample for visualization (default: all)\n",
    "    highlight_detector_ids : list or set, optional\n",
    "        Detector IDs to highlight with different color (ignored if scanner_info is None)\n",
    "    highlight_color : str, optional\n",
    "        Color for highlighted detectors (default: 'green')\n",
    "    validate_lor_index : int, optional\n",
    "        Initial LOR index to display in the slider (default: 0)\n",
    "    verbose : bool, optional\n",
    "        If False, suppresses all print outputs (default: True)\n",
    "    distance_threshold : float, optional\n",
    "        Maximum allowed distance (in mm) between extended endpoints and assigned detectors.\n",
    "        LOR pairs where either endpoint exceeds this distance are excluded (default: 5.0)\n",
    "        Only used if scanner_info is provided.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        If scanner_info provided: (full_detector_id_pairs, valid_detector_id_pairs, valid_lor_indices)\n",
    "        If scanner_info is None: (None, None, None)\n",
    "    \"\"\"\n",
    "    \n",
    "    def extend_endpoints_to_radius(endpoints1, endpoints2, target_radius):\n",
    "        \"\"\"\n",
    "        Extend LOR endpoints along the LOR direction until they reach the target radius.\n",
    "        \"\"\"\n",
    "        # Calculate LOR direction vectors (from endpoint1 to endpoint2)\n",
    "        lor_directions = endpoints2 - endpoints1\n",
    "        lor_lengths = np.linalg.norm(lor_directions, axis=1, keepdims=True)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        lor_lengths = np.where(lor_lengths == 0, 1e-10, lor_lengths)\n",
    "        lor_unit_vectors = lor_directions / lor_lengths\n",
    "        \n",
    "        def find_radius_intersection(start_point, direction, target_radius):\n",
    "            \"\"\"Find where a ray intersects the cylinder at target_radius.\"\"\"\n",
    "            x0, y0, z0 = start_point.T\n",
    "            dx, dy, dz = direction.T\n",
    "            \n",
    "            # Quadratic equation coefficients: at² + bt + c = 0\n",
    "            a = dx**2 + dy**2\n",
    "            b = 2 * (x0 * dx + y0 * dy)\n",
    "            c = x0**2 + y0**2 - target_radius**2\n",
    "            \n",
    "            # Solve quadratic equation\n",
    "            valid_mask = np.abs(a) > 1e-10  # Direction has xy component\n",
    "            result = start_point.copy()\n",
    "            \n",
    "            if np.any(valid_mask):\n",
    "                a_valid = a[valid_mask]\n",
    "                b_valid = b[valid_mask]\n",
    "                c_valid = c[valid_mask]\n",
    "                \n",
    "                discriminant = b_valid**2 - 4 * a_valid * c_valid\n",
    "                solvable_mask = discriminant >= 0\n",
    "                \n",
    "                if np.any(solvable_mask):\n",
    "                    sqrt_disc = np.sqrt(discriminant[solvable_mask])\n",
    "                    t1 = (-b_valid[solvable_mask] + sqrt_disc) / (2 * a_valid[solvable_mask])\n",
    "                    t2 = (-b_valid[solvable_mask] - sqrt_disc) / (2 * a_valid[solvable_mask])\n",
    "                    \n",
    "                    # Choose the positive t value\n",
    "                    t_chosen = np.where(\n",
    "                        (t1 > 0) & (t2 > 0), np.minimum(t1, t2),\n",
    "                        np.where(t1 > 0, t1, \n",
    "                                np.where(t2 > 0, t2, np.maximum(t1, t2)))\n",
    "                    )\n",
    "                    \n",
    "                    # Calculate intersection points\n",
    "                    valid_indices = np.where(valid_mask)[0]\n",
    "                    solvable_indices = valid_indices[solvable_mask]\n",
    "                    \n",
    "                    result[solvable_indices] = (start_point[solvable_indices] + \n",
    "                                            t_chosen.reshape(-1, 1) * direction[solvable_indices])\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        # Extend endpoints in OPPOSITE directions along the LOR line\n",
    "        extended_endpoints1 = find_radius_intersection(endpoints1, -lor_unit_vectors, target_radius)\n",
    "        extended_endpoints2 = find_radius_intersection(endpoints2, lor_unit_vectors, target_radius)\n",
    "        \n",
    "        return extended_endpoints1, extended_endpoints2\n",
    "    \n",
    "    # Sample LORs if specified\n",
    "    if sample_lors is not None and sample_lors < coordinates.shape[0]:\n",
    "        indices = np.random.choice(coordinates.shape[0], sample_lors, replace=False)\n",
    "        coordinates_sample = coordinates[indices]\n",
    "        if verbose:\n",
    "            print(f\"Sampling {sample_lors} LORs out of {coordinates.shape[0]} total\")\n",
    "    else:\n",
    "        coordinates_sample = coordinates\n",
    "        if verbose:\n",
    "            print(f\"Visualizing all {coordinates.shape[0]} LORs\")\n",
    "    \n",
    "    # Extract LOR endpoints\n",
    "    n_lors = coordinates_sample.shape[0]\n",
    "    endpoint1 = coordinates_sample[:, :3]  # [x1, y1, z1]\n",
    "    endpoint2 = coordinates_sample[:, 3:]  # [x2, y2, z2]\n",
    "    \n",
    "    # Initialize variables for detector analysis (will remain None if no scanner_info)\n",
    "    detector_positions = None\n",
    "    detector_ids = None\n",
    "    full_detector_id_pairs = None\n",
    "    valid_detector_id_pairs = None\n",
    "    valid_lor_indices = None\n",
    "    extended_endpoint1 = None\n",
    "    extended_endpoint2 = None\n",
    "    distances1 = None\n",
    "    distances2 = None\n",
    "    \n",
    "    # Only perform detector analysis if scanner_info is provided\n",
    "    if scanner_info is not None:\n",
    "        # Generate detector positions and IDs\n",
    "        radius = scanner_info['radius']\n",
    "        crystals_per_ring = scanner_info['NrCrystalsPerRing']\n",
    "        n_rings = scanner_info['NrRings']\n",
    "        crystal_axial_spacing = scanner_info['crystalAxialSpacing']\n",
    "        module_axial_spacing = scanner_info['moduleAxialSpacing']\n",
    "        module_axial_nr = scanner_info['moduleAxialNr']\n",
    "        crystals_axial_per_module = scanner_info['crystalAxialNr']\n",
    "        \n",
    "        # Calculate total axial extent\n",
    "        crystals_per_module_axial = crystals_axial_per_module\n",
    "        modules_span = (module_axial_nr - 1) * module_axial_spacing\n",
    "        crystals_within_modules_span = (crystals_per_module_axial - 1) * crystal_axial_spacing * module_axial_nr\n",
    "        total_axial_extent = modules_span + crystals_within_modules_span\n",
    "        \n",
    "        # Generate detector positions and IDs\n",
    "        detector_positions = []\n",
    "        detector_ids = []\n",
    "        \n",
    "        for ring in range(n_rings):\n",
    "            # Calculate z position for this ring\n",
    "            if n_rings == 1:\n",
    "                z_pos = 0.0\n",
    "            else:\n",
    "                z_pos = -total_axial_extent/2 + ring * (total_axial_extent / (n_rings - 1))\n",
    "            \n",
    "            for crystal in range(crystals_per_ring):\n",
    "                # Calculate angular position\n",
    "                angle = 2 * np.pi * crystal / crystals_per_ring\n",
    "                \n",
    "                # Convert to Cartesian coordinates\n",
    "                x_pos = radius * np.cos(angle)\n",
    "                y_pos = radius * np.sin(angle)\n",
    "                \n",
    "                detector_positions.append([x_pos, y_pos, z_pos])\n",
    "                detector_id = ring * crystals_per_ring + crystal\n",
    "                detector_ids.append(detector_id)\n",
    "        \n",
    "        detector_positions = np.array(detector_positions)\n",
    "        detector_ids = np.array(detector_ids)\n",
    "        \n",
    "        # Calculate detector assignments for all LORs\n",
    "        extended_endpoint1, extended_endpoint2 = extend_endpoints_to_radius(endpoint1, endpoint2, radius)\n",
    "        \n",
    "        # Build KDTree for efficient nearest neighbor search\n",
    "        kdtree = cKDTree(detector_positions)\n",
    "        \n",
    "        # Find nearest detector for each extended endpoint\n",
    "        _, nearest_indices1 = kdtree.query(extended_endpoint1)\n",
    "        _, nearest_indices2 = kdtree.query(extended_endpoint2)\n",
    "        \n",
    "        # Convert to detector IDs\n",
    "        full_detector_id_pairs = np.column_stack([\n",
    "            detector_ids[nearest_indices1],\n",
    "            detector_ids[nearest_indices2]\n",
    "        ])\n",
    "        \n",
    "        # Calculate distances and apply filtering\n",
    "        distances1 = np.linalg.norm(extended_endpoint1 - detector_positions[nearest_indices1], axis=1)\n",
    "        distances2 = np.linalg.norm(extended_endpoint2 - detector_positions[nearest_indices2], axis=1)\n",
    "        valid_mask = (distances1 <= distance_threshold) & (distances2 <= distance_threshold)\n",
    "        \n",
    "        valid_detector_id_pairs = full_detector_id_pairs[valid_mask]\n",
    "        valid_lor_indices = np.where(valid_mask)[0]\n",
    "        \n",
    "        # Print initial statistics\n",
    "        if verbose:\n",
    "            print(f\"\\nDistance Filtering (threshold: {distance_threshold} mm):\")\n",
    "            print(f\"Original LORs: {len(full_detector_id_pairs)}\")\n",
    "            print(f\"Valid LORs: {len(valid_detector_id_pairs)}\")\n",
    "            print(f\"Filtered out: {len(full_detector_id_pairs) - len(valid_detector_id_pairs)}\")\n",
    "            print(f\"Filtering efficiency: {len(valid_detector_id_pairs)/len(full_detector_id_pairs)*100:.1f}%\")\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"No scanner_info provided - visualizing LOR endpoints only\")\n",
    "    \n",
    "    # Create the persistent FigureWidget\n",
    "    fig = FigureWidget()\n",
    "    \n",
    "    # Add static background elements that don't change with slider\n",
    "    all_lor_points = np.vstack([endpoint1, endpoint2])\n",
    "    bg_opacity = 0.3\n",
    "    detector_opacity = 0.4\n",
    "    \n",
    "    # Add ALL LOR endpoints (static background)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_lor_points[:, 0],\n",
    "        y=all_lor_points[:, 1],\n",
    "        z=all_lor_points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color='red',\n",
    "            opacity=bg_opacity,\n",
    "            line=dict(width=0)\n",
    "        ),\n",
    "        name=f'All LOR Endpoints',\n",
    "        hovertemplate='<b>LOR Endpoint</b><br>' +\n",
    "                      'X: %{x:.1f} mm<br>' +\n",
    "                      'Y: %{y:.1f} mm<br>' +\n",
    "                      'Z: %{z:.1f} mm<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Add detector traces only if scanner_info is provided\n",
    "    if scanner_info is not None:\n",
    "        # Prepare detector colors\n",
    "        if highlight_detector_ids is not None:\n",
    "            highlight_set = set(highlight_detector_ids)\n",
    "            highlight_mask = np.isin(detector_ids, list(highlight_set))\n",
    "            regular_mask = ~highlight_mask\n",
    "            regular_positions = detector_positions[regular_mask]\n",
    "            highlight_positions = detector_positions[highlight_mask]\n",
    "            regular_ids = detector_ids[regular_mask]\n",
    "            highlight_ids = detector_ids[highlight_mask]\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Highlighting {len(highlight_positions)} detectors: {sorted(highlight_set)}\")\n",
    "        else:\n",
    "            regular_positions = detector_positions\n",
    "            highlight_positions = np.array([]).reshape(0, 3)\n",
    "            regular_ids = detector_ids\n",
    "            highlight_ids = np.array([])\n",
    "        \n",
    "        # Add regular detectors (static)\n",
    "        if len(regular_positions) > 0:\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=regular_positions[:, 0],\n",
    "                y=regular_positions[:, 1],\n",
    "                z=regular_positions[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=3,\n",
    "                    color='blue',\n",
    "                    opacity=detector_opacity,\n",
    "                    symbol='diamond',\n",
    "                    line=dict(width=0)\n",
    "                ),\n",
    "                name='Regular Detectors',\n",
    "                customdata=regular_ids,\n",
    "                hovertemplate='<b>Detector ID: %{customdata}</b><br>' +\n",
    "                              'X: %{x:.1f} mm<br>' +\n",
    "                              'Y: %{y:.1f} mm<br>' +\n",
    "                              'Z: %{z:.1f} mm<extra></extra>'\n",
    "            ))\n",
    "        \n",
    "        # Add highlighted detectors (static)\n",
    "        if len(highlight_positions) > 0:\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=highlight_positions[:, 0],\n",
    "                y=highlight_positions[:, 1],\n",
    "                z=highlight_positions[:, 2],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=5,\n",
    "                    color=highlight_color,\n",
    "                    opacity=1.0,\n",
    "                    symbol='diamond',\n",
    "                    line=dict(width=1, color='black')\n",
    "                ),\n",
    "                name=f'Highlighted Detectors ({highlight_color})',\n",
    "                customdata=highlight_ids,\n",
    "                hovertemplate='<b>Highlighted Detector ID: %{customdata}</b><br>' +\n",
    "                              'X: %{x:.1f} mm<br>' +\n",
    "                              'Y: %{y:.1f} mm<br>' +\n",
    "                              'Z: %{z:.1f} mm<extra></extra>'\n",
    "            ))\n",
    "    \n",
    "    # Define trace names based on whether scanner_info is provided\n",
    "    if scanner_info is not None:\n",
    "        trace_names = [\n",
    "            'LOR - Original Endpoints',\n",
    "            'LOR - Extended Endpoints', \n",
    "            'LOR - Assigned Detectors',\n",
    "            'LOR - Original Line',\n",
    "            'Extension Path 1',\n",
    "            'Extension Path 2', \n",
    "            'Detector Assignment 1',\n",
    "            'Detector Assignment 2'\n",
    "        ]\n",
    "    else:\n",
    "        trace_names = [\n",
    "            'LOR - Original Endpoints',\n",
    "            'LOR - Original Line'\n",
    "        ]\n",
    "    \n",
    "    # Add empty traces that will be populated by slider updates\n",
    "    for i, name in enumerate(trace_names):\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[], y=[], z=[],\n",
    "            mode='markers' if 'Endpoints' in name or 'Detectors' in name else 'lines',\n",
    "            name=name,\n",
    "            showlegend=True if 'Endpoints' in name or 'Detectors' in name else False\n",
    "        ))\n",
    "    \n",
    "    # Set initial layout\n",
    "    title_text = '3D LOR Validation with Persistent Camera View' if scanner_info is not None else '3D LOR Point Cloud Visualization'\n",
    "    fig.update_layout(\n",
    "        title=title_text,\n",
    "        scene=dict(\n",
    "            xaxis_title='X (mm)',\n",
    "            yaxis_title='Y (mm)',\n",
    "            zaxis_title='Z (mm)',\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.5, y=1.5, z=1.5),\n",
    "                center=dict(x=0, y=0, z=0),\n",
    "                up=dict(x=0, y=0, z=1)\n",
    "            ),\n",
    "            aspectmode='cube'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        legend=dict(\n",
    "            x=0.02,\n",
    "            y=0.98,\n",
    "            bgcolor='rgba(255,255,255,0.8)'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def update_lor_visualization(lor_index):\n",
    "        \"\"\"Update only the LOR-specific traces without recreating the entire plot\"\"\"\n",
    "        \n",
    "        if lor_index >= coordinates_sample.shape[0]:\n",
    "            # Clear all dynamic traces if invalid index\n",
    "            static_traces_count = 1  # All LOR endpoints\n",
    "            if scanner_info is not None:\n",
    "                static_traces_count += 1  # Regular detectors\n",
    "                if highlight_detector_ids is not None:\n",
    "                    static_traces_count += 1  # Highlighted detectors\n",
    "            \n",
    "            with fig.batch_update():\n",
    "                for i in range(len(trace_names)):\n",
    "                    fig.data[static_traces_count + i].update(x=[], y=[], z=[])\n",
    "                title_suffix = 'LOR Validation' if scanner_info is not None else 'LOR Point Cloud Visualization'\n",
    "                fig.layout.title.text = f'3D {title_suffix}: LOR {lor_index} (INVALID INDEX)'\n",
    "            return\n",
    "        \n",
    "        # Get the specific LOR's data\n",
    "        val_endpoint1 = coordinates_sample[lor_index, :3]\n",
    "        val_endpoint2 = coordinates_sample[lor_index, 3:]\n",
    "        \n",
    "        # Calculate how many static traces we have\n",
    "        static_traces_count = 1  # All LOR endpoints\n",
    "        if scanner_info is not None:\n",
    "            static_traces_count += 1  # Regular detectors\n",
    "            if highlight_detector_ids is not None:\n",
    "                static_traces_count += 1  # Highlighted detectors\n",
    "        \n",
    "        with fig.batch_update():\n",
    "            if scanner_info is not None:\n",
    "                # Get validation data for the selected LOR\n",
    "                original_lor_survived = lor_index in valid_lor_indices\n",
    "                val_extended1 = extended_endpoint1[lor_index]\n",
    "                val_extended2 = extended_endpoint2[lor_index]\n",
    "                \n",
    "                # Get detector assignments\n",
    "                val_detector1_id = full_detector_id_pairs[lor_index, 0]\n",
    "                val_detector2_id = full_detector_id_pairs[lor_index, 1]\n",
    "                \n",
    "                # Find detector positions\n",
    "                det_idx1 = np.where(detector_ids == val_detector1_id)[0][0]\n",
    "                det_idx2 = np.where(detector_ids == val_detector2_id)[0][0]\n",
    "                val_detector1_pos = detector_positions[det_idx1]\n",
    "                val_detector2_pos = detector_positions[det_idx2]\n",
    "                \n",
    "                dist1, dist2 = distances1[lor_index], distances2[lor_index]\n",
    "                \n",
    "                # Color coding based on validity\n",
    "                endpoint_color = 'orange' if original_lor_survived else 'red'\n",
    "                extended_color = 'purple' if original_lor_survived else 'magenta'\n",
    "                detector_color = 'yellow' if original_lor_survived else 'pink'\n",
    "                line_color_1 = 'orange' if original_lor_survived else 'red'\n",
    "                line_color_2 = 'purple' if original_lor_survived else 'magenta'\n",
    "                \n",
    "                status_text = f\"VALID (≤{distance_threshold}mm)\" if original_lor_survived else f\"FILTERED (>{distance_threshold}mm)\"\n",
    "                \n",
    "                # Update traces in the exact order they were created in trace_names:\n",
    "                # 0: 'LOR - Original Endpoints'\n",
    "                fig.data[static_traces_count + 0].update(\n",
    "                    x=[val_endpoint1[0], val_endpoint2[0]],\n",
    "                    y=[val_endpoint1[1], val_endpoint2[1]],\n",
    "                    z=[val_endpoint1[2], val_endpoint2[2]],\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=endpoint_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='circle',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Original Endpoints ({status_text})',\n",
    "                    hovertemplate='<b>Original Endpoint</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # 1: 'LOR - Extended Endpoints'\n",
    "                fig.data[static_traces_count + 1].update(\n",
    "                    x=[val_extended1[0], val_extended2[0]],\n",
    "                    y=[val_extended1[1], val_extended2[1]],\n",
    "                    z=[val_extended1[2], val_extended2[2]],\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=extended_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='square',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Extended Endpoints',\n",
    "                    hovertemplate='<b>Extended Endpoint</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # 2: 'LOR - Assigned Detectors'\n",
    "                fig.data[static_traces_count + 2].update(\n",
    "                    x=[val_detector1_pos[0], val_detector2_pos[0]],\n",
    "                    y=[val_detector1_pos[1], val_detector2_pos[1]],\n",
    "                    z=[val_detector1_pos[2], val_detector2_pos[2]],\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=detector_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='diamond-open',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Assigned Detectors (d1:{dist1:.1f}mm, d2:{dist2:.1f}mm)',\n",
    "                    customdata=[val_detector1_id, val_detector2_id],\n",
    "                    hovertemplate='<b>Assigned Detector ID: %{customdata}</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # 3: 'LOR - Original Line'\n",
    "                fig.data[static_traces_count + 3].update(\n",
    "                    x=[val_endpoint1[0], val_endpoint2[0]],\n",
    "                    y=[val_endpoint1[1], val_endpoint2[1]],\n",
    "                    z=[val_endpoint1[2], val_endpoint2[2]],\n",
    "                    line=dict(color='black', width=6),\n",
    "                    name=f'LOR {lor_index} - Original LOR Line'\n",
    "                )\n",
    "                \n",
    "                # 4: 'Extension Path 1'\n",
    "                fig.data[static_traces_count + 4].update(\n",
    "                    x=[val_endpoint1[0], val_extended1[0]],\n",
    "                    y=[val_endpoint1[1], val_extended1[1]],\n",
    "                    z=[val_endpoint1[2], val_extended1[2]],\n",
    "                    line=dict(color=line_color_1, width=4, dash='dash')\n",
    "                )\n",
    "                \n",
    "                # 5: 'Extension Path 2'\n",
    "                fig.data[static_traces_count + 5].update(\n",
    "                    x=[val_endpoint2[0], val_extended2[0]],\n",
    "                    y=[val_endpoint2[1], val_extended2[1]],\n",
    "                    z=[val_endpoint2[2], val_extended2[2]],\n",
    "                    line=dict(color=line_color_1, width=4, dash='dash')\n",
    "                )\n",
    "                \n",
    "                # 6: 'Detector Assignment 1'\n",
    "                fig.data[static_traces_count + 6].update(\n",
    "                    x=[val_extended1[0], val_detector1_pos[0]],\n",
    "                    y=[val_extended1[1], val_detector1_pos[1]],\n",
    "                    z=[val_extended1[2], val_detector1_pos[2]],\n",
    "                    line=dict(color=line_color_2, width=4, dash='dot')\n",
    "                )\n",
    "                \n",
    "                # 7: 'Detector Assignment 2'\n",
    "                fig.data[static_traces_count + 7].update(\n",
    "                    x=[val_extended2[0], val_detector2_pos[0]],\n",
    "                    y=[val_extended2[1], val_detector2_pos[1]],\n",
    "                    z=[val_extended2[2], val_detector2_pos[2]],\n",
    "                    line=dict(color=line_color_2, width=4, dash='dot')\n",
    "                )\n",
    "                \n",
    "                # Update title\n",
    "                fig.layout.title.text = f'3D LOR Validation: LOR {lor_index} ({status_text})'\n",
    "                \n",
    "            else:\n",
    "                # Point cloud mode - only update original endpoints and line\n",
    "                # 0: 'LOR - Original Endpoints'\n",
    "                fig.data[static_traces_count + 0].update(\n",
    "                    x=[val_endpoint1[0], val_endpoint2[0]],\n",
    "                    y=[val_endpoint1[1], val_endpoint2[1]],\n",
    "                    z=[val_endpoint1[2], val_endpoint2[2]],\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color='orange',\n",
    "                        opacity=1.0,\n",
    "                        symbol='circle',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Original Endpoints',\n",
    "                    hovertemplate='<b>Original Endpoint</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # 1: 'LOR - Original Line'\n",
    "                fig.data[static_traces_count + 1].update(\n",
    "                    x=[val_endpoint1[0], val_endpoint2[0]],\n",
    "                    y=[val_endpoint1[1], val_endpoint2[1]],\n",
    "                    z=[val_endpoint1[2], val_endpoint2[2]],\n",
    "                    line=dict(color='black', width=6),\n",
    "                    name=f'LOR {lor_index} - Original LOR Line'\n",
    "                )\n",
    "                \n",
    "                # Update title for point cloud mode\n",
    "                fig.layout.title.text = f'3D LOR Point Cloud: LOR {lor_index}'\n",
    "    \n",
    "    # Set up the interactive slider\n",
    "    max_lor_index = coordinates_sample.shape[0] - 1\n",
    "    initial_lor_index = validate_lor_index if validate_lor_index is not None else 0\n",
    "    \n",
    "    slider = IntSlider(\n",
    "        value=initial_lor_index,\n",
    "        min=0,\n",
    "        max=max_lor_index,\n",
    "        step=1,\n",
    "        description='LOR Index:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nInteractive slider created for LOR indices 0-{max_lor_index}\")\n",
    "        if scanner_info is not None:\n",
    "            print(f\"Distance threshold: {distance_threshold} mm\")\n",
    "    \n",
    "    # Connect slider to update function\n",
    "    def on_slider_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            update_lor_visualization(change['new'])\n",
    "    \n",
    "    slider.observe(on_slider_change)\n",
    "    \n",
    "    # Initialize with the starting LOR\n",
    "    update_lor_visualization(initial_lor_index)\n",
    "    \n",
    "    # Display the widget and figure\n",
    "    display(VBox([slider, fig]))\n",
    "    \n",
    "    return full_detector_id_pairs, valid_detector_id_pairs, valid_lor_indices\n",
    "\n",
    "# full_detector_ids, valid_detector_ids, valid_indices = visualize_lors_and_detectors_3d(\n",
    "#                                                     filtered_coordinates.numpy(),\n",
    "#                                                     # info,\n",
    "#                                                     #  highlight_detector_ids=[0, 1, 5, 4370],\n",
    "#                                                      verbose=True,\n",
    "#                                                     #  verbose=False,\n",
    "#                                                     #  validate_lor_index=13,\n",
    "#                                                      distance_threshold=5.0,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1efda9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ProjectMeta and SystemMatrix classes for xyz LOR \n",
    "# PETLMProjMeta() # <--- Uncomment and crtl+left_click to compare with the custom class structure here \n",
    "\n",
    "class PETLORProjMeta():\n",
    "    \"\"\"Metadata for PET using direct LOR coordinates instead of detector IDs.\n",
    "    \n",
    "    Args:\n",
    "        lor_coords (torch.Tensor): N × 6 tensor containing LOR coordinates as [x1, y1, z1, x2, y2, z2]\n",
    "        tof_meta (PETTOFMeta | None, optional): PET time-of-flight metadata. Defaults to None.\n",
    "        weights (torch.tensor | None, optional): weights for scaling projections. Defaults to None.\n",
    "        lor_coords_sensitivity (torch.Tensor | None, optional): LOR coordinates for sensitivity computation. \n",
    "            If None, uses lor_coords. Defaults to None.\n",
    "        weights_sensitivity (torch.tensor | None, optional): weights for sensitivity computation. Defaults to None.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        lor_coords: torch.Tensor,  # Shape: (N, 6) - [x1,y1,z1,x2,y2,z2]\n",
    "        tof_meta = None,\n",
    "        weights: torch.tensor | None = None,\n",
    "        lor_coords_sensitivity: torch.Tensor | None = None,\n",
    "        weights_sensitivity: torch.tensor | None = None,\n",
    "    ):\n",
    "        self.shape = (lor_coords.shape[0],)\n",
    "        self.lor_coords = lor_coords.cpu()  # N × 6 tensor\n",
    "        \n",
    "        if lor_coords_sensitivity is not None:\n",
    "            self.lor_coords_sensitivity = lor_coords_sensitivity.cpu()\n",
    "        else:\n",
    "            self.lor_coords_sensitivity = None\n",
    "            \n",
    "        self.tof_meta = tof_meta\n",
    "        self.weights = weights\n",
    "        self.weights_sensitivity = weights_sensitivity\n",
    "        \n",
    "        # For compatibility - these won't be used but may be referenced\n",
    "        self.detector_ids = None\n",
    "        self.detector_ids_sensitivity = None\n",
    "        self.scanner_lut = None\n",
    "        self.info = None\n",
    "\n",
    "from pytomography.transforms import Transform\n",
    "from pytomography.projectors import SystemMatrix\n",
    "import parallelproj\n",
    "\n",
    "# PETLMSystemMatrix() # <--- Uncomment and crtl+left_click to compare with the custom class structure here \n",
    "\n",
    "class PETLORSystemMatrix(SystemMatrix):\n",
    "    \"\"\"System matrix for PET using direct LOR coordinates instead of detector IDs.\n",
    "    \n",
    "    Args:\n",
    "        object_meta (ObjectMeta): Metadata of object space\n",
    "        proj_meta (PETLORProjMeta): PET LOR projection space metadata\n",
    "        obj2obj_transforms (list[Transform]): Object space transforms. Defaults to [].\n",
    "        attenuation_map (torch.tensor | None): Attenuation map. Defaults to None.\n",
    "        scale_projection_by_sensitivity (bool): Scale projections by sensitivity. Defaults to False.\n",
    "        N_splits (int): Number of splits for memory management. Defaults to 1.\n",
    "        FOV_scale_enabled (bool): Enable FOV scaling. Defaults to True.\n",
    "        device (str): Output device. Defaults to pytomography.device.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        object_meta: ObjectMeta,\n",
    "        proj_meta,  # PETLORProjMeta\n",
    "        obj2obj_transforms: list[Transform] = [],\n",
    "        attenuation_map: torch.tensor | None = None,\n",
    "        scale_projection_by_sensitivity: bool = False,\n",
    "        N_splits: int = 1,\n",
    "        FOV_scale_enabled: bool = True,\n",
    "        device: str = pytomography.device,\n",
    "    ) -> None:\n",
    "        super(PETLORSystemMatrix, self).__init__(\n",
    "            obj2obj_transforms=obj2obj_transforms,\n",
    "            proj2proj_transforms=[],\n",
    "            object_meta=object_meta,\n",
    "            proj_meta=proj_meta\n",
    "        )\n",
    "        self.output_device = device\n",
    "        self.TOF = proj_meta.tof_meta is not None\n",
    "        self.object_origin = (- np.array(object_meta.shape) / 2 + 0.5) * (np.array(object_meta.dr))\n",
    "        self.obj2obj_transforms = obj2obj_transforms\n",
    "        self.attenuation_map = attenuation_map\n",
    "        self.N_splits = N_splits\n",
    "        self.scale_projection_by_sensitivity = scale_projection_by_sensitivity\n",
    "        self.FOV_scale_enabled = FOV_scale_enabled\n",
    "        \n",
    "        # Compute normalization factor\n",
    "        self.norm_BP = self._backward_full()\n",
    "        self.norm_BP[self.norm_BP < 1e-7] = 1e7\n",
    "\n",
    "    def _get_lor_coordinates(self, lor_coords_tensor, subset_indices=None):\n",
    "        \"\"\"Extract start and end coordinates from LOR tensor.\"\"\"\n",
    "        if subset_indices is not None:\n",
    "            lor_subset = lor_coords_tensor[subset_indices]\n",
    "        else:\n",
    "            lor_subset = lor_coords_tensor\n",
    "            \n",
    "        xstart = lor_subset[:, :3]  # [x1, y1, z1]\n",
    "        xend = lor_subset[:, 3:]    # [x2, y2, z2]\n",
    "        return xstart, xend\n",
    "\n",
    "    def _compute_attenuation_probability_projection(self, lor_coords: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"Computes attenuation probabilities along LORs.\"\"\"\n",
    "        proj = torch.tensor([]).cpu()\n",
    "        \n",
    "        for lor_coords_partial in torch.tensor_split(lor_coords, self.N_splits):\n",
    "            xstart, xend = self._get_lor_coordinates(lor_coords_partial)\n",
    "            \n",
    "            proj_i = torch.exp(-parallelproj.joseph3d_fwd(\n",
    "                xstart.to(pytomography.device),\n",
    "                xend.to(pytomography.device),\n",
    "                self.attenuation_map,\n",
    "                self.object_origin,\n",
    "                self.object_meta.dr,\n",
    "                num_chunks=4)).cpu()\n",
    "            proj = torch.concatenate([proj, proj_i])\n",
    "        return proj.to(self.output_device)\n",
    "\n",
    "    def _compute_sensitivity_projection(self, all_lors: bool = True) -> torch.Tensor:\n",
    "        \"\"\"Computes sensitivity projection for normalization.\"\"\"\n",
    "        if all_lors and self.proj_meta.lor_coords_sensitivity is not None:\n",
    "            lor_coords = self.proj_meta.lor_coords_sensitivity\n",
    "            weights = self.proj_meta.weights_sensitivity\n",
    "        else:\n",
    "            lor_coords = self.proj_meta.lor_coords\n",
    "            weights = self.proj_meta.weights\n",
    "\n",
    "        proj = torch.ones(lor_coords.shape[0])\n",
    "        \n",
    "        if weights is not None:\n",
    "            proj *= weights.cpu()\n",
    "            \n",
    "        if self.attenuation_map is not None:\n",
    "            proj *= self._compute_attenuation_probability_projection(lor_coords).cpu()\n",
    "            \n",
    "        return proj\n",
    "\n",
    "    def _backward_full(self, N_splits: int = 20):\n",
    "        \"\"\"Computes full back projection for normalization.\"\"\"\n",
    "        proj = self._compute_sensitivity_projection()\n",
    "        \n",
    "        # Use sensitivity LORs if available, otherwise use regular LORs\n",
    "        if self.proj_meta.lor_coords_sensitivity is not None:\n",
    "            lor_coords = self.proj_meta.lor_coords_sensitivity\n",
    "        else:\n",
    "            lor_coords = self.proj_meta.lor_coords\n",
    "\n",
    "        norm_BP = 0\n",
    "        for proj_subset, lor_coords_subset in zip(\n",
    "            torch.tensor_split(proj, N_splits), \n",
    "            torch.tensor_split(lor_coords, N_splits)\n",
    "        ):\n",
    "            xstart, xend = self._get_lor_coordinates(lor_coords_subset)\n",
    "            \n",
    "            norm_BP += parallelproj.joseph3d_back(\n",
    "                xstart.to(pytomography.device),\n",
    "                xend.to(pytomography.device),\n",
    "                self.object_meta.shape,\n",
    "                self.object_origin,\n",
    "                self.object_meta.dr,\n",
    "                proj_subset.to(pytomography.device) + pytomography.delta,\n",
    "                num_chunks=4)\n",
    "                \n",
    "        # Apply object transforms\n",
    "        for transform in self.obj2obj_transforms[::-1]:\n",
    "            norm_BP = transform.backward(norm_BP)\n",
    "        return norm_BP.cpu()\n",
    "\n",
    "    def set_n_subsets(self, n_subsets: int) -> list:\n",
    "        \"\"\"Sets up subset indices for ordered subsets algorithms.\"\"\"\n",
    "        indices = torch.arange(self.proj_meta.lor_coords.shape[0]).to(torch.long).cpu()\n",
    "        subset_indices_array = []\n",
    "        for i in range(n_subsets):\n",
    "            subset_indices_array.append(indices[i::n_subsets])\n",
    "        self.subset_indices_array = subset_indices_array\n",
    "\n",
    "    def get_projection_subset(self, projections: torch.Tensor, subset_idx: int) -> torch.tensor:\n",
    "        \"\"\"Gets projection subset for ordered subsets.\"\"\"\n",
    "        if (projections.shape[0] > 1) and (subset_idx is not None):\n",
    "            subset_indices = self.subset_indices_array[subset_idx]\n",
    "            proj_subset = projections[subset_indices]\n",
    "        else:\n",
    "            proj_subset = projections\n",
    "        return proj_subset\n",
    "\n",
    "    def get_weighting_subset(self, subset_idx: int) -> float:\n",
    "        \"\"\"Gets relative weighting for subset.\"\"\"\n",
    "        if subset_idx is None:\n",
    "            return 1\n",
    "        else:\n",
    "            return len(self.subset_indices_array[subset_idx]) / self.proj_meta.lor_coords.shape[0]\n",
    "\n",
    "    def compute_normalization_factor(self, subset_idx: int | None = None) -> torch.tensor:\n",
    "        \"\"\"Computes normalization factor for reconstruction.\"\"\"\n",
    "        if subset_idx is None:\n",
    "            fraction_considered = 1\n",
    "        else:\n",
    "            fraction_considered = (self.subset_indices_array[subset_idx].shape[0] / \n",
    "                                 self.proj_meta.lor_coords.shape[0])\n",
    "        return fraction_considered * self.norm_BP.to(self.output_device)\n",
    "\n",
    "    def forward(self, object: torch.tensor, subset_idx: int = None) -> torch.tensor:\n",
    "        \"\"\"Forward projection using direct LOR coordinates.\n",
    "        \n",
    "        Each LOR just gets an associated line-attenuation,\n",
    "        which is the sum of the attenuations of all voxels along its path,\n",
    "        weighted by how much of the line is actually inside that voxel\n",
    "        i.e. the actual length of line inside the voxel, times that voxels attenuation, summed along the entire LOR\n",
    "        Outputs a 1D array, with one element for every LOR, which is the line integral described here.\n",
    "        \n",
    "        \"\"\"\n",
    "        # Get LOR coordinates (subset if specified)\n",
    "        if subset_idx is not None:\n",
    "            subset_indices = self.subset_indices_array[subset_idx].cpu()\n",
    "            lor_coords = self.proj_meta.lor_coords[subset_indices]\n",
    "        else:\n",
    "            lor_coords = self.proj_meta.lor_coords\n",
    "\n",
    "        # Apply object space transforms\n",
    "        object = object.to(pytomography.device)\n",
    "        for transform in self.obj2obj_transforms:\n",
    "            object = transform.forward(object)\n",
    "\n",
    "        # Project using LOR coordinates\n",
    "        proj = torch.tensor([]).cpu()\n",
    "        for lor_coords_partial in torch.tensor_split(lor_coords, self.N_splits):\n",
    "            xstart, xend = self._get_lor_coordinates(lor_coords_partial)\n",
    "            \n",
    "            if self.TOF:\n",
    "                # TOF version would need TOF bin information added to lor_coords\n",
    "                # This is more complex and would require extending the coordinate format\n",
    "                raise NotImplementedError(\"TOF not yet implemented for direct LOR coordinates\")\n",
    "            else:\n",
    "                proj_i = parallelproj.joseph3d_fwd(\n",
    "                    xstart.to(pytomography.device),\n",
    "                    xend.to(pytomography.device),\n",
    "                    object,\n",
    "                    self.object_origin,\n",
    "                    self.object_meta.dr\n",
    "                )\n",
    "            proj = torch.concatenate([proj, proj_i.cpu()])\n",
    "\n",
    "        if self.scale_projection_by_sensitivity:\n",
    "            if self.proj_meta.weights is None:\n",
    "                raise Exception('If scaling by sensitivity, then `weights` must be provided')\n",
    "            else:\n",
    "                proj = proj * self.get_projection_subset(self.proj_meta.weights, subset_idx).to(proj.device)\n",
    "                \n",
    "        return proj.to(self.output_device)\n",
    "\n",
    "    def backward(self, proj: torch.tensor, subset_idx: int = None, \n",
    "                return_norm_constant: bool = False) -> torch.tensor:\n",
    "        \"\"\"Back projection using direct LOR coordinates.\"\"\"\n",
    "        # Get LOR coordinates (subset if specified)\n",
    "        if subset_idx is not None:\n",
    "            subset_indices = self.subset_indices_array[subset_idx].cpu()\n",
    "            lor_coords = self.proj_meta.lor_coords[subset_indices]\n",
    "        else:\n",
    "            lor_coords = self.proj_meta.lor_coords\n",
    "\n",
    "        # Apply sensitivity scaling if needed\n",
    "        if self.scale_projection_by_sensitivity:\n",
    "            if self.proj_meta.weights is None:\n",
    "                raise Exception('If scaling by sensitivity, then `weights` must be provided')\n",
    "            else:\n",
    "                proj = proj * self.get_projection_subset(self.proj_meta.weights, subset_idx).to(proj.device)\n",
    "\n",
    "        BP = 0\n",
    "        for proj_i, lor_coords_partial in zip(\n",
    "            torch.tensor_split(proj, self.N_splits), \n",
    "            torch.tensor_split(lor_coords, self.N_splits)\n",
    "        ):\n",
    "            proj_i = proj_i.to(pytomography.device)\n",
    "            xstart, xend = self._get_lor_coordinates(lor_coords_partial)\n",
    "            \n",
    "            if self.TOF:\n",
    "                raise NotImplementedError(\"TOF not yet implemented for direct LOR coordinates\")\n",
    "            else:\n",
    "                BP += parallelproj.joseph3d_back(\n",
    "                    xstart.to(pytomography.device),\n",
    "                    xend.to(pytomography.device),\n",
    "                    self.object_meta.shape,\n",
    "                    self.object_origin,\n",
    "                    self.object_meta.dr,\n",
    "                    proj_i\n",
    "                )\n",
    "\n",
    "        # Apply object transforms\n",
    "        norm_constant = self.compute_normalization_factor(subset_idx)\n",
    "        for transform in self.obj2obj_transforms[::-1]:\n",
    "            if return_norm_constant:\n",
    "                BP, norm_constant = transform.backward(BP, norm_constant=norm_constant)\n",
    "            else:\n",
    "                BP = transform.backward(BP)\n",
    "\n",
    "        if return_norm_constant:\n",
    "            return BP.to(self.output_device), norm_constant.to(self.output_device)\n",
    "        else:\n",
    "            return BP.to(self.output_device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7f72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or Create attenuation maps\n",
    "\n",
    "# atten_map = gate.get_aligned_attenuation_map(os.path.join(path, 'gate_simulation/simple_phantom/umap_mMR_brainSimplePhantom.hv'), object_meta).to(pytomography.device)\n",
    "\n",
    "zeros_atten_map = torch.zeros(voxel_space)\n",
    "\n",
    "# create a half-rectangular attenuation map\n",
    "half_rect_atten_map = torch.zeros(voxel_space)\n",
    "mid_x = voxel_space[0] // 2\n",
    "half_rect_atten_map[:mid_x, :, :] = torch.linspace(0, 0.1, mid_x).view(-1, 1, 1)\n",
    "\n",
    "# Create a gradient attenuation map\n",
    "coords = torch.stack(torch.meshgrid(\n",
    "    torch.arange(voxel_space[0]),\n",
    "    torch.arange(voxel_space[1]),\n",
    "    torch.arange(voxel_space[2]),\n",
    "    indexing='ij'\n",
    "), dim=-1).float()\n",
    "gradient_atten_map = coords.mean(dim=-1)\n",
    "gradient_atten_map = gradient_atten_map / gradient_atten_map.max()\n",
    "\n",
    "# Create a cylindrical attenuation map with radial gradient\n",
    "radius_mm = 278  # cylinder radius in mm\n",
    "height = voxel_space[2] * voxel_size  # cylinder height in mm\n",
    "center_x = voxel_space[0] // 2\n",
    "center_y = voxel_space[1] // 2\n",
    "center_z = voxel_space[2] // 2\n",
    "radius_vox = radius_mm / voxel_size\n",
    "\n",
    "# Generate grid of voxel indices\n",
    "x = torch.arange(voxel_space[0]).float()\n",
    "y = torch.arange(voxel_space[1]).float()\n",
    "z = torch.arange(voxel_space[2]).float()\n",
    "xx, yy, zz = torch.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "# Compute distance from central axis for each voxel\n",
    "dist_from_axis = torch.sqrt((xx - center_x)**2 + (yy - center_y)**2)\n",
    "\n",
    "# Create gradient cylinder attenuation map\n",
    "gradient_cylindrical_atten_map = torch.ones(voxel_space)\n",
    "normalized_dist = dist_from_axis / radius_vox  # Normalize distances to [0,1]\n",
    "\n",
    "# Create radial gradient: high attenuation (1.0) at center, decreasing outward\n",
    "gradient_cylindrical_atten_map = 1.0 - normalized_dist.clone()  # Invert the gradient\n",
    "gradient_cylindrical_atten_map[gradient_cylindrical_atten_map < 0] = 0  # Clip negative values\n",
    "gradient_cylindrical_atten_map[dist_from_axis > radius_vox] = 0  # Set outside cylinder to 0\n",
    "gradient_cylindrical_atten_map /= 100\n",
    "\n",
    "# Also create a solid cylinder for comparison\n",
    "cylindrical_atten_map = torch.zeros(voxel_space)\n",
    "cylindrical_atten_map[dist_from_axis <= radius_vox] = 0.14/ (voxel_size/10) # 0.14  cm⁻¹ is the attenuation for dense bone apparently\n",
    "\n",
    "\n",
    "# Create a spherical attenuation map centered at origin\n",
    "def create_spherical_atten_map(voxel_space, voxel_size, radius_mm=None, atten_value=0.1):\n",
    "    \"\"\"\n",
    "    Create a spherical attenuation map centered at the midpoint of voxel space.\n",
    "    \n",
    "    Args:\n",
    "        voxel_space: tuple (x, y, z) dimensions of the voxel grid\n",
    "        voxel_size: size of each voxel in mm\n",
    "        radius_mm: sphere radius in mm. If None, defaults to 1/4 of smallest axis\n",
    "        atten_value: attenuation value inside the sphere (default 0.1)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: spherical attenuation map with shape voxel_space\n",
    "    \"\"\"\n",
    "    # Calculate default radius if not specified\n",
    "    if radius_mm is None:\n",
    "        min_axis_mm = min(voxel_space) * voxel_size\n",
    "        radius_mm = min_axis_mm / 4\n",
    "    \n",
    "    # Convert radius to voxel units\n",
    "    radius_vox = radius_mm / voxel_size\n",
    "    \n",
    "    # Calculate center coordinates\n",
    "    center_x = voxel_space[0] // 2\n",
    "    center_y = voxel_space[1] // 2\n",
    "    center_z = voxel_space[2] // 2\n",
    "    \n",
    "    # Generate grid of voxel indices\n",
    "    x = torch.arange(voxel_space[0]).float()\n",
    "    y = torch.arange(voxel_space[1]).float()\n",
    "    z = torch.arange(voxel_space[2]).float()\n",
    "    xx, yy, zz = torch.meshgrid(x, y, z, indexing='ij')\n",
    "    \n",
    "    # Compute distance from center for each voxel\n",
    "    dist_from_center = torch.sqrt((xx - center_x)**2 + (yy - center_y)**2 + (zz - center_z)**2)\n",
    "    \n",
    "    # Create spherical attenuation map\n",
    "    spherical_atten_map = torch.zeros(voxel_space)\n",
    "    spherical_atten_map[dist_from_center <= radius_vox] = atten_value\n",
    "    \n",
    "    return spherical_atten_map\n",
    "\n",
    "# Usage example with your existing variables:\n",
    "spherical_atten_map = create_spherical_atten_map(voxel_space, voxel_size, atten_value=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89871c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual to confirm attention map\n",
    "# visualize_voxel_tensor_3d(cylindrical_atten_map.cpu().numpy(),\n",
    "#                            initial_min_threshold=0.0, initial_max_threshold=1.0,\n",
    "#                            voxel_size_mm=voxel_size,\n",
    "#                            min_threshold=0.00005, max_threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39c5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# atten_map = half_rect_atten_map.to(pytomography.device)\n",
    "# atten_map = gradient_atten_map.to(pytomography.device)\n",
    "# atten_map = cylindrical_atten_map.to(pytomography.device)\n",
    "# atten_map = gradient_cylindrical_atten_map.to(pytomography.device)\n",
    "atten_map = zeros_atten_map.to(pytomography.device)\n",
    "# atten_map = spherical_atten_map.to(pytomography.device)\n",
    "# atten_map = None\n",
    "\n",
    "# Create PSF transform\n",
    "psf_transform = GaussianFilter(3.) # 3mm gaussian blurring\n",
    "\n",
    "# Create object metadata (same as before)\n",
    "object_meta = ObjectMeta(\n",
    "    shape=voxel_tensor.shape,  # Your image dimensions\n",
    "    dr=(voxel_size, voxel_size, voxel_size),    # Voxel sizes in mm\n",
    ")\n",
    "\n",
    "# Create projection metadata\n",
    "proj_meta = PETLORProjMeta(\n",
    "    lor_coords=filtered_coordinates,\n",
    "    weights=None,  # Optional: weights for detected events\n",
    "    lor_coords_sensitivity=None,  # Optional: different LORs for sensitivity\n",
    "    weights_sensitivity=None,  # Optional: sensitivity weights\n",
    ")\n",
    "\n",
    "# Create system matrix\n",
    "system_matrix = PETLORSystemMatrix(\n",
    "    object_meta=object_meta,\n",
    "    proj_meta=proj_meta,\n",
    "    obj2obj_transforms=[psf_transform],  # Optional transforms\n",
    "    attenuation_map=atten_map,\n",
    "    N_splits=1,   # Memory management\n",
    ")\n",
    "\n",
    "initial_image = torch.ones(object_meta.shape)\n",
    "\n",
    "# Forward projection\n",
    "projections = system_matrix.forward(initial_image)\n",
    "\n",
    "# Back projection\n",
    "back_projected = system_matrix.backward(projections)\n",
    "\n",
    "print(f\"Input image shape: {initial_image.shape}\")\n",
    "print(f\"Projections shape: {projections.shape}\")\n",
    "print(f\"Back projected shape: {back_projected.shape}\")\n",
    "\n",
    "plot_cross_sections_interactive(back_projected.cpu().numpy())\n",
    "print(back_projected.cpu().numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5a1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(projections.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c83ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recon\n",
    "likelihood = PoissonLogLikelihood(\n",
    "        system_matrix,\n",
    "        # projections, # For listmode reconstruction, projections don't need to be provided, since all detection events are stored in proj_meta\n",
    "        # additive_term = additive_term # NO ADDITIVE TERM YET, NO SCATTER ESTIMATION\n",
    "    )\n",
    "\n",
    "recon_algorithm = OSEM(likelihood)\n",
    "# recon_algorithm = OSEM(likelihood, object_initial=torch.tensor(back_projected.cpu().numpy().copy()))\n",
    "recon_without_scatter_estimation = recon_algorithm(n_iters=140, n_subsets=1)\n",
    "\n",
    "plot_cross_sections_interactive(recon_without_scatter_estimation.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f37b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recon_without_scatter_estimation.cpu().numpy().mean())\n",
    "print(back_projected.cpu().numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c44498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom functions for LOR coordinate based sampling and smoothing\n",
    "\n",
    "def sample_3d_volume_at_points(\n",
    "    volume: torch.Tensor,\n",
    "    points: torch.Tensor,\n",
    "    grid_bounds: tuple = None,\n",
    "    mode: str = 'bilinear',\n",
    "    padding_mode: str = 'zeros'\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Sample a 3D volume at arbitrary 3D points using trilinear interpolation.\n",
    "    \n",
    "    Args:\n",
    "        volume (torch.Tensor): 3D volume with shape (nx, ny, nz)\n",
    "        points (torch.Tensor): Points to sample at, shape (n_points, 3) as [x, y, z] coordinates\n",
    "        grid_bounds (tuple, optional): ((x_min, x_max), (y_min, y_max), (z_min, z_max)) in mm.\n",
    "                                     If None, inferred from volume shape assuming unit spacing.\n",
    "        mode (str, optional): Interpolation mode. Defaults to 'bilinear' (trilinear in 3D).\n",
    "        padding_mode (str, optional): Padding mode for out-of-bounds. Defaults to 'zeros'.\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Sampled values at each point, shape (n_points,)\n",
    "    \"\"\"\n",
    "    device = volume.device\n",
    "    points = points.to(device)\n",
    "    \n",
    "    # Get volume dimensions\n",
    "    nx, ny, nz = volume.shape\n",
    "    \n",
    "    # Set default grid bounds if not provided\n",
    "    if grid_bounds is None:\n",
    "        # Assume unit spacing centered around origin\n",
    "        grid_bounds = (\n",
    "            (-nx/2, nx/2),\n",
    "            (-ny/2, ny/2), \n",
    "            (-nz/2, nz/2)\n",
    "        )\n",
    "    \n",
    "    (x_min, x_max), (y_min, y_max), (z_min, z_max) = grid_bounds\n",
    "    \n",
    "    # Convert physical coordinates to normalized grid coordinates [-1, 1]\n",
    "    # PyTorch's grid_sample expects coordinates in [-1, 1] range\n",
    "    x_norm = 2 * (points[:, 0] - x_min) / (x_max - x_min) - 1\n",
    "    y_norm = 2 * (points[:, 1] - y_min) / (y_max - y_min) - 1\n",
    "    z_norm = 2 * (points[:, 2] - z_min) / (z_max - z_min) - 1\n",
    "    \n",
    "    # Stack normalized coordinates - PyTorch expects [batch, depth, height, width, 3]\n",
    "    # For 3D, grid should be [N, D, H, W, 3] where last dim is [x, y, z]\n",
    "    grid_coords = torch.stack([x_norm, y_norm, z_norm], dim=-1)  # Shape: (n_points, 3)\n",
    "    \n",
    "    # Reshape for grid_sample: need [1, n_points, 1, 1, 3]\n",
    "    grid_coords = grid_coords.unsqueeze(0).unsqueeze(2).unsqueeze(2)  # [1, n_points, 1, 1, 3]\n",
    "    \n",
    "    # Add batch dimension to volume: [1, 1, nx, ny, nz]\n",
    "    volume_batched = volume.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Sample using trilinear interpolation\n",
    "    sampled = torch.nn.functional.grid_sample(\n",
    "        volume_batched,\n",
    "        grid_coords,\n",
    "        mode=mode,\n",
    "        padding_mode=padding_mode,\n",
    "        align_corners=True\n",
    "    )\n",
    "    \n",
    "    # Remove batch dimensions and reshape to (n_points,)\n",
    "    sampled = sampled.squeeze(0).squeeze(0).squeeze(-1).squeeze(-1)  # [n_points]\n",
    "    \n",
    "    return sampled\n",
    "\n",
    "\n",
    "def get_smoothed_lor_values(\n",
    "    smoothed_volume: torch.Tensor,\n",
    "    lor_coords: torch.Tensor,\n",
    "    grid_bounds: tuple = None\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Convert smoothed 3D volume back to per-LOR values by sampling at LOR midpoints.\n",
    "    \n",
    "    Args:\n",
    "        smoothed_volume (torch.Tensor): 3D smoothed volume, shape (nx, ny, nz)\n",
    "        lor_coords (torch.Tensor): LOR coordinates, shape (n_lors, 6) as [x1,y1,z1,x2,y2,z2]\n",
    "        grid_bounds (tuple, optional): Grid bounds used when creating the smoothed volume\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Smoothed values per LOR, shape (n_lors,)\n",
    "    \"\"\"\n",
    "    # Calculate LOR midpoints\n",
    "    midpoints = (lor_coords[:, :3] + lor_coords[:, 3:]) / 2\n",
    "    \n",
    "    # Sample the smoothed volume at midpoint locations\n",
    "    smoothed_lor_values = sample_3d_volume_at_points(\n",
    "        smoothed_volume,\n",
    "        midpoints,\n",
    "        grid_bounds=grid_bounds\n",
    "    )\n",
    "    \n",
    "    return smoothed_lor_values\n",
    "\n",
    "@torch.no_grad()\n",
    "def smooth_randoms_coordinates(\n",
    "    lor_coordinates: torch.Tensor,\n",
    "    weights: torch.Tensor = None,\n",
    "    bandwidth: float = 10.0,\n",
    "    adaptive: bool = True,\n",
    "    query_points: torch.Tensor = None,\n",
    "    grid_resolution: tuple = (64, 64, 32),\n",
    "    normalization: bool = False\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Smooths PET randoms using kernel density estimation directly on LOR coordinates\n",
    "    \n",
    "    Args:\n",
    "        lor_coordinates (torch.Tensor): LOR coordinates shaped (pairs, 6) as [x1,y1,z1,x2,y2,z2] in mm\n",
    "        weights (torch.Tensor, optional): Weights for each LOR. Defaults to uniform.\n",
    "        bandwidth (float, optional): Base smoothing bandwidth in mm. Defaults to 10.0.\n",
    "        adaptive (bool, optional): Use adaptive bandwidth based on local density. Defaults to True.\n",
    "        query_points (torch.Tensor, optional): Specific points to evaluate. If None, creates regular grid.\n",
    "        grid_resolution (tuple, optional): Grid resolution (nx, ny, nz) for output. Defaults to (64, 64, 32).\n",
    "        normalization (bool, optional): Apply symmetric normalization. Defaults to False.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Smoothed randoms estimate at query points or regular grid\n",
    "    \"\"\"\n",
    "    device = lor_coordinates.device\n",
    "    n_lors = lor_coordinates.shape[0]\n",
    "    \n",
    "    # Use uniform weights if not provided\n",
    "    if weights is None:\n",
    "        weights = torch.ones(n_lors, device=device)\n",
    "    \n",
    "    # Calculate LOR midpoints (representative spatial location)\n",
    "    p1 = lor_coordinates[:, :3]  # [x1, y1, z1]\n",
    "    p2 = lor_coordinates[:, 3:]  # [x2, y2, z2]\n",
    "    midpoints = (p1 + p2) / 2\n",
    "    \n",
    "    # Create query points if not provided\n",
    "    if query_points is None:\n",
    "        # Create regular grid covering the data extent with some padding\n",
    "        mins = midpoints.min(dim=0)[0] - bandwidth * 2\n",
    "        maxs = midpoints.max(dim=0)[0] + bandwidth * 2\n",
    "        \n",
    "        x_grid = torch.linspace(mins[0], maxs[0], grid_resolution[0], device=device)\n",
    "        y_grid = torch.linspace(mins[1], maxs[1], grid_resolution[1], device=device)\n",
    "        z_grid = torch.linspace(mins[2], maxs[2], grid_resolution[2], device=device)\n",
    "        \n",
    "        # Create meshgrid and flatten to query points\n",
    "        X, Y, Z = torch.meshgrid(x_grid, y_grid, z_grid, indexing='ij')\n",
    "        query_points = torch.stack([X.flatten(), Y.flatten(), Z.flatten()], dim=1)\n",
    "        output_shape = grid_resolution\n",
    "    else:\n",
    "        output_shape = (query_points.shape[0],)\n",
    "    \n",
    "    # Calculate adaptive bandwidth if requested\n",
    "    if adaptive:\n",
    "        # Estimate local density using k-nearest neighbors\n",
    "        k = min(20, n_lors // 10)  # adaptive k based on data size\n",
    "        \n",
    "        # Batch processing for memory efficiency\n",
    "        batch_size = min(1000, n_lors)\n",
    "        local_bandwidths = torch.zeros(n_lors, device=device)\n",
    "        \n",
    "        for i in range(0, n_lors, batch_size):\n",
    "            batch_end = min(i + batch_size, n_lors)\n",
    "            batch_points = midpoints[i:batch_end]\n",
    "            \n",
    "            # Calculate distances to all other points\n",
    "            distances = torch.cdist(batch_points, midpoints)\n",
    "            \n",
    "            # Get k-th nearest neighbor distance\n",
    "            kth_distances = torch.kthvalue(distances, k + 1, dim=1)[0]  # +1 to exclude self\n",
    "            \n",
    "            # Adaptive bandwidth: smaller where density is higher\n",
    "            local_bandwidths[i:batch_end] = bandwidth * (kth_distances / kth_distances.median())\n",
    "    else:\n",
    "        local_bandwidths = torch.full((n_lors,), bandwidth, device=device)\n",
    "    \n",
    "    # Kernel density estimation\n",
    "    n_query = query_points.shape[0]\n",
    "    density = torch.zeros(n_query, device=device)\n",
    "    \n",
    "    # Process in batches to manage memory\n",
    "    query_batch_size = min(1000, n_query)\n",
    "    lor_batch_size = min(1000, n_lors)\n",
    "    \n",
    "    for q_start in range(0, n_query, query_batch_size):\n",
    "        q_end = min(q_start + query_batch_size, n_query)\n",
    "        query_batch = query_points[q_start:q_end]\n",
    "        batch_density = torch.zeros(q_end - q_start, device=device)\n",
    "        \n",
    "        for l_start in range(0, n_lors, lor_batch_size):\n",
    "            l_end = min(l_start + lor_batch_size, n_lors)\n",
    "            lor_batch = midpoints[l_start:l_end]\n",
    "            weight_batch = weights[l_start:l_end]\n",
    "            bandwidth_batch = local_bandwidths[l_start:l_end]\n",
    "            \n",
    "            # Calculate squared distances\n",
    "            dist_sq = torch.cdist(query_batch, lor_batch).pow(2)\n",
    "            \n",
    "            # Gaussian kernel with adaptive bandwidth\n",
    "            # K(x) = exp(-0.5 * (dist/bandwidth)^2) / (bandwidth^3 * (2π)^(3/2))\n",
    "            bandwidth_batch_sq = bandwidth_batch.pow(2)\n",
    "            gaussian_weights = torch.exp(-0.5 * dist_sq / bandwidth_batch_sq.unsqueeze(0))\n",
    "            \n",
    "            # Normalize by bandwidth cubed for 3D\n",
    "            normalization_factor = 1.0 / (bandwidth_batch.pow(3) * (2 * torch.pi) ** 1.5)\n",
    "            gaussian_weights = gaussian_weights * normalization_factor.unsqueeze(0)\n",
    "            \n",
    "            # Apply LOR weights and sum\n",
    "            weighted_gaussian = gaussian_weights * weight_batch.unsqueeze(0)\n",
    "            batch_density += weighted_gaussian.sum(dim=1)\n",
    "        \n",
    "        density[q_start:q_end] = batch_density\n",
    "    \n",
    "    # Handle normalization (symmetric estimation)\n",
    "    if normalization:\n",
    "        # For normalization, we'd typically want symmetric treatment\n",
    "        # This could involve flipping coordinates or other geometry-specific operations\n",
    "        # Since we don't have scanner-specific geometry, we'll apply a simple symmetric approach\n",
    "        \n",
    "        # Flip coordinates through origin and repeat estimation\n",
    "        flipped_midpoints = -midpoints\n",
    "        \n",
    "        density_flipped = torch.zeros(n_query, device=device)\n",
    "        \n",
    "        for q_start in range(0, n_query, query_batch_size):\n",
    "            q_end = min(q_start + query_batch_size, n_query)\n",
    "            query_batch = query_points[q_start:q_end]\n",
    "            batch_density = torch.zeros(q_end - q_start, device=device)\n",
    "            \n",
    "            for l_start in range(0, n_lors, lor_batch_size):\n",
    "                l_end = min(l_start + lor_batch_size, n_lors)\n",
    "                lor_batch = flipped_midpoints[l_start:l_end]\n",
    "                weight_batch = weights[l_start:l_end]\n",
    "                bandwidth_batch = local_bandwidths[l_start:l_end]\n",
    "                \n",
    "                dist_sq = torch.cdist(query_batch, lor_batch).pow(2)\n",
    "                bandwidth_batch_sq = bandwidth_batch.pow(2)\n",
    "                gaussian_weights = torch.exp(-0.5 * dist_sq / bandwidth_batch_sq.unsqueeze(0))\n",
    "                normalization_factor = 1.0 / (bandwidth_batch.pow(3) * (2 * torch.pi) ** 1.5)\n",
    "                gaussian_weights = gaussian_weights * normalization_factor.unsqueeze(0)\n",
    "                weighted_gaussian = gaussian_weights * weight_batch.unsqueeze(0)\n",
    "                batch_density += weighted_gaussian.sum(dim=1)\n",
    "            \n",
    "            density_flipped[q_start:q_end] = batch_density\n",
    "        \n",
    "        density = (density + density_flipped) / 2\n",
    "    \n",
    "    # Reshape to output format\n",
    "    if len(output_shape) > 1:\n",
    "        density = density.reshape(output_shape)\n",
    "    \n",
    "    return density\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8168a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gaussian blurred midpoint cloud (without scatter term)\n",
    "sinogram_delays = smooth_randoms_coordinates(filtered_coordinates, weights=None, bandwidth=10.0, adaptive=True, grid_resolution=voxel_space)\n",
    "\n",
    "# Get additive term (without scatter term)\n",
    "lm_sensitivity = system_matrix._compute_sensitivity_projection()\n",
    "\n",
    "print(f\"LM sensitivity shape: {lm_sensitivity.shape}\")\n",
    "print(f\"Smoothed LM shape, called sinogram delays: {sinogram_delays.shape}\")\n",
    "\n",
    "# Get the grid bounds that were used to create the smoothed volume\n",
    "# This should match what was used in smooth_randoms_coordinates\n",
    "lor_coords = proj_meta.lor_coords\n",
    "midpoints = (lor_coords[:, :3] + lor_coords[:, 3:]) / 2\n",
    "bandwidth = 10.0  # Same as used in smoothing\n",
    "\n",
    "mins = midpoints.min(dim=0)[0] - bandwidth * 2\n",
    "maxs = midpoints.max(dim=0)[0] + bandwidth * 2\n",
    "grid_bounds = (\n",
    "    (mins[0].item(), maxs[0].item()),\n",
    "    (mins[1].item(), maxs[1].item()),\n",
    "    (mins[2].item(), maxs[2].item())\n",
    ")\n",
    "\n",
    "print(f\"Grid bounds: {grid_bounds}\")\n",
    "\n",
    "# Sample the smoothed volume at LOR midpoint locations\n",
    "lm_delays = get_smoothed_lor_values(\n",
    "    sinogram_delays, # smoothed volume \n",
    "    lor_coords, \n",
    "    grid_bounds=grid_bounds\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba89dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from typing import Tuple, Optional\n",
    "import parallelproj\n",
    "\n",
    "def get_lor_scatter_estimate(\n",
    "    object_meta,  # ObjectMeta\n",
    "    proj_meta,    # PETLORProjMeta  \n",
    "    pet_image: torch.Tensor,\n",
    "    system_matrix,  # PETLORSystemMatrix\n",
    "    attenuation_image: Optional[torch.Tensor] = None,\n",
    "    image_stepsize: int = 4,\n",
    "    attenuation_cutoff: float = 0.004,\n",
    "    scatter_stepsize: int = 4,\n",
    "    num_scatter_points: int = 1000,\n",
    "    energy_window_fraction: float = 0.2,\n",
    "    compton_fraction: float = 0.8,\n",
    "    N_splits: int = 1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Estimate scatter for LOR-based PET data using simplified single scatter simulation.\n",
    "    \n",
    "    Args:\n",
    "        object_meta: Object metadata\n",
    "        proj_meta: PETLORProjMeta with LOR coordinates\n",
    "        pet_image: Reconstructed PET image for scatter estimation\n",
    "        system_matrix: PETLORSystemMatrix\n",
    "        attenuation_image: Optional attenuation map (linear attenuation coefficient).\n",
    "                          If None, assumes uniform medium with minimal attenuation.\n",
    "        image_stepsize: Subsampling factor for image voxels used as scatter points\n",
    "        attenuation_cutoff: Minimum attenuation value to consider as scatter point\n",
    "                           (ignored if attenuation_image is None)\n",
    "        scatter_stepsize: Subsampling of LORs for scatter calculation\n",
    "        num_scatter_points: Maximum number of scatter points to use\n",
    "        energy_window_fraction: Fraction of scattered photons accepted\n",
    "        compton_fraction: Fraction of scattered events that are Compton scatter\n",
    "        N_splits: Number of splits for memory management\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Estimated scatter for each LOR\n",
    "    \"\"\"\n",
    "    device = pet_image.device\n",
    "    \n",
    "    # Create uniform attenuation map if none provided\n",
    "    if attenuation_image is None:\n",
    "        # Assume water-like attenuation (0.096 cm^-1 at 511 keV)\n",
    "        attenuation_image = torch.full_like(pet_image, 0.001)  # Very low uniform attenuation\n",
    "        attenuation_cutoff = 0.0001  # Lower cutoff since we have uniform low attenuation\n",
    "        print(\"No attenuation map provided - using uniform low attenuation\")\n",
    "    \n",
    "    # Get valid scatter points from the image\n",
    "    scatter_points, scatter_activities = _get_scatter_points(\n",
    "        pet_image, attenuation_image, object_meta, \n",
    "        image_stepsize, attenuation_cutoff, num_scatter_points\n",
    "    )\n",
    "    \n",
    "    if scatter_points.shape[0] == 0:\n",
    "        print(\"No valid scatter points found\")\n",
    "        return torch.zeros(proj_meta.lor_coords.shape[0], device=device)\n",
    "    \n",
    "    print(f\"Using {scatter_points.shape[0]} scatter points\")\n",
    "    \n",
    "    # Subsample LORs for computational efficiency\n",
    "    n_lors = proj_meta.lor_coords.shape[0]\n",
    "    lor_indices = torch.arange(0, n_lors, scatter_stepsize)\n",
    "    sampled_lor_coords = proj_meta.lor_coords[lor_indices]\n",
    "    \n",
    "    # Calculate scatter for sampled LORs\n",
    "    scatter_sampled = _calculate_single_scatter(\n",
    "        sampled_lor_coords, scatter_points, scatter_activities,\n",
    "        attenuation_image, object_meta, energy_window_fraction, \n",
    "        compton_fraction, N_splits\n",
    "    )\n",
    "    \n",
    "    # Interpolate scatter to all LORs\n",
    "    scatter_full = _interpolate_scatter_to_full_lors(\n",
    "        scatter_sampled, lor_indices, n_lors, proj_meta.lor_coords\n",
    "    )\n",
    "    \n",
    "    return scatter_full.to(device)\n",
    "\n",
    "\n",
    "def _get_scatter_points(\n",
    "    pet_image: torch.Tensor,\n",
    "    attenuation_image: torch.Tensor,\n",
    "    object_meta,\n",
    "    stepsize: int,\n",
    "    attenuation_cutoff: float,\n",
    "    max_points: int\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Extract valid scatter points from the image.\"\"\"\n",
    "    \n",
    "    # Subsample image for computational efficiency\n",
    "    pet_sub = pet_image[::stepsize, ::stepsize, ::stepsize]\n",
    "    atten_sub = attenuation_image[::stepsize, ::stepsize, ::stepsize]\n",
    "    \n",
    "    # Find voxels with sufficient activity and attenuation\n",
    "    # If attenuation is very uniform/low, just use activity threshold\n",
    "    if attenuation_cutoff > 0:\n",
    "        valid_mask = (atten_sub > attenuation_cutoff) & (pet_sub > 0)\n",
    "    else:\n",
    "        # Use activity-only threshold when attenuation is uniform\n",
    "        activity_threshold = pet_sub.max() * 0.01  # 1% of max activity\n",
    "        valid_mask = pet_sub > activity_threshold\n",
    "    \n",
    "    if not valid_mask.any():\n",
    "        return torch.empty((0, 3)), torch.empty(0)\n",
    "    \n",
    "    # Get indices of valid voxels\n",
    "    valid_indices = torch.where(valid_mask)\n",
    "    \n",
    "    # Convert to physical coordinates\n",
    "    origin = np.array(object_meta.shape) / 2 * np.array(object_meta.dr)\n",
    "    scatter_coords = torch.stack([\n",
    "        (valid_indices[0] * stepsize - object_meta.shape[0]/2 + 0.5) * object_meta.dr[0],\n",
    "        (valid_indices[1] * stepsize - object_meta.shape[1]/2 + 0.5) * object_meta.dr[1], \n",
    "        (valid_indices[2] * stepsize - object_meta.shape[2]/2 + 0.5) * object_meta.dr[2]\n",
    "    ], dim=1)\n",
    "    \n",
    "    # Get activities at these points\n",
    "    activities = pet_sub[valid_mask]\n",
    "    \n",
    "    # Limit number of points if too many\n",
    "    if scatter_coords.shape[0] > max_points:\n",
    "        # Sample based on activity (higher activity = higher probability)\n",
    "        probs = activities / activities.sum()\n",
    "        selected_indices = torch.multinomial(probs, max_points, replacement=False)\n",
    "        scatter_coords = scatter_coords[selected_indices]\n",
    "        activities = activities[selected_indices]\n",
    "    \n",
    "    return scatter_coords, activities\n",
    "\n",
    "\n",
    "def _calculate_single_scatter(\n",
    "    lor_coords: torch.Tensor,\n",
    "    scatter_points: torch.Tensor,\n",
    "    scatter_activities: torch.Tensor,\n",
    "    attenuation_image: torch.Tensor,\n",
    "    object_meta,\n",
    "    energy_fraction: float,\n",
    "    compton_fraction: float,\n",
    "    N_splits: int\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Calculate single scatter contribution for given LORs.\"\"\"\n",
    "    \n",
    "    device = lor_coords.device\n",
    "    n_lors = lor_coords.shape[0]\n",
    "    n_scatter = scatter_points.shape[0]\n",
    "    \n",
    "    scatter_estimate = torch.zeros(n_lors, device=device)\n",
    "    object_origin = (- np.array(object_meta.shape) / 2 + 0.5) * (np.array(object_meta.dr))\n",
    "    \n",
    "    # Process in batches to manage memory\n",
    "    batch_size = min(100, n_lors)\n",
    "    \n",
    "    for lor_start in range(0, n_lors, batch_size):\n",
    "        lor_end = min(lor_start + batch_size, n_lors)\n",
    "        lor_batch = lor_coords[lor_start:lor_end]\n",
    "        \n",
    "        batch_scatter = torch.zeros(lor_end - lor_start, device=device)\n",
    "        \n",
    "        # For each LOR in the batch\n",
    "        for i, lor in enumerate(lor_batch):\n",
    "            p1 = lor[:3]  # Start point\n",
    "            p2 = lor[3:]  # End point\n",
    "            \n",
    "            # Calculate scatter contribution from each scatter point\n",
    "            for j in range(n_scatter):\n",
    "                scatter_point = scatter_points[j]\n",
    "                activity = scatter_activities[j]\n",
    "                \n",
    "                # Calculate scatter probability\n",
    "                scatter_prob = _calculate_scatter_probability(\n",
    "                    p1, p2, scatter_point, attenuation_image, \n",
    "                    object_origin, object_meta.dr, energy_fraction, compton_fraction\n",
    "                )\n",
    "                \n",
    "                batch_scatter[i] += activity * scatter_prob\n",
    "        \n",
    "        scatter_estimate[lor_start:lor_end] = batch_scatter\n",
    "    \n",
    "    return scatter_estimate\n",
    "\n",
    "\n",
    "def _calculate_scatter_probability(\n",
    "    p1: torch.Tensor,\n",
    "    p2: torch.Tensor, \n",
    "    scatter_point: torch.Tensor,\n",
    "    attenuation_image: torch.Tensor,\n",
    "    object_origin: np.ndarray,\n",
    "    dr: tuple,\n",
    "    energy_fraction: float,\n",
    "    compton_fraction: float\n",
    ") -> float:\n",
    "    \"\"\"Calculate the probability of scatter from a point contributing to a LOR.\"\"\"\n",
    "    \n",
    "    # Calculate distances\n",
    "    d1 = torch.norm(scatter_point - p1)  # Distance from p1 to scatter point\n",
    "    d2 = torch.norm(p2 - scatter_point)  # Distance from scatter point to p2\n",
    "    \n",
    "    if d1 == 0 or d2 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    # Calculate scattering angle using cosine rule\n",
    "    d12 = torch.norm(p2 - p1)  # Direct distance\n",
    "    cos_theta = (d1**2 + d2**2 - d12**2) / (2 * d1 * d2)\n",
    "    cos_theta = torch.clamp(cos_theta, -1, 1)  # Ensure valid range\n",
    "    \n",
    "    # Klein-Nishina formula for Compton scattering (simplified)\n",
    "    # For 511 keV photons\n",
    "    alpha = 1.022  # 511 keV / 511 keV\n",
    "    compton_prob = (1 + cos_theta + (alpha * (1 - cos_theta))**2 / (1 + alpha * (1 - cos_theta)))\n",
    "    \n",
    "    # Geometric probability (inverse square law)\n",
    "    geometric_prob = 1.0 / (4 * np.pi * d1**2) * 1.0 / (4 * np.pi * d2**2)\n",
    "    \n",
    "    # Attenuation along paths\n",
    "    # Path from p1 to scatter point\n",
    "    atten1 = _calculate_line_integral(\n",
    "        p1, scatter_point, attenuation_image, object_origin, dr\n",
    "    )\n",
    "    \n",
    "    # Path from scatter point to p2  \n",
    "    atten2 = _calculate_line_integral(\n",
    "        scatter_point, p2, attenuation_image, object_origin, dr\n",
    "    )\n",
    "    \n",
    "    attenuation_factor = torch.exp(-(atten1 + atten2))\n",
    "    \n",
    "    # Combine all factors\n",
    "    scatter_prob = (compton_fraction * energy_fraction * \n",
    "                   compton_prob * geometric_prob * attenuation_factor)\n",
    "    \n",
    "    return scatter_prob.item()\n",
    "\n",
    "\n",
    "def _calculate_line_integral(\n",
    "    p1: torch.Tensor,\n",
    "    p2: torch.Tensor,\n",
    "    image: torch.Tensor,\n",
    "    origin: np.ndarray,\n",
    "    dr: tuple\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Calculate line integral of image along path from p1 to p2.\"\"\"\n",
    "    \n",
    "    # Use parallelproj for line integral calculation\n",
    "    try:\n",
    "        integral = parallelproj.joseph3d_fwd(\n",
    "            p1.unsqueeze(0).to(image.device),\n",
    "            p2.unsqueeze(0).to(image.device),\n",
    "            image.to(image.device),\n",
    "            origin,\n",
    "            dr\n",
    "        )[0]\n",
    "        return integral\n",
    "    except:\n",
    "        # Fallback: simple approximation\n",
    "        return torch.norm(p2 - p1) * 0.01  # Rough approximation\n",
    "\n",
    "\n",
    "def _interpolate_scatter_to_full_lors(\n",
    "    scatter_sampled: torch.Tensor,\n",
    "    sampled_indices: torch.Tensor,\n",
    "    total_lors: int,\n",
    "    all_lor_coords: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Interpolate scattered estimates from sampled LORs to all LORs.\"\"\"\n",
    "    \n",
    "    device = scatter_sampled.device\n",
    "    scatter_full = torch.zeros(total_lors, device=device)\n",
    "    \n",
    "    if len(scatter_sampled) == 0:\n",
    "        return scatter_full\n",
    "    \n",
    "    # Simple approach: assign sampled values to their positions\n",
    "    scatter_full[sampled_indices] = scatter_sampled\n",
    "    \n",
    "    # For non-sampled LORs, use nearest neighbor interpolation\n",
    "    # based on LOR midpoint proximity\n",
    "    sampled_midpoints = (all_lor_coords[sampled_indices, :3] + \n",
    "                        all_lor_coords[sampled_indices, 3:]) / 2\n",
    "    \n",
    "    for i in range(total_lors):\n",
    "        if i not in sampled_indices:\n",
    "            # Find nearest sampled LOR\n",
    "            lor_midpoint = (all_lor_coords[i, :3] + all_lor_coords[i, 3:]) / 2\n",
    "            distances = torch.norm(sampled_midpoints - lor_midpoint.unsqueeze(0), dim=1)\n",
    "            nearest_idx = torch.argmin(distances)\n",
    "            scatter_full[i] = scatter_sampled[nearest_idx]\n",
    "    \n",
    "    return scatter_full\n",
    "\n",
    "\n",
    "# Example usage function to showcase information flow\n",
    "def apply_scatter_correction(\n",
    "    object_meta,\n",
    "    proj_meta, \n",
    "    system_matrix,\n",
    "    pet_image: torch.Tensor,\n",
    "    measured_projections: torch.Tensor,\n",
    "    attenuation_image: Optional[torch.Tensor] = None\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply scatter correction to measured projections.\n",
    "    \n",
    "    Args:\n",
    "        attenuation_image: Optional attenuation map. If None, assumes uniform medium.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (scatter_estimate, corrected_projections)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estimate scatter\n",
    "    scatter_estimate = get_lor_scatter_estimate(\n",
    "        object_meta=object_meta,\n",
    "        proj_meta=proj_meta,\n",
    "        pet_image=pet_image,\n",
    "        system_matrix=system_matrix,\n",
    "        attenuation_image=attenuation_image,  # Now optional\n",
    "        image_stepsize=4,\n",
    "        attenuation_cutoff=0.004,\n",
    "        scatter_stepsize=4,\n",
    "        num_scatter_points=1000\n",
    "    )\n",
    "    \n",
    "    # Correct projections by subtracting scatter\n",
    "    corrected_projections = measured_projections - scatter_estimate\n",
    "    corrected_projections = torch.clamp(corrected_projections, min=0)  # Ensure non-negative\n",
    "    \n",
    "    return scatter_estimate, corrected_projections\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102155b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_estimate = get_lor_scatter_estimate(\n",
    "        object_meta=object_meta,\n",
    "        proj_meta=proj_meta,\n",
    "        pet_image=recon_without_scatter_estimation,\n",
    "        attenuation_image=atten_map,\n",
    "        system_matrix=system_matrix,\n",
    "        image_stepsize=16,\n",
    "        # image_stepsize=4,\n",
    "        attenuation_cutoff=0.004,\n",
    "        scatter_stepsize=16,\n",
    "        # scatter_stepsize=4,\n",
    "        num_scatter_points=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac9d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "additive_term = lm_delays / lm_sensitivity\n",
    "additive_term[additive_term.isnan()] = 0\n",
    "\n",
    "# Create likelihood. For listmode reconstruction, projections don't need to be provided, since all detection events are stored in proj_meta\n",
    "likelihood = PoissonLogLikelihood(\n",
    "    system_matrix,\n",
    "    # recon_algorithm = OSEM(likelihood, object_initial=back_projected)\n",
    "    additive_term=additive_term,  # Additive term for randoms\n",
    ")\n",
    "\n",
    "# # (Optional) Initialise the recon algorithm with a voxel tensor  \n",
    "# random_voxel_tensor = torch.rand(voxel_tensor.shape, device=pytomography.device)\n",
    "# back_projected_tensor = torch.tensor(back_projected.cpu().numpy())\n",
    "\n",
    "# recon_algorithm = OSEM(likelihood, object_initial=None)\n",
    "recon_algorithm = OSEM(likelihood, object_initial=torch.tensor(back_projected.cpu().numpy().copy()))\n",
    "recon_with_scatter_estimation = recon_algorithm(n_iters=100, n_subsets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ab371",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cross_sections_interactive(recon_with_scatter_estimation.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = recon_without_scatter_estimation-recon_with_scatter_estimation\n",
    "# diff = recon_with_scatter_estimation - recon_without_scatter_estimation\n",
    "# plot_cross_sections_interactive(diff.cpu().numpy())\n",
    "print(diff.cpu().numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf46d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_voxel_tensor_3d(recon_without_scatter_estimation.cpu().numpy(), \n",
    "#                           initial_min_threshold=0.0004, \n",
    "#                         #   initial_min_threshold=0.004, \n",
    "#                           initial_max_threshold=0.1,\n",
    "#                           voxel_size_mm=voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdee4fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_voxel_tensor_3d(recon_with_scatter_estimation.cpu().numpy(), \n",
    "                        #   initial_min_threshold=0.0004, \n",
    "                        #   initial_min_threshold=0.004, \n",
    "                        #   initial_max_threshold=0.1,\n",
    "                          voxel_size_mm=voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cc07ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pixel values distribution\n",
    "# print(recon_without_scatter_estimation.cpu().numpy().shape)\n",
    "\n",
    "intensity_range = (0,0.03)\n",
    "voxel_values = recon_without_scatter_estimation.cpu().numpy().flatten()\n",
    "\n",
    "plt.figure(figsize=(13, 3))\n",
    "plt.hist(voxel_values, bins=200, color='blue', alpha=0.7, range=intensity_range)\n",
    "plt.xlabel('Voxel Intensity')\n",
    "plt.ylabel('Count')\n",
    "plt.title(f'Distribution of Voxel Intensities (Bounded {intensity_range})')\n",
    "plt.grid(True)\n",
    "plt.xlim(intensity_range)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6739339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compare recon before and after scatter estimation\n",
    "# plot_cross_sections_interactive(recon_without_scatter_estimation.cpu().numpy(), title=\"My 3D Data\")\n",
    "# plot_cross_sections_interactive(recon_with_scatter_estimation.cpu().numpy(), title=\"My 3D Data\")\n",
    "# plot_cross_sections_interactive(recon_without_scatter_estimation.cpu().numpy()-recon_with_scatter_estimation.cpu().numpy(), title=\"My 3D Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effe5e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinogram confirmation and visualisation functions\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Optional\n",
    "\n",
    "def lor_coords_to_3d_sinogram(\n",
    "    lor_coords: torch.Tensor,\n",
    "    weights: Optional[torch.Tensor] = None,\n",
    "    n_radial_bins: int = 256,\n",
    "    n_angular_bins: int = 180,\n",
    "    n_axial_bins: int = 64,\n",
    "    radial_range: Optional[Tuple[float, float]] = None,\n",
    "    angular_range: Tuple[float, float] = (0, 180),\n",
    "    axial_range: Optional[Tuple[float, float]] = None\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Convert LOR coordinates to a full 3D sinogram (s, φ, z) where:\n",
    "    - s: radial distance from central axis\n",
    "    - φ: azimuthal angle (0-180°) \n",
    "    - z: axial position (average z of LOR endpoints)\n",
    "    \n",
    "    Args:\n",
    "        lor_coords: LOR coordinates tensor (N, 6) as [x1,y1,z1,x2,y2,z2] in mm\n",
    "        weights: Optional weights for each LOR (e.g., counts)\n",
    "        n_radial_bins: Number of radial bins (s direction)\n",
    "        n_angular_bins: Number of angular bins (φ direction)  \n",
    "        n_axial_bins: Number of axial bins (z direction)\n",
    "        radial_range: (min_s, max_s) in mm. If None, auto-determined\n",
    "        angular_range: (min_φ, max_φ) in degrees\n",
    "        axial_range: (min_z, max_z) in mm. If None, auto-determined\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (sinogram_3d, radial_coords, angular_coords, axial_coords)\n",
    "        sinogram_3d shape: (n_axial_bins, n_angular_bins, n_radial_bins)\n",
    "    \"\"\"\n",
    "    device = lor_coords.device\n",
    "    n_lors = lor_coords.shape[0]\n",
    "    \n",
    "    # Default weights\n",
    "    if weights is None:\n",
    "        weights = torch.ones(n_lors, device=device)\n",
    "    \n",
    "    print(f\"Creating 3D sinogram from {n_lors} LORs\")\n",
    "    \n",
    "    # Extract coordinates\n",
    "    p1 = lor_coords[:, :3]  # [x1, y1, z1]\n",
    "    p2 = lor_coords[:, 3:]  # [x2, y2, z2]\n",
    "    \n",
    "    # Calculate radial distance and angle in x-y plane\n",
    "    radial_distances, angles = _calculate_sinogram_coords_xy(p1[:, :2], p2[:, :2])\n",
    "    \n",
    "    # Calculate axial position (average z coordinate)\n",
    "    axial_positions = (p1[:, 2] + p2[:, 2]) / 2\n",
    "    \n",
    "    # Convert angles to degrees and normalize to [0, 180)\n",
    "    angles_deg = torch.rad2deg(angles) % 180\n",
    "    \n",
    "    # Determine ranges if not specified\n",
    "    if radial_range is None:\n",
    "        r_min = radial_distances.min().item() - 1\n",
    "        r_max = radial_distances.max().item() + 1\n",
    "        radial_range = (r_min, r_max)\n",
    "    \n",
    "    if axial_range is None:\n",
    "        z_min = axial_positions.min().item() - 1\n",
    "        z_max = axial_positions.max().item() + 1\n",
    "        axial_range = (z_min, z_max)\n",
    "    \n",
    "    print(f\"Radial range: {radial_range[0]:.1f} to {radial_range[1]:.1f} mm\")\n",
    "    print(f\"Angular range: {angular_range[0]:.1f} to {angular_range[1]:.1f} degrees\")\n",
    "    print(f\"Axial range: {axial_range[0]:.1f} to {axial_range[1]:.1f} mm\")\n",
    "    \n",
    "    # Create 3D sinogram\n",
    "    sinogram_3d = _create_3d_sinogram_histogram(\n",
    "        radial_distances, angles_deg, axial_positions, weights,\n",
    "        n_radial_bins, n_angular_bins, n_axial_bins,\n",
    "        radial_range, angular_range, axial_range\n",
    "    )\n",
    "    \n",
    "    # Create coordinate arrays\n",
    "    radial_coords = torch.linspace(radial_range[0], radial_range[1], n_radial_bins, device=device)\n",
    "    angular_coords = torch.linspace(angular_range[0], angular_range[1], n_angular_bins, device=device)\n",
    "    axial_coords = torch.linspace(axial_range[0], axial_range[1], n_axial_bins, device=device)\n",
    "    \n",
    "    return sinogram_3d, radial_coords, angular_coords, axial_coords\n",
    "\n",
    "\n",
    "def _calculate_sinogram_coords_xy(\n",
    "    p1: torch.Tensor, \n",
    "    p2: torch.Tensor\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Calculate radial distance and angle for LORs projected to x-y plane.\"\"\"\n",
    "    \n",
    "    # Calculate line parameters in x-y plane: ax + by + c = 0\n",
    "    x1, y1 = p1[:, 0], p1[:, 1]\n",
    "    x2, y2 = p2[:, 0], p2[:, 1]\n",
    "    \n",
    "    a = y2 - y1\n",
    "    b = x1 - x2\n",
    "    c = x2 * y1 - x1 * y2\n",
    "    \n",
    "    # Normalize to get signed distance from origin\n",
    "    norm = torch.sqrt(a**2 + b**2)\n",
    "    \n",
    "    # Handle parallel lines (avoid division by zero)\n",
    "    valid_mask = norm > 1e-8\n",
    "    \n",
    "    radial_distance = torch.zeros_like(norm)\n",
    "    angle = torch.zeros_like(norm)\n",
    "    \n",
    "    if valid_mask.any():\n",
    "        # Signed distance from origin to line\n",
    "        radial_distance[valid_mask] = torch.abs(c[valid_mask] / norm[valid_mask])\n",
    "        \n",
    "        # Angle of normal to line (perpendicular to LOR)\n",
    "        angle[valid_mask] = torch.atan2(a[valid_mask] / norm[valid_mask], \n",
    "                                       b[valid_mask] / norm[valid_mask])\n",
    "    \n",
    "    # Ensure radial distance is positive and angle is in [0, π)\n",
    "    negative_mask = radial_distance < 0\n",
    "    radial_distance[negative_mask] = -radial_distance[negative_mask]\n",
    "    angle[negative_mask] = angle[negative_mask] + torch.pi\n",
    "    \n",
    "    # Normalize angle to [0, π)\n",
    "    angle = angle % torch.pi\n",
    "    \n",
    "    return radial_distance, angle\n",
    "\n",
    "\n",
    "def _create_3d_sinogram_histogram(\n",
    "    radial_distances: torch.Tensor,\n",
    "    angles_deg: torch.Tensor,\n",
    "    axial_positions: torch.Tensor,\n",
    "    weights: torch.Tensor,\n",
    "    n_radial_bins: int,\n",
    "    n_angular_bins: int,\n",
    "    n_axial_bins: int,\n",
    "    radial_range: Tuple[float, float],\n",
    "    angular_range: Tuple[float, float],\n",
    "    axial_range: Tuple[float, float]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Create 3D histogram (sinogram) from coordinates.\"\"\"\n",
    "    \n",
    "    device = radial_distances.device\n",
    "    \n",
    "    # Create bin edges\n",
    "    r_edges = torch.linspace(radial_range[0], radial_range[1], n_radial_bins + 1, device=device)\n",
    "    a_edges = torch.linspace(angular_range[0], angular_range[1], n_angular_bins + 1, device=device)\n",
    "    z_edges = torch.linspace(axial_range[0], axial_range[1], n_axial_bins + 1, device=device)\n",
    "    \n",
    "    # Find bin indices\n",
    "    r_indices = torch.searchsorted(r_edges[1:], radial_distances)\n",
    "    a_indices = torch.searchsorted(a_edges[1:], angles_deg)\n",
    "    z_indices = torch.searchsorted(z_edges[1:], axial_positions)\n",
    "    \n",
    "    # Clip to valid range\n",
    "    r_indices = torch.clamp(r_indices, 0, n_radial_bins - 1)\n",
    "    a_indices = torch.clamp(a_indices, 0, n_angular_bins - 1)\n",
    "    z_indices = torch.clamp(z_indices, 0, n_axial_bins - 1)\n",
    "    \n",
    "    # Create 3D sinogram using scatter_add\n",
    "    sinogram_3d = torch.zeros((n_axial_bins, n_angular_bins, n_radial_bins), device=device)\n",
    "    \n",
    "    # Convert 3D indices to 1D\n",
    "    linear_indices = (z_indices * n_angular_bins * n_radial_bins + \n",
    "                     a_indices * n_radial_bins + r_indices)\n",
    "    \n",
    "    # Add weights to appropriate bins\n",
    "    sinogram_flat = torch.zeros(n_axial_bins * n_angular_bins * n_radial_bins, device=device)\n",
    "    sinogram_flat.scatter_add_(0, linear_indices, weights)\n",
    "    sinogram_3d = sinogram_flat.reshape(n_axial_bins, n_angular_bins, n_radial_bins)\n",
    "    \n",
    "    return sinogram_3d\n",
    "\n",
    "\n",
    "def visualize_3d_sinogram(\n",
    "    sinogram_3d: torch.Tensor,\n",
    "    radial_coords: torch.Tensor,\n",
    "    angular_coords: torch.Tensor,\n",
    "    axial_coords: torch.Tensor,\n",
    "    save_path: Optional[str] = None,\n",
    "    log_scale: bool = True\n",
    ") -> None:\n",
    "    \"\"\"Visualize 3D sinogram with multiple views.\"\"\"\n",
    "    \n",
    "    sino_np = sinogram_3d.cpu().numpy()\n",
    "    \n",
    "    if log_scale and sino_np.max() > 0:\n",
    "        sino_np = np.log(sino_np + 1)\n",
    "        scale_label = \" (Log Scale)\"\n",
    "    else:\n",
    "        scale_label = \"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    fig.suptitle(f\"3D Sinogram Visualization{scale_label}\", fontsize=16)\n",
    "    \n",
    "    # Central slices\n",
    "    z_center = sino_np.shape[0] // 2\n",
    "    a_center = sino_np.shape[1] // 2\n",
    "    r_center = sino_np.shape[2] // 2\n",
    "    \n",
    "    # Axial view (φ vs s) at central z\n",
    "    im1 = axes[0,0].imshow(\n",
    "        sino_np[z_center, :, :],\n",
    "        aspect='auto', origin='lower',\n",
    "        extent=[radial_coords.min().item(), radial_coords.max().item(),\n",
    "                angular_coords.min().item(), angular_coords.max().item()],\n",
    "        cmap='hot'\n",
    "    )\n",
    "    axes[0,0].set_xlabel('Radial Distance (mm)')\n",
    "    axes[0,0].set_ylabel('Angle (degrees)')\n",
    "    axes[0,0].set_title(f'Central Axial Slice (z={axial_coords[z_center]:.1f}mm)')\n",
    "    plt.colorbar(im1, ax=axes[0,0])\n",
    "    \n",
    "    # Sagittal view (z vs s) at central φ  \n",
    "    im2 = axes[0,1].imshow(\n",
    "        sino_np[:, a_center, :],\n",
    "        aspect='auto', origin='lower',\n",
    "        extent=[radial_coords.min().item(), radial_coords.max().item(),\n",
    "                axial_coords.min().item(), axial_coords.max().item()],\n",
    "        cmap='hot'\n",
    "    )\n",
    "    axes[0,1].set_xlabel('Radial Distance (mm)')\n",
    "    axes[0,1].set_ylabel('Axial Position (mm)')\n",
    "    axes[0,1].set_title(f'Central Sagittal Slice (φ={angular_coords[a_center]:.1f}°)')\n",
    "    plt.colorbar(im2, ax=axes[0,1])\n",
    "    \n",
    "    # Coronal view (z vs φ) at central s\n",
    "    im3 = axes[0,2].imshow(\n",
    "        sino_np[:, :, r_center],\n",
    "        aspect='auto', origin='lower',\n",
    "        extent=[angular_coords.min().item(), angular_coords.max().item(),\n",
    "                axial_coords.min().item(), axial_coords.max().item()],\n",
    "        cmap='hot'\n",
    "    )\n",
    "    axes[0,2].set_xlabel('Angle (degrees)')\n",
    "    axes[0,2].set_ylabel('Axial Position (mm)')\n",
    "    axes[0,2].set_title(f'Central Coronal Slice (s={radial_coords[r_center]:.1f}mm)')\n",
    "    plt.colorbar(im3, ax=axes[0,2])\n",
    "    \n",
    "    # Projections (summed over one dimension)\n",
    "    # Sum over axial dimension\n",
    "    axes[1,0].imshow(\n",
    "        sino_np.sum(axis=0),\n",
    "        aspect='auto', origin='lower',\n",
    "        extent=[radial_coords.min().item(), radial_coords.max().item(),\n",
    "                angular_coords.min().item(), angular_coords.max().item()],\n",
    "        cmap='hot'\n",
    "    )\n",
    "    axes[1,0].set_xlabel('Radial Distance (mm)')\n",
    "    axes[1,0].set_ylabel('Angle (degrees)')\n",
    "    axes[1,0].set_title('Axial Projection (summed over z)')\n",
    "    \n",
    "    # Sum over angular dimension\n",
    "    axes[1,1].imshow(\n",
    "        sino_np.sum(axis=1),\n",
    "        aspect='auto', origin='lower',\n",
    "        extent=[radial_coords.min().item(), radial_coords.max().item(),\n",
    "                axial_coords.min().item(), axial_coords.max().item()],\n",
    "        cmap='hot'\n",
    "    )\n",
    "    axes[1,1].set_xlabel('Radial Distance (mm)')\n",
    "    axes[1,1].set_ylabel('Axial Position (mm)')\n",
    "    axes[1,1].set_title('Angular Projection (summed over φ)')\n",
    "    \n",
    "    # Sum over radial dimension\n",
    "    axes[1,2].imshow(\n",
    "        sino_np.sum(axis=2),\n",
    "        aspect='auto', origin='lower',\n",
    "        extent=[angular_coords.min().item(), angular_coords.max().item(),\n",
    "                axial_coords.min().item(), axial_coords.max().item()],\n",
    "        cmap='hot'\n",
    "    )\n",
    "    axes[1,2].set_xlabel('Angle (degrees)')\n",
    "    axes[1,2].set_ylabel('Axial Position (mm)')\n",
    "    axes[1,2].set_title('Radial Projection (summed over s)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def analyze_3d_sinogram_statistics(\n",
    "    sinogram_3d: torch.Tensor,\n",
    "    radial_coords: torch.Tensor,\n",
    "    angular_coords: torch.Tensor,\n",
    "    axial_coords: torch.Tensor\n",
    ") -> dict:\n",
    "    \"\"\"Analyze statistics of 3D sinogram.\"\"\"\n",
    "    \n",
    "    stats = {\n",
    "        'total_counts': float(sinogram_3d.sum()),\n",
    "        'max_counts': float(sinogram_3d.max()),\n",
    "        'mean_counts': float(sinogram_3d.mean()),\n",
    "        'std_counts': float(sinogram_3d.std()),\n",
    "        'non_zero_bins': int((sinogram_3d > 0).sum()),\n",
    "        'total_bins': int(sinogram_3d.numel()),\n",
    "        'shape': tuple(sinogram_3d.shape),\n",
    "        'radial_range_mm': (float(radial_coords.min()), float(radial_coords.max())),\n",
    "        'angular_range_deg': (float(angular_coords.min()), float(angular_coords.max())),\n",
    "        'axial_range_mm': (float(axial_coords.min()), float(axial_coords.max())),\n",
    "        'radial_resolution_mm': float((radial_coords.max() - radial_coords.min()) / len(radial_coords)),\n",
    "        'angular_resolution_deg': float((angular_coords.max() - angular_coords.min()) / len(angular_coords)),\n",
    "        'axial_resolution_mm': float((axial_coords.max() - axial_coords.min()) / len(axial_coords))\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def sanity_check_3d_lor_data(\n",
    "    lor_coords: torch.Tensor,\n",
    "    weights: Optional[torch.Tensor] = None,\n",
    "    n_radial_bins: int = 128,\n",
    "    n_angular_bins: int = 90,\n",
    "    n_axial_bins: int = 32\n",
    ") -> None:\n",
    "    \"\"\"Comprehensive 3D sinogram sanity check.\"\"\"\n",
    "    \n",
    "    print(\"=== 3D LOR Data Sanity Check ===\")\n",
    "    print(f\"Total LORs: {lor_coords.shape[0]}\")\n",
    "    \n",
    "    if weights is not None:\n",
    "        print(f\"Total counts: {weights.sum():.0f}\")\n",
    "        print(f\"Average counts per LOR: {weights.mean():.2f}\")\n",
    "    \n",
    "    # Create 3D sinogram\n",
    "    print(\"\\nCreating 3D sinogram...\")\n",
    "    sinogram_3d, radial_coords, angular_coords, axial_coords = lor_coords_to_3d_sinogram(\n",
    "        lor_coords=lor_coords,\n",
    "        weights=weights,\n",
    "        n_radial_bins=n_radial_bins,\n",
    "        n_angular_bins=n_angular_bins,\n",
    "        n_axial_bins=n_axial_bins\n",
    "    )\n",
    "    \n",
    "    # Analyze statistics\n",
    "    stats = analyze_3d_sinogram_statistics(sinogram_3d, radial_coords, angular_coords, axial_coords)\n",
    "    \n",
    "    print(\"\\n=== 3D Sinogram Statistics ===\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_3d_sinogram(sinogram_3d, radial_coords, angular_coords, axial_coords)\n",
    "    \n",
    "    # Quality checks\n",
    "    print(\"\\n=== Data Quality Checks ===\")\n",
    "    \n",
    "    if stats['non_zero_bins'] < stats['total_bins'] * 0.01:\n",
    "        print(\"⚠️  Very sparse 3D sinogram - check LOR coordinates\")\n",
    "    \n",
    "    if stats['max_counts'] > stats['mean_counts'] * 100:\n",
    "        print(\"⚠️  Very uneven count distribution\")\n",
    "    \n",
    "    if stats['radial_range_mm'][1] > 1000:\n",
    "        print(\"⚠️  Very large radial range - check coordinate units\")\n",
    "    \n",
    "    print(\"✅ 3D sinogram analysis complete!\")\n",
    "\n",
    "\n",
    "def _filter_lors_by_slice(\n",
    "    lor_coords: torch.Tensor,\n",
    "    weights: torch.Tensor,\n",
    "    slice_axis: int,\n",
    "    slice_position: Optional[float],\n",
    "    slice_thickness: Optional[float]\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Filter LORs that pass through a specified slice.\"\"\"\n",
    "    \n",
    "    # Get z-coordinates of start and end points\n",
    "    z1 = lor_coords[:, slice_axis]\n",
    "    z2 = lor_coords[:, slice_axis + 3]\n",
    "    \n",
    "    if slice_position is None:\n",
    "        # Use center of data range\n",
    "        slice_position = (z1.min() + z1.max() + z2.min() + z2.max()) / 4\n",
    "    \n",
    "    if slice_thickness is None:\n",
    "        # Include all LORs\n",
    "        mask = torch.ones(lor_coords.shape[0], dtype=torch.bool, device=lor_coords.device)\n",
    "    else:\n",
    "        # Check if LOR passes through the slice\n",
    "        z_min = torch.minimum(z1, z2)\n",
    "        z_max = torch.maximum(z1, z2)\n",
    "        \n",
    "        slice_min = slice_position - slice_thickness / 2\n",
    "        slice_max = slice_position + slice_thickness / 2\n",
    "        \n",
    "        # LOR intersects slice if it spans the slice boundaries\n",
    "        mask = (z_min <= slice_max) & (z_max >= slice_min)\n",
    "    \n",
    "    return lor_coords[mask], weights[mask]\n",
    "\n",
    "\n",
    "def _calculate_sinogram_coords(\n",
    "    p1: torch.Tensor, \n",
    "    p2: torch.Tensor\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Calculate radial distance and angle for LORs in 2D.\"\"\"\n",
    "    \n",
    "    # Calculate line parameters: ax + by + c = 0\n",
    "    # For line through (x1,y1) and (x2,y2):\n",
    "    # a = y2 - y1, b = x1 - x2, c = x2*y1 - x1*y2\n",
    "    \n",
    "    x1, y1 = p1[:, 0], p1[:, 1]\n",
    "    x2, y2 = p2[:, 0], p2[:, 1]\n",
    "    \n",
    "    a = y2 - y1\n",
    "    b = x1 - x2\n",
    "    c = x2 * y1 - x1 * y2\n",
    "    \n",
    "    # Normalize to get signed distance from origin\n",
    "    norm = torch.sqrt(a**2 + b**2)\n",
    "    \n",
    "    # Handle parallel lines (avoid division by zero)\n",
    "    valid_mask = norm > 1e-8\n",
    "    \n",
    "    radial_distance = torch.zeros_like(norm)\n",
    "    angle = torch.zeros_like(norm)\n",
    "    \n",
    "    if valid_mask.any():\n",
    "        # Signed distance from origin to line\n",
    "        radial_distance[valid_mask] = torch.abs(c[valid_mask] / norm[valid_mask])\n",
    "        \n",
    "        # Angle of normal to line (perpendicular to LOR)\n",
    "        # atan2(a/norm, b/norm) gives angle of normal vector\n",
    "        angle[valid_mask] = torch.atan2(a[valid_mask] / norm[valid_mask], \n",
    "                                       b[valid_mask] / norm[valid_mask])\n",
    "    \n",
    "    # Ensure radial distance is positive and angle is in [0, π)\n",
    "    negative_mask = radial_distance < 0\n",
    "    radial_distance[negative_mask] = -radial_distance[negative_mask]\n",
    "    angle[negative_mask] = angle[negative_mask] + torch.pi\n",
    "    \n",
    "    # Normalize angle to [0, π)\n",
    "    angle = angle % torch.pi\n",
    "    \n",
    "    return radial_distance, angle\n",
    "\n",
    "\n",
    "def _create_sinogram_histogram(\n",
    "    radial_distances: torch.Tensor,\n",
    "    angles_deg: torch.Tensor,\n",
    "    weights: torch.Tensor,\n",
    "    n_radial_bins: int,\n",
    "    n_angular_bins: int,\n",
    "    radial_range: Tuple[float, float],\n",
    "    angular_range: Tuple[float, float]\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Create 2D histogram (sinogram) from radial distances and angles.\"\"\"\n",
    "    \n",
    "    device = radial_distances.device\n",
    "    \n",
    "    # Create bin edges\n",
    "    r_edges = torch.linspace(radial_range[0], radial_range[1], n_radial_bins + 1, device=device)\n",
    "    a_edges = torch.linspace(angular_range[0], angular_range[1], n_angular_bins + 1, device=device)\n",
    "    \n",
    "    # Find bin indices\n",
    "    r_indices = torch.searchsorted(r_edges[1:], radial_distances)\n",
    "    a_indices = torch.searchsorted(a_edges[1:], angles_deg)\n",
    "    \n",
    "    # Clip to valid range\n",
    "    r_indices = torch.clamp(r_indices, 0, n_radial_bins - 1)\n",
    "    a_indices = torch.clamp(a_indices, 0, n_angular_bins - 1)\n",
    "    \n",
    "    # Create sinogram using scatter_add\n",
    "    sinogram = torch.zeros((n_angular_bins, n_radial_bins), device=device)\n",
    "    \n",
    "    # Convert 2D indices to 1D\n",
    "    linear_indices = a_indices * n_radial_bins + r_indices\n",
    "    \n",
    "    # Add weights to appropriate bins\n",
    "    sinogram_flat = torch.zeros(n_angular_bins * n_radial_bins, device=device)\n",
    "    sinogram_flat.scatter_add_(0, linear_indices, weights)\n",
    "    sinogram = sinogram_flat.reshape(n_angular_bins, n_radial_bins)\n",
    "    \n",
    "    return sinogram\n",
    "\n",
    "\n",
    "def visualize_sinogram(\n",
    "    sinogram: torch.Tensor,\n",
    "    radial_coords: torch.Tensor,\n",
    "    angular_coords: torch.Tensor,\n",
    "    title: str = \"Sinogram\",\n",
    "    save_path: Optional[str] = None,\n",
    "    log_scale: bool = True\n",
    ") -> None:\n",
    "    \"\"\"Visualize the sinogram with proper axes labels.\"\"\"\n",
    "    \n",
    "    sino_np = sinogram.cpu().numpy()\n",
    "    \n",
    "    if log_scale and sino_np.max() > 0:\n",
    "        sino_np = np.log(sino_np + 1)  # Add 1 to avoid log(0)\n",
    "        title += \" (Log Scale)\"\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create the plot\n",
    "    im = plt.imshow(\n",
    "        sino_np,\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        extent=[\n",
    "            radial_coords.min().item(),\n",
    "            radial_coords.max().item(),\n",
    "            angular_coords.min().item(),\n",
    "            angular_coords.max().item()\n",
    "        ],\n",
    "        cmap='hot'\n",
    "    )\n",
    "    \n",
    "    plt.colorbar(im, label='Counts' + (' (log)' if log_scale else ''))\n",
    "    plt.xlabel('Radial Distance (mm)')\n",
    "    plt.ylabel('Angle (degrees)')\n",
    "    plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def analyze_sinogram_statistics(\n",
    "    sinogram: torch.Tensor,\n",
    "    radial_coords: torch.Tensor,\n",
    "    angular_coords: torch.Tensor\n",
    ") -> dict:\n",
    "    \"\"\"Analyze basic statistics of the sinogram.\"\"\"\n",
    "    \n",
    "    sino_np = sinogram.cpu().numpy()\n",
    "    \n",
    "    stats = {\n",
    "        'total_counts': float(sinogram.sum()),\n",
    "        'max_counts': float(sinogram.max()),\n",
    "        'mean_counts': float(sinogram.mean()),\n",
    "        'std_counts': float(sinogram.std()),\n",
    "        'non_zero_bins': int((sinogram > 0).sum()),\n",
    "        'total_bins': int(sinogram.numel()),\n",
    "        'radial_range_mm': (float(radial_coords.min()), float(radial_coords.max())),\n",
    "        'angular_range_deg': (float(angular_coords.min()), float(angular_coords.max())),\n",
    "        'radial_resolution_mm': float((radial_coords.max() - radial_coords.min()) / len(radial_coords)),\n",
    "        'angular_resolution_deg': float((angular_coords.max() - angular_coords.min()) / len(angular_coords))\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def create_multiple_slice_sinograms(\n",
    "    lor_coords: torch.Tensor,\n",
    "    weights: Optional[torch.Tensor] = None,\n",
    "    n_slices: int = 5,\n",
    "    slice_axis: int = 2,\n",
    "    slice_thickness: float = 10.0,\n",
    "    **sinogram_kwargs\n",
    ") -> dict:\n",
    "    \"\"\"Create sinograms for multiple slices through the data.\"\"\"\n",
    "    \n",
    "    # Get slice axis coordinates\n",
    "    z1 = lor_coords[:, slice_axis]\n",
    "    z2 = lor_coords[:, slice_axis + 3]\n",
    "    z_min = torch.min(z1.min(), z2.min())\n",
    "    z_max = torch.max(z1.max(), z2.max())\n",
    "    \n",
    "    # Create slice positions\n",
    "    slice_positions = torch.linspace(z_min + slice_thickness/2, \n",
    "                                   z_max - slice_thickness/2, \n",
    "                                   n_slices)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for i, slice_pos in enumerate(slice_positions):\n",
    "        print(f\"Creating sinogram for slice {i+1}/{n_slices} at position {slice_pos:.1f}mm\")\n",
    "        \n",
    "        sinogram, radial_coords, angular_coords = lor_coords_to_sinogram(\n",
    "            lor_coords=lor_coords,\n",
    "            weights=weights,\n",
    "            slice_position=slice_pos.item(),\n",
    "            slice_thickness=slice_thickness,\n",
    "            slice_axis=slice_axis,\n",
    "            **sinogram_kwargs\n",
    "        )\n",
    "        \n",
    "        results[f'slice_{i}'] = {\n",
    "            'sinogram': sinogram,\n",
    "            'radial_coords': radial_coords,\n",
    "            'angular_coords': angular_coords,\n",
    "            'slice_position': slice_pos.item(),\n",
    "            'statistics': analyze_sinogram_statistics(sinogram, radial_coords, angular_coords)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage function\n",
    "def sanity_check_lor_data(\n",
    "    lor_coords: torch.Tensor,\n",
    "    weights: Optional[torch.Tensor] = None,\n",
    "    slice_thickness: float = 20.0\n",
    ") -> None:\n",
    "    \"\"\"Comprehensive sanity check of LOR data using sinogram analysis.\"\"\"\n",
    "    \n",
    "    print(\"=== LOR Data Sanity Check ===\")\n",
    "    print(f\"Total LORs: {lor_coords.shape[0]}\")\n",
    "    \n",
    "    if weights is not None:\n",
    "        print(f\"Total counts: {weights.sum():.0f}\")\n",
    "        print(f\"Average counts per LOR: {weights.mean():.2f}\")\n",
    "    \n",
    "    # Create sinogram for central slice\n",
    "    sinogram, radial_coords, angular_coords = lor_coords_to_sinogram(\n",
    "        lor_coords=lor_coords,\n",
    "        weights=weights,\n",
    "        slice_thickness=slice_thickness,\n",
    "        n_radial_bins=256,\n",
    "        n_angular_bins=180\n",
    "    )\n",
    "    \n",
    "    # Analyze statistics\n",
    "    stats = analyze_sinogram_statistics(sinogram, radial_coords, angular_coords)\n",
    "    \n",
    "    print(\"\\n=== Sinogram Statistics ===\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_sinogram(sinogram, radial_coords, angular_coords, \n",
    "                      title=\"Central Slice Sinogram\")\n",
    "    \n",
    "    # Check for common issues\n",
    "    print(\"\\n=== Data Quality Checks ===\")\n",
    "    \n",
    "    if stats['non_zero_bins'] < stats['total_bins'] * 0.1:\n",
    "        print(\"⚠️  Very sparse sinogram - check if LOR coordinates are correct\")\n",
    "    \n",
    "    if stats['max_counts'] > stats['mean_counts'] * 100:\n",
    "        print(\"⚠️  Very uneven count distribution - check for hot spots\")\n",
    "    \n",
    "    if stats['radial_range_mm'][1] > 1000:\n",
    "        print(\"⚠️  Very large radial range - check coordinate units (should be mm)\")\n",
    "    \n",
    "    print(\"✅ Sanity check complete!\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4f13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create full 3D sinogram\n",
    "sinogram_3d, radial_coords, angular_coords, axial_coords = lor_coords_to_3d_sinogram(\n",
    "    lor_coords=filtered_coordinates,\n",
    "    weights=None,  # or your count weights\n",
    "    n_radial_bins=128,    # s direction\n",
    "    n_angular_bins=180,    # φ direction (0-180°)\n",
    "    n_axial_bins=32       # z direction\n",
    ")\n",
    "\n",
    "print(f\"3D sinogram shape: {sinogram_3d.shape}\")  # (z, φ, s)\n",
    "\n",
    "# Comprehensive analysis\n",
    "sanity_check_3d_lor_data(filtered_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acdd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import parallelproj\\\n",
    "\n",
    "def osem_pet_reconstruction(lors, \n",
    "                           voxel_size=(2.0, 2.0, 2.0),\n",
    "                           image_shape=(128, 128, 64),\n",
    "                           image_origin=None,\n",
    "                           attenuation_map=None,\n",
    "                           psf_fwhm=None,\n",
    "                           psf_kernel=None,\n",
    "                           n_subsets=8,\n",
    "                           n_iterations=10,\n",
    "                           device='cpu'):\n",
    "    \"\"\"\n",
    "    OSEM reconstruction for PET data using parallelproj joseph3d functions with PSF modeling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    lors : np.ndarray\n",
    "        Shape (n_LORs, 6) containing [x1, y1, z1, x2, y2, z2] endpoints\n",
    "    voxel_size : tuple\n",
    "        Voxel dimensions in mm (dx, dy, dz)\n",
    "    image_shape : tuple  \n",
    "        Number of voxels (nx, ny, nz)\n",
    "    image_origin : tuple or None\n",
    "        Image origin in mm. If None, centers image at coordinate origin\n",
    "    attenuation_map : np.ndarray or None\n",
    "        Attenuation coefficients (1/mm) same shape as reconstruction\n",
    "    psf_fwhm : tuple or float or None\n",
    "        PSF FWHM in mm. If tuple: (fwhm_x, fwhm_y, fwhm_z). If float: isotropic PSF. If None: no PSF\n",
    "    psf_kernel : torch.Tensor or None\n",
    "        Custom PSF kernel. If provided, overrides psf_fwhm\n",
    "    n_subsets : int\n",
    "        Number of ordered subsets\n",
    "    n_iterations : int\n",
    "        Number of OSEM iterations\n",
    "    device : str\n",
    "        'cpu' or 'cuda' - device for computations\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    torch.Tensor : Reconstructed image volume\n",
    "    \"\"\"\n",
    "    \n",
    "    # Set up image geometry\n",
    "    nx, ny, nz = image_shape\n",
    "    dx, dy, dz = voxel_size\n",
    "    \n",
    "    if image_origin is None:\n",
    "        # Center image at coordinate origin (following parallelproj convention)\n",
    "        image_origin = np.array([-(nx-1)*dx/2, -(ny-1)*dy/2, -(nz-1)*dz/2])\n",
    "    else:\n",
    "        image_origin = np.array(image_origin)\n",
    "    \n",
    "    # Convert to torch tensors and move to device\n",
    "    torch_device = torch.device(device)\n",
    "    dr = torch.tensor(voxel_size, dtype=torch.float32, device=torch_device)\n",
    "    \n",
    "    # Initialize uniform image (small positive value to avoid division by zero)\n",
    "    image = torch.ones(image_shape, dtype=torch.float32, device=torch_device) * 0.1\n",
    "    \n",
    "    # Convert LOR endpoints to torch tensors\n",
    "    lors_tensor = torch.tensor(lors, dtype=torch.float32)\n",
    "    start_points = lors_tensor[:, :3]  # xyz1\n",
    "    end_points = lors_tensor[:, 3:]    # xyz2\n",
    "    n_lors = lors.shape[0]\n",
    "    \n",
    "    # Convert attenuation map if provided\n",
    "    if attenuation_map is not None:\n",
    "        attenuation_map = torch.tensor(attenuation_map, dtype=torch.float32, device=torch_device)\n",
    "    \n",
    "    # Set up PSF convolution\n",
    "    psf_conv = None\n",
    "    if psf_kernel is not None:\n",
    "        # Use custom PSF kernel\n",
    "        psf_conv = create_psf_convolution(psf_kernel, torch_device)\n",
    "    elif psf_fwhm is not None:\n",
    "        # Create Gaussian PSF from FWHM\n",
    "        psf_conv = create_gaussian_psf_convolution(psf_fwhm, voxel_size, torch_device)\n",
    "    \n",
    "    # Create subset indices\n",
    "    indices = torch.arange(n_lors)\n",
    "    subset_indices = [indices[i::n_subsets] for i in range(n_subsets)]\n",
    "    \n",
    "    print(f\"Starting OSEM reconstruction:\")\n",
    "    print(f\"Image shape: {image_shape}, Voxel size: {voxel_size}\")\n",
    "    print(f\"Number of LORs: {n_lors}, Subsets: {n_subsets}, Iterations: {n_iterations}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    \n",
    "    for iteration in range(n_iterations):\n",
    "        print(f\"Iteration {iteration + 1}/{n_iterations}\")\n",
    "        \n",
    "        for subset_idx, subset in enumerate(subset_indices):\n",
    "            if len(subset) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Get LORs for this subset\n",
    "            subset_starts = start_points[subset].to(torch_device)\n",
    "            subset_ends = end_points[subset].to(torch_device)\n",
    "            \n",
    "            # Apply PSF to current image estimate for forward projection\n",
    "            if psf_conv is not None:\n",
    "                image_psf = apply_psf_forward(image, psf_conv)\n",
    "            else:\n",
    "                image_psf = image\n",
    "            \n",
    "            # Forward projection: A * PSF * x\n",
    "            forward_proj = parallelproj.joseph3d_fwd(\n",
    "                subset_starts,\n",
    "                subset_ends,\n",
    "                image_psf,\n",
    "                image_origin,\n",
    "                dr\n",
    "            )\n",
    "            \n",
    "            # Apply attenuation correction to forward projection\n",
    "            if attenuation_map is not None:\n",
    "                # Calculate attenuation line integrals\n",
    "                atten_proj = parallelproj.joseph3d_fwd(\n",
    "                    subset_starts,\n",
    "                    subset_ends,\n",
    "                    attenuation_map,\n",
    "                    image_origin,\n",
    "                    dr\n",
    "                )\n",
    "                # Apply attenuation factors (exp(-line integral))\n",
    "                forward_proj = forward_proj * torch.exp(-atten_proj)\n",
    "            \n",
    "            # Avoid division by zero\n",
    "            forward_proj = torch.clamp(forward_proj, min=1e-8)\n",
    "            \n",
    "            # Measured data for this subset (assuming uniform counts for demonstration)\n",
    "            # In practice, you would provide actual measured counts\n",
    "            measured_counts = torch.ones(len(subset), dtype=torch.float32, device=torch_device)\n",
    "            \n",
    "            # Ratio of measured to calculated\n",
    "            ratio = measured_counts / forward_proj\n",
    "            \n",
    "            # Backproject the ratio: PSF^T * A^T * (y/Ax)\n",
    "            backproj_ratio = parallelproj.joseph3d_back(\n",
    "                subset_starts,\n",
    "                subset_ends,\n",
    "                image_shape,\n",
    "                image_origin,\n",
    "                dr,\n",
    "                ratio\n",
    "            )\n",
    "            \n",
    "            # Apply PSF transpose to backprojection\n",
    "            if psf_conv is not None:\n",
    "                backproj_ratio = apply_psf_backward(backproj_ratio, psf_conv)\n",
    "            \n",
    "            # Sensitivity image: PSF^T * A^T * 1\n",
    "            ones = torch.ones(len(subset), dtype=torch.float32, device=torch_device)\n",
    "            sensitivity = parallelproj.joseph3d_back(\n",
    "                subset_starts,\n",
    "                subset_ends,\n",
    "                image_shape,\n",
    "                image_origin,\n",
    "                dr,\n",
    "                ones\n",
    "            )\n",
    "            \n",
    "            # Apply PSF transpose to sensitivity\n",
    "            if psf_conv is not None:\n",
    "                sensitivity = apply_psf_backward(sensitivity, psf_conv)\n",
    "            \n",
    "            # Apply attenuation correction to sensitivity\n",
    "            if attenuation_map is not None:\n",
    "                # Backproject the attenuation factors\n",
    "                atten_factors = torch.exp(-atten_proj)\n",
    "                atten_sensitivity = parallelproj.joseph3d_back(\n",
    "                    subset_starts,\n",
    "                    subset_ends,\n",
    "                    image_shape,\n",
    "                    image_origin,\n",
    "                    dr,\n",
    "                    atten_factors\n",
    "                )\n",
    "                # Correct the sensitivity and backprojection\n",
    "                sensitivity = atten_sensitivity\n",
    "                # Note: In full implementation, you might want to handle this differently\n",
    "                # depending on your exact attenuation correction approach\n",
    "            \n",
    "            # Avoid division by zero in sensitivity\n",
    "            sensitivity = torch.clamp(sensitivity, min=1e-8)\n",
    "            \n",
    "            # OSEM update: x_new = x_old * (A^T(y/Ax)) / (A^T(1))\n",
    "            image = image * backproj_ratio / sensitivity\n",
    "            \n",
    "            # Ensure non-negative\n",
    "            image = torch.clamp(image, min=0)\n",
    "        \n",
    "        print(f\"  Image sum: {image.sum().item():.3e}, Max: {image.max().item():.3e}\")\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def create_gaussian_psf_convolution(fwhm, voxel_size, device):\n",
    "    \"\"\"Create 3D Gaussian PSF convolution layer.\"\"\"\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    # Convert FWHM to sigma\n",
    "    if isinstance(fwhm, (int, float)):\n",
    "        fwhm = (fwhm, fwhm, fwhm)\n",
    "    \n",
    "    # Convert FWHM from mm to voxels\n",
    "    sigma_voxels = []\n",
    "    for i in range(3):\n",
    "        sigma_mm = fwhm[i] / (2 * np.sqrt(2 * np.log(2)))  # FWHM to sigma\n",
    "        sigma_voxels.append(sigma_mm / voxel_size[i])  # mm to voxels\n",
    "    \n",
    "    # Create 3D Gaussian kernel\n",
    "    kernel_size = [max(5, int(6 * s)) for s in sigma_voxels]  # 6 sigma coverage\n",
    "    # Ensure odd kernel sizes\n",
    "    kernel_size = [k + 1 if k % 2 == 0 else k for k in kernel_size]\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    coords = []\n",
    "    for i, (size, sigma) in enumerate(zip(kernel_size, sigma_voxels)):\n",
    "        coord = torch.arange(size, dtype=torch.float32, device=device) - size // 2\n",
    "        coords.append(coord)\n",
    "    \n",
    "    # Create 3D meshgrid\n",
    "    z_grid, y_grid, x_grid = torch.meshgrid(coords[2], coords[1], coords[0], indexing='ij')\n",
    "    \n",
    "    # Calculate 3D Gaussian\n",
    "    kernel = torch.exp(-(x_grid**2 / (2 * sigma_voxels[0]**2) + \n",
    "                        y_grid**2 / (2 * sigma_voxels[1]**2) + \n",
    "                        z_grid**2 / (2 * sigma_voxels[2]**2)))\n",
    "    \n",
    "    # Normalize kernel\n",
    "    kernel = kernel / kernel.sum()\n",
    "    \n",
    "    # Reshape for conv3d: (out_channels, in_channels, depth, height, width)\n",
    "    kernel = kernel.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "\n",
    "def create_psf_convolution(psf_kernel, device):\n",
    "    \"\"\"Create PSF convolution from custom kernel.\"\"\"\n",
    "    if isinstance(psf_kernel, np.ndarray):\n",
    "        psf_kernel = torch.tensor(psf_kernel, dtype=torch.float32, device=device)\n",
    "    else:\n",
    "        psf_kernel = psf_kernel.to(device)\n",
    "    \n",
    "    # Normalize kernel\n",
    "    psf_kernel = psf_kernel / psf_kernel.sum()\n",
    "    \n",
    "    # Reshape for conv3d if needed\n",
    "    if psf_kernel.dim() == 3:\n",
    "        psf_kernel = psf_kernel.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    return psf_kernel\n",
    "\n",
    "\n",
    "def apply_psf_forward(image, psf_kernel):\n",
    "    \"\"\"Apply PSF convolution (forward direction).\"\"\"\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    # Add batch and channel dimensions for conv3d\n",
    "    image_batch = image.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Apply convolution with appropriate padding\n",
    "    pad_size = [(k.size(-1-i)//2, k.size(-1-i)//2) for i, k in enumerate([psf_kernel]*3)]\n",
    "    pad_size = [p for pair in pad_size for p in pair]  # Flatten\n",
    "    \n",
    "    image_padded = F.pad(image_batch, pad_size, mode='reflect')\n",
    "    result = F.conv3d(image_padded, psf_kernel)\n",
    "    \n",
    "    # Remove batch and channel dimensions\n",
    "    return result.squeeze(0).squeeze(0)\n",
    "\n",
    "\n",
    "def apply_psf_backward(backproj, psf_kernel):\n",
    "    \"\"\"Apply PSF transpose (backward direction).\"\"\"\n",
    "    import torch.nn.functional as F\n",
    "    \n",
    "    # Add batch and channel dimensions\n",
    "    backproj_batch = backproj.unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    # Apply transpose convolution (same as convolution with flipped kernel)\n",
    "    # For symmetric Gaussian PSF, transpose is the same as forward\n",
    "    pad_size = [(k.size(-1-i)//2, k.size(-1-i)//2) for i, k in enumerate([psf_kernel]*3)]\n",
    "    pad_size = [p for pair in pad_size for p in pair]  # Flatten\n",
    "    \n",
    "    backproj_padded = F.pad(backproj_batch, pad_size, mode='reflect')\n",
    "    result = F.conv3d(backproj_padded, psf_kernel)\n",
    "    \n",
    "    # Remove batch and channel dimensions\n",
    "    return result.squeeze(0).squeeze(0)\n",
    "   \n",
    "# result = osem_pet_reconstruction(\n",
    "#     lors=filtered_coordinates.cpu().numpy(),\n",
    "#     # lors=lors,\n",
    "#     voxel_size=(voxel_size, voxel_size, voxel_size),\n",
    "#     image_shape=voxel_space,\n",
    "#     # image_shape=image_shape,\n",
    "#     attenuation_map=atten_map,\n",
    "#     psf_fwhm=(3.0, 3.0, 3.0),  # PSF FWHM in mm (x, y, z)\n",
    "#     n_subsets=1,\n",
    "#     n_iterations=20,\n",
    "#     device='cpu'  # Use 'cuda' if available and supported\n",
    "# )\n",
    "# print(f\"Reconstruction complete. Final image shape: {result.shape}\")\n",
    "# print(f\"Final image stats - Sum: {result.sum().item():.3e}, Max: {result.max().item():.3e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798ac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cross_sections_interactive(result.cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytomography_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
