{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b18667e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: False\n",
      "Current device: cpu\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "from __future__ import annotations\n",
    "import torch    \n",
    "import pytomography\n",
    "from pytomography.metadata import ObjectMeta\n",
    "from pytomography.metadata.PET import PETLMProjMeta\n",
    "from pytomography.projectors.PET import PETLMSystemMatrix\n",
    "from pytomography.algorithms import OSEM, MLEM\n",
    "from pytomography.io.PET import gate, shared\n",
    "from pytomography.likelihoods import PoissonLogLikelihood\n",
    "import os\n",
    "from pytomography.transforms.shared import GaussianFilter\n",
    "import matplotlib.pyplot as plt\n",
    "from pytomography.utils import sss\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "torch.cuda.is_available = lambda: False\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "pytomography.device = 'cpu'\n",
    "print(f\"Current device: {pytomography.device}\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fa5eb2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualisation Functions\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "\n",
    "def visualize_voxel_tensor_3d(voxel_tensor, initial_min_threshold=None, initial_max_threshold=None, \n",
    "                               voxel_size_mm=1.0, world_origin=None, min_threshold=None, max_threshold=None):\n",
    "    \"\"\"\n",
    "    Interactive 3D visualization of voxel tensor with dual threshold sliders.\n",
    "\n",
    "    Args:\n",
    "        voxel_tensor: (nx, ny, nz) numpy array with voxel counts\n",
    "        initial_min_threshold: Initial minimum threshold value for the slider (default: min_val)\n",
    "        initial_max_threshold: Initial maximum threshold value for the slider (default: max_val)\n",
    "        voxel_size_mm: Size of each voxel in mm (default: 1.0mm)\n",
    "        world_origin: (x_min, y_min, z_min) world coordinates of voxel (0,0,0) (optional)\n",
    "        min_threshold: Minimum threshold value for slider range (optional)\n",
    "        max_threshold: Maximum threshold value for slider range (optional)\n",
    "    \"\"\"\n",
    "    # Extract non-zero voxel coordinates and values\n",
    "    coords = np.where(voxel_tensor > 0)\n",
    "    x_coords, y_coords, z_coords = coords\n",
    "    values = voxel_tensor[coords]\n",
    "\n",
    "    # Convert voxel indices to world coordinates if world_origin provided\n",
    "    if world_origin is not None:\n",
    "        x_min, y_min, z_min = world_origin\n",
    "        x_coords_world = x_coords * voxel_size_mm + x_min\n",
    "        y_coords_world = y_coords * voxel_size_mm + y_min\n",
    "        z_coords_world = z_coords * voxel_size_mm + z_min\n",
    "        coord_suffix = \" (mm)\"\n",
    "    else:\n",
    "        x_coords_world = x_coords * voxel_size_mm\n",
    "        y_coords_world = y_coords * voxel_size_mm\n",
    "        z_coords_world = z_coords * voxel_size_mm\n",
    "        coord_suffix = f\" (×{voxel_size_mm}mm)\"\n",
    "\n",
    "    # Get value range for sliders\n",
    "    min_val = float(np.min(values))\n",
    "    max_val = float(np.max(values))\n",
    "\n",
    "    # Use user-specified min/max threshold range if provided\n",
    "    slider_min = min_threshold if min_threshold is not None else min_val\n",
    "    slider_max = max_threshold if max_threshold is not None else max_val\n",
    "\n",
    "    # Set initial thresholds with defaults\n",
    "    if initial_min_threshold is None:\n",
    "        initial_min_threshold = slider_min\n",
    "    else:\n",
    "        initial_min_threshold = max(slider_min, min(slider_max, float(initial_min_threshold)))\n",
    "    \n",
    "    if initial_max_threshold is None:\n",
    "        initial_max_threshold = slider_max\n",
    "    else:\n",
    "        initial_max_threshold = max(slider_min, min(slider_max, float(initial_max_threshold)))\n",
    "\n",
    "    # Ensure min <= max\n",
    "    if initial_min_threshold > initial_max_threshold:\n",
    "        initial_min_threshold, initial_max_threshold = initial_max_threshold, initial_min_threshold\n",
    "\n",
    "    print(f\"Voxel value range: {min_val} to {max_val}\")\n",
    "    print(f\"Total non-zero voxels: {len(values)}\")\n",
    "    print(f\"Initial thresholds: {initial_min_threshold} to {initial_max_threshold}\")\n",
    "    print(f\"Slider range: {slider_min} to {slider_max}\")\n",
    "    print(f\"Voxel resolution: {voxel_size_mm}mm\")\n",
    "\n",
    "    def update_plot(min_thresh, max_thresh):\n",
    "        # Ensure min <= max\n",
    "        if min_thresh > max_thresh:\n",
    "            min_thresh, max_thresh = max_thresh, min_thresh\n",
    "\n",
    "        # Filter voxels within threshold range\n",
    "        mask = (values >= min_thresh) & (values <= max_thresh)\n",
    "        if not np.any(mask):\n",
    "            print(f\"No voxels in threshold range [{min_thresh}, {max_thresh}]\")\n",
    "            return\n",
    "\n",
    "        filtered_x = x_coords_world[mask]\n",
    "        filtered_y = y_coords_world[mask]\n",
    "        filtered_z = z_coords_world[mask]\n",
    "        filtered_values = values[mask]\n",
    "\n",
    "        # Create 3D scatter plot\n",
    "        fig = go.Figure(data=go.Scatter3d(\n",
    "            x=filtered_x,\n",
    "            y=filtered_y,\n",
    "            z=filtered_z,\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=1,\n",
    "                color=filtered_values,\n",
    "                colorscale='Viridis',\n",
    "                opacity=0.8,\n",
    "                colorbar=dict(title=\"Voxel Count\"),\n",
    "                line=dict(width=0)\n",
    "            ),\n",
    "            text=[f'Count: {v}' for v in filtered_values],\n",
    "            hovertemplate='<b>Voxel (%{x:.1f}, %{y:.1f}, %{z:.1f})</b><br>%{text}<extra></extra>'\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f'3D Voxel Visualization (Range: [{min_thresh:.6f}, {max_thresh:.6f}], Showing: {len(filtered_values)} voxels)',\n",
    "            scene=dict(\n",
    "                xaxis_title=f'X{coord_suffix}',\n",
    "                yaxis_title=f'Y{coord_suffix}',\n",
    "                zaxis_title=f'Z{coord_suffix}',\n",
    "                camera=dict(\n",
    "                    eye=dict(x=1.5, y=1.5, z=1.5)\n",
    "                ),\n",
    "                aspectmode='cube'\n",
    "            ),\n",
    "            width=800,\n",
    "            height=600\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    # Create interactive sliders with linked constraints\n",
    "    min_threshold_slider = FloatSlider(\n",
    "        value=initial_min_threshold,\n",
    "        min=slider_min,\n",
    "        max=slider_max,\n",
    "        step=0.01,\n",
    "        description='Min Threshold:',\n",
    "        continuous_update=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    max_threshold_slider = FloatSlider(\n",
    "        value=initial_max_threshold,\n",
    "        min=slider_min,\n",
    "        max=slider_max,\n",
    "        step=0.01,\n",
    "        description='Max Threshold:',\n",
    "        continuous_update=False,\n",
    "        style={'description_width': 'initial'}\n",
    "    )\n",
    "\n",
    "    # Link sliders to maintain min <= max constraint\n",
    "    def on_min_change(change):\n",
    "        if change['new'] > max_threshold_slider.value:\n",
    "            max_threshold_slider.value = change['new']\n",
    "\n",
    "    def on_max_change(change):\n",
    "        if change['new'] < min_threshold_slider.value:\n",
    "            min_threshold_slider.value = change['new']\n",
    "\n",
    "    min_threshold_slider.observe(on_min_change, names='value')\n",
    "    max_threshold_slider.observe(on_max_change, names='value')\n",
    "\n",
    "    interact(update_plot, \n",
    "             min_thresh=min_threshold_slider, \n",
    "             max_thresh=max_threshold_slider)\n",
    "\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "\n",
    "def plot_cross_sections_interactive(numpy_array, vmax=None, title=\"Orthogonal Cross Sections\"):\n",
    "    \"\"\"\n",
    "    Create an interactive 3D cross-section viewer for a 3D numpy array.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    numpy_array : np.ndarray\n",
    "        3D numpy array to visualize (shape: nx, ny, nz)\n",
    "    vmax : float, optional\n",
    "        Maximum value for color scale. If None, uses array maximum\n",
    "    title : str, optional\n",
    "        Title for the plot\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ensure input is numpy array\n",
    "    if not isinstance(numpy_array, np.ndarray):\n",
    "        raise ValueError(\"Input must be a numpy array\")\n",
    "    \n",
    "    if numpy_array.ndim != 3:\n",
    "        raise ValueError(\"Input must be a 3D array\")\n",
    "    \n",
    "    nx, ny, nz = numpy_array.shape\n",
    "    \n",
    "    # Set default vmax if not provided\n",
    "    if vmax is None:\n",
    "        vmax = numpy_array.max()\n",
    "    \n",
    "    def plot_cross_sections_horizontal(x_idx=nx//2, y_idx=ny//2, z_idx=nz//2, \n",
    "                                     vmax_slider=vmax, cmap='Magma'):\n",
    "        fig = make_subplots(rows=1, cols=3, subplot_titles=[\n",
    "            f'XY plane @ z={z_idx}',\n",
    "            f'XZ plane @ y={y_idx}',\n",
    "            f'YZ plane @ x={x_idx}'\n",
    "        ])\n",
    "\n",
    "        # XY plane at z=z_idx\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=numpy_array[:, :, z_idx].T,\n",
    "            colorscale=cmap,\n",
    "            zmax=vmax_slider,\n",
    "            zmin=0,\n",
    "            showscale=True,\n",
    "            name=f'XY @ z={z_idx}'\n",
    "        ), row=1, col=1)\n",
    "\n",
    "        # XZ plane at y=y_idx\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=numpy_array[:, y_idx, :].T,\n",
    "            colorscale=cmap,\n",
    "            zmax=vmax_slider,\n",
    "            zmin=0,\n",
    "            showscale=True,\n",
    "            name=f'XZ @ y={y_idx}'\n",
    "        ), row=1, col=2)\n",
    "\n",
    "        # YZ plane at x=x_idx\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=numpy_array[x_idx, :, :].T,\n",
    "            colorscale=cmap,\n",
    "            zmax=vmax_slider,\n",
    "            zmin=0,\n",
    "            showscale=True,\n",
    "            name=f'YZ @ x={x_idx}'\n",
    "        ), row=1, col=3)\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=1200,\n",
    "            height=400,\n",
    "            title_text=title\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "    # Create interactive widget\n",
    "    interact(\n",
    "        plot_cross_sections_horizontal,\n",
    "        x_idx=IntSlider(min=0, max=nx-1, step=1, value=nx//2, description='X index'),\n",
    "        y_idx=IntSlider(min=0, max=ny-1, step=1, value=ny//2, description='Y index'),\n",
    "        z_idx=IntSlider(min=0, max=nz-1, step=1, value=nz//2, description='Z index'),\n",
    "        vmax_slider=FloatSlider(min=0, max=numpy_array.max(), step=0.01, value=vmax, description='vmax'),\n",
    "        cmap=['Magma','Greys', 'Viridis', 'Cividis', 'Plasma']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16df6757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data Shape (pairs, coords) : (62660, 6)\n",
      "\n",
      "Filtered shape: torch.Size([6591, 6])\n",
      "\n",
      "x range: min=-278.1294250488281, max=278.1666564941406\n",
      "y range: min=-278.4194641113281, max=277.8843688964844\n",
      "z range: min=-147.99453735351562, max=147.9492950439453\n"
     ]
    }
   ],
   "source": [
    "# Initial Loading, Filtering, and Coordinate Range Calculation\n",
    "import numpy as np\n",
    "\n",
    "# Load coordinates\n",
    "coordinates = np.load(fr\"C:\\Users\\h\\Desktop\\PET_Recons\\Reconstructions\\ground_truth.npy\")\n",
    "\n",
    "# Confirm shape should be (pairs, coords=6), coords are (x1, y1, z1, x2, y2, z2)\n",
    "print(f\"\\nData Shape (pairs, coords) : {coordinates.shape}\\n\")  \n",
    "\n",
    "# Remove pairs where any coordinate value is exactly 0\n",
    "filtered_coordinates = coordinates[~np.any(coordinates == 0, axis=1)]\n",
    "filtered_coordinates = torch.from_numpy(filtered_coordinates).float()\n",
    "# filtered_coordinates = filtered_coordinates[:100,:]\n",
    "print(f\"Filtered shape: {filtered_coordinates.shape}\\n\")\n",
    "\n",
    "# Extract all x, y, z pairs - Coordinates are in the order (x1, y1, z1, x2, y2, z2)\n",
    "all_xyz = filtered_coordinates.reshape(-1, 3) # Reshape to (pairs, 3) for (x, y, z)\n",
    "x_vals, y_vals, z_vals = all_xyz[:, 0], all_xyz[:, 1], all_xyz[:, 2]\n",
    "print(f\"x range: min={x_vals.min()}, max={x_vals.max()}\")\n",
    "print(f\"y range: min={y_vals.min()}, max={y_vals.max()}\")\n",
    "print(f\"z range: min={z_vals.min()}, max={z_vals.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "45f9ff0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artificial intersecting lines\n",
    "\n",
    "import torch\n",
    "import math\n",
    "\n",
    "def create_intersecting_lines(counts=1000, intersection_point=(0, 0, 0), coord_range=(100, 100, 100)):\n",
    "    \"\"\"\n",
    "    Create a torch tensor of shape (counts, 6) containing lines that all intersect at a specified point.\n",
    "    \n",
    "    Args:\n",
    "        counts: Number of lines to generate\n",
    "        intersection_point: (x, y, z) coordinates where all lines intersect\n",
    "        coord_range: (x_range, y_range, z_range) maximum absolute values for coordinates\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: Shape (counts, 6) with format [x1, y1, z1, x2, y2, z2] per row\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to tensors\n",
    "    intersection = torch.tensor(intersection_point, dtype=torch.float32)\n",
    "    ranges = torch.tensor(coord_range, dtype=torch.float32)\n",
    "    \n",
    "    # Generate random unit directions for each line\n",
    "    # Using normal distribution then normalizing gives uniform distribution on sphere\n",
    "    directions = torch.randn(counts, 3)\n",
    "    directions = directions / torch.norm(directions, dim=1, keepdim=True)\n",
    "    \n",
    "    # Generate random distances for each endpoint from intersection point\n",
    "    # Use different distances for each end of the line\n",
    "    distances1 = torch.rand(counts, 1) * ranges.max()  # Distance for first endpoint\n",
    "    distances2 = torch.rand(counts, 1) * ranges.max()  # Distance for second endpoint\n",
    "    \n",
    "    # Calculate endpoints\n",
    "    endpoint1 = intersection + distances1 * directions\n",
    "    endpoint2 = intersection - distances2 * directions\n",
    "    \n",
    "    # Clamp coordinates to stay within specified ranges\n",
    "    endpoint1 = torch.clamp(endpoint1, -ranges, ranges)\n",
    "    endpoint2 = torch.clamp(endpoint2, -ranges, ranges)\n",
    "    \n",
    "    # Combine into final tensor shape (counts, 6)\n",
    "    lines = torch.cat([endpoint1, endpoint2], dim=1)\n",
    "    \n",
    "    return lines.float()\n",
    "\n",
    "# Generate default tensor\n",
    "# lines_tensor = create_intersecting_lines()\n",
    "# print(f\"Generated tensor shape: {lines_tensor.shape}\")\n",
    "# print(f\"First 5 lines:\")\n",
    "# print(lines_tensor[:5])\n",
    "\n",
    "# Verify lines intersect at origin (check a few lines)\n",
    "def verify_intersection(lines, intersection_point=(0, 0, 0)):\n",
    "    \"\"\"Verify that lines pass through the intersection point\"\"\"\n",
    "    intersection = torch.tensor(intersection_point, dtype=torch.float32)\n",
    "    \n",
    "    for i in range(min(5, len(lines))):\n",
    "        p1 = lines[i, :3]\n",
    "        p2 = lines[i, 3:]\n",
    "        \n",
    "        # Parametric line equation: point = p1 + t*(p2-p1)\n",
    "        # Find t where line passes closest to intersection\n",
    "        direction = p2 - p1\n",
    "        to_intersection = intersection - p1\n",
    "        \n",
    "        # t = dot(to_intersection, direction) / dot(direction, direction)\n",
    "        t = torch.dot(to_intersection, direction) / torch.dot(direction, direction)\n",
    "        closest_point = p1 + t * direction\n",
    "        \n",
    "        distance = torch.norm(closest_point - intersection)\n",
    "        print(f\"Line {i}: closest distance to intersection = {distance:.6f}\")\n",
    "\n",
    "# print(\"\\nVerification (should be very close to 0):\")\n",
    "# verify_intersection(lines_tensor)\n",
    "\n",
    "# custom_lines = create_intersecting_lines(\n",
    "#     counts=1000, \n",
    "#     intersection_point=(10, -5, 20), \n",
    "#     coord_range=(50, 75, 30)\n",
    "# )\n",
    "\n",
    "# custom_lines.shape\n",
    "# filtered_coordinates = custom_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "79c0efee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # FAKE DATA GENERATION FOR TESTING\n",
    "# # Create a 1000x2 tensor with random integers, ensuring pairs are never equal\n",
    "# detector_ids = torch.full((1000, 2), 0, dtype=torch.long)\n",
    "# detector_ids[:, 0] = 3\n",
    "# detector_ids[:, 1] = 6\n",
    "# detector_ids = torch.randint(low=0, high=64*8, size=(1000, 2))\n",
    "# print(detector_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1c3e6913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel size: 4.0mm\n",
      "Voxel shape: (140, 140, 74) (nx, ny, nz)\n",
      "Voxel tensor shape: (140, 140, 74)\n",
      "x range: min=-278.1294250488281, max=278.1666564941406\n",
      "y range: min=-278.4194641113281, max=277.8843688964844\n",
      "z range: min=-147.99453735351562, max=147.9492950439453\n"
     ]
    }
   ],
   "source": [
    "# Data shape extraction and basic 3d backprojection\n",
    "voxel_size = 4.0\n",
    "\n",
    "def binary_rasterize_lors_3d_dda(pairs_coords, voxel_size_mm=1.0):\n",
    "    \"\"\"\n",
    "    Rasterize lines of response into 3D voxel space using exact 3D DDA traversal.\n",
    "    \n",
    "    Args:\n",
    "        pairs_coords: (N, 6) array where each row is [x1,y1,z1,x2,y2,z2]\n",
    "        voxel_size_mm: Size of each voxel in mm (default: 1.0mm)\n",
    "    \n",
    "    Returns:\n",
    "        voxel_tensor: (nx, ny, nz) array with line traversal counts\n",
    "    \"\"\"\n",
    "    # World coordinate ranges (mm)\n",
    "    all_xyz = pairs_coords.reshape(-1, 3) # Reshape to (pairs, 3) for (x, y, z)\n",
    "    x_vals, y_vals, z_vals = all_xyz[:, 0], all_xyz[:, 1], all_xyz[:, 2]\n",
    "\n",
    "    x_min = x_vals.min()\n",
    "    x_max = x_vals.max()\n",
    "    y_min = y_vals.min()\n",
    "    y_max = y_vals.max()\n",
    "    z_min = z_vals.min()\n",
    "    z_max = z_vals.max()\n",
    "\n",
    "    # Round the min and max values to voxel boundaries\n",
    "    x_min = np.floor(x_min / voxel_size_mm) * voxel_size_mm\n",
    "    x_max = np.ceil(x_max / voxel_size_mm) * voxel_size_mm\n",
    "    y_min = np.floor(y_min / voxel_size_mm) * voxel_size_mm\n",
    "    y_max = np.ceil(y_max / voxel_size_mm) * voxel_size_mm\n",
    "    z_min = np.floor(z_min / voxel_size_mm) * voxel_size_mm\n",
    "    z_max = np.ceil(z_max / voxel_size_mm) * voxel_size_mm\n",
    "\n",
    "    # Calculate voxel tensor shape based on resolution\n",
    "    nx = int((x_max - x_min) / voxel_size_mm)\n",
    "    ny = int((y_max - y_min) / voxel_size_mm)\n",
    "    nz = int((z_max - z_min) / voxel_size_mm)\n",
    "    \n",
    "    voxel_shape = (nx, ny, nz)\n",
    "    print(f\"Voxel size: {voxel_size_mm}mm\")\n",
    "    print(f\"Voxel shape: {voxel_shape} (nx, ny, nz)\")\n",
    "    \n",
    "    voxel_tensor = np.zeros(voxel_shape, dtype=np.int32)\n",
    "    \n",
    "    # Coordinate transformation: world -> voxel indices\n",
    "    def world_to_voxel(coords):\n",
    "        x, y, z = coords[:, 0], coords[:, 1], coords[:, 2]\n",
    "        vx = (x - x_min) / voxel_size_mm\n",
    "        vy = (y - y_min) / voxel_size_mm\n",
    "        vz = (z - z_min) / voxel_size_mm\n",
    "        return np.column_stack([vx, vy, vz])\n",
    "    \n",
    "    def dda_3d(p1, p2):\n",
    "        \"\"\"3D DDA algorithm - returns list of (x,y,z) voxel indices along line\"\"\"\n",
    "        x1, y1, z1 = p1\n",
    "        x2, y2, z2 = p2\n",
    "        \n",
    "        # Direction and step sizes\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        dz = z2 - z1\n",
    "        \n",
    "        # Number of steps is maximum of absolute differences\n",
    "        steps = int(max(abs(dx), abs(dy), abs(dz)))\n",
    "        if steps == 0:\n",
    "            return [(int(round(x1)), int(round(y1)), int(round(z1)))]\n",
    "        \n",
    "        # Step increments\n",
    "        x_inc = dx / steps\n",
    "        y_inc = dy / steps\n",
    "        z_inc = dz / steps\n",
    "        \n",
    "        voxels = []\n",
    "        x, y, z = x1, y1, z1\n",
    "        \n",
    "        for _ in range(steps + 1):\n",
    "            vx, vy, vz = int(round(x)), int(round(y)), int(round(z))\n",
    "            \n",
    "            # Check bounds\n",
    "            if 0 <= vx < nx and 0 <= vy < ny and 0 <= vz < nz:\n",
    "                voxels.append((vx, vy, vz))\n",
    "            \n",
    "            x += x_inc\n",
    "            y += y_inc\n",
    "            z += z_inc\n",
    "        \n",
    "        return voxels\n",
    "    \n",
    "    # Transform all coordinates to voxel space\n",
    "    points1 = world_to_voxel(pairs_coords[:, :3])  # First points\n",
    "    points2 = world_to_voxel(pairs_coords[:, 3:])  # Second points\n",
    "    \n",
    "    # Process each LOR\n",
    "    for i in range(len(pairs_coords)):\n",
    "        p1 = points1[i]\n",
    "        p2 = points2[i]\n",
    "        \n",
    "        # Get voxels along this line\n",
    "        voxels = dda_3d(p1, p2)\n",
    "        \n",
    "        # Increment voxel counts\n",
    "        for vx, vy, vz in voxels:\n",
    "            voxel_tensor[vx, vy, vz] += 1\n",
    "    \n",
    "    return voxel_tensor\n",
    "\n",
    "voxel_tensor = binary_rasterize_lors_3d_dda(filtered_coordinates, voxel_size_mm=voxel_size)\n",
    "print(f\"Voxel tensor shape: {voxel_tensor.shape}\")\n",
    "\n",
    "# Specify object space for reconstruction\n",
    "# voxel_space = voxel_tensor.shape # voxels\n",
    "voxel_space = voxel_tensor.shape # voxels\n",
    "\n",
    "print(f\"x range: min={x_vals.min()}, max={x_vals.max()}\")\n",
    "print(f\"y range: min={y_vals.min()}, max={y_vals.max()}\")\n",
    "print(f\"z range: min={z_vals.min()}, max={z_vals.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6cadc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualizing all 6591 LORs\n",
      "\n",
      "Distance Filtering (threshold: 5.0 mm):\n",
      "Original LORs: 6591\n",
      "Valid LORs: 3987\n",
      "Filtered out: 2604\n",
      "Filtering efficiency: 60.5%\n",
      "\n",
      "Interactive slider created for LOR indices 0-6590\n",
      "Distance threshold: 5.0 mm\n",
      "Camera orientation will persist during slider interactions!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b33b98659944f4a1253b199dd5f6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=1, description='LOR Index:', layout=Layout(width='400px'), max=6590, style=Slid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  193 28543]\n"
     ]
    }
   ],
   "source": [
    "# Configure and validate virtual PET scanner geometry\n",
    "\n",
    "info = {'min_rsector_difference': 0,\n",
    " 'crystal_length': 20.0,\n",
    " 'radius': 337.0,\n",
    " 'crystalTransNr': 8,\n",
    " 'crystalTransSpacing': 4.0,\n",
    " 'crystalAxialNr': 8,\n",
    " 'crystalAxialSpacing': 4.0,\n",
    " 'submoduleAxialNr': 1,\n",
    " 'submoduleAxialSpacing': 0,\n",
    " 'submoduleTransNr': 1,\n",
    " 'submoduleTransSpacing': 0,\n",
    " 'moduleTransNr': 1,\n",
    " 'moduleTransSpacing': 0.0,\n",
    " 'moduleAxialNr': 8,\n",
    " 'moduleAxialSpacing': 32.25,\n",
    " 'rsectorTransNr': 56,\n",
    " 'rsectorAxialNr': 1,\n",
    " 'NrCrystalsPerRing': 448,\n",
    " 'NrRings': 64,\n",
    " 'firstCrystalAxis': 1}\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import FigureWidget\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from ipywidgets import interact, IntSlider, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize_lors_and_detectors_3d(coordinates, scanner_info, sample_lors=None, \n",
    "                                   highlight_detector_ids=None, highlight_color='green',\n",
    "                                   validate_lor_index=None, verbose=True, \n",
    "                                   distance_threshold=5.0):\n",
    "    \"\"\"\n",
    "    3D visualization of LOR endpoints and PET detector positions with interactive slider for LOR validation.\n",
    "    Camera orientation is preserved during slider interactions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    coordinates : numpy.ndarray\n",
    "        Shape (n_lors, 6) containing [x1, y1, z1, x2, y2, z2] for each LOR\n",
    "    scanner_info : dict\n",
    "        Dictionary containing scanner geometry parameters\n",
    "    sample_lors : int, optional\n",
    "        Number of LORs to sample for visualization (default: all)\n",
    "    highlight_detector_ids : list or set, optional\n",
    "        Detector IDs to highlight with different color\n",
    "    highlight_color : str, optional\n",
    "        Color for highlighted detectors (default: 'green')\n",
    "    validate_lor_index : int, optional\n",
    "        Initial LOR index to display in the slider (default: 0)\n",
    "    verbose : bool, optional\n",
    "        If False, suppresses all print outputs (default: True)\n",
    "    distance_threshold : float, optional\n",
    "        Maximum allowed distance (in mm) between extended endpoints and assigned detectors.\n",
    "        LOR pairs where either endpoint exceeds this distance are excluded (default: 5.0)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (full_detector_id_pairs, valid_detector_id_pairs, valid_lor_indices)\n",
    "    \"\"\"\n",
    "    \n",
    "    def extend_endpoints_to_radius(endpoints1, endpoints2, target_radius):\n",
    "        \"\"\"\n",
    "        Extend LOR endpoints along the LOR direction until they reach the target radius.\n",
    "        \"\"\"\n",
    "        # Calculate LOR direction vectors (from endpoint1 to endpoint2)\n",
    "        lor_directions = endpoints2 - endpoints1\n",
    "        lor_lengths = np.linalg.norm(lor_directions, axis=1, keepdims=True)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        lor_lengths = np.where(lor_lengths == 0, 1e-10, lor_lengths)\n",
    "        lor_unit_vectors = lor_directions / lor_lengths\n",
    "        \n",
    "        def find_radius_intersection(start_point, direction, target_radius):\n",
    "            \"\"\"Find where a ray intersects the cylinder at target_radius.\"\"\"\n",
    "            x0, y0, z0 = start_point.T\n",
    "            dx, dy, dz = direction.T\n",
    "            \n",
    "            # Quadratic equation coefficients: at² + bt + c = 0\n",
    "            a = dx**2 + dy**2\n",
    "            b = 2 * (x0 * dx + y0 * dy)\n",
    "            c = x0**2 + y0**2 - target_radius**2\n",
    "            \n",
    "            # Solve quadratic equation\n",
    "            valid_mask = np.abs(a) > 1e-10  # Direction has xy component\n",
    "            result = start_point.copy()\n",
    "            \n",
    "            if np.any(valid_mask):\n",
    "                a_valid = a[valid_mask]\n",
    "                b_valid = b[valid_mask]\n",
    "                c_valid = c[valid_mask]\n",
    "                \n",
    "                discriminant = b_valid**2 - 4 * a_valid * c_valid\n",
    "                solvable_mask = discriminant >= 0\n",
    "                \n",
    "                if np.any(solvable_mask):\n",
    "                    sqrt_disc = np.sqrt(discriminant[solvable_mask])\n",
    "                    t1 = (-b_valid[solvable_mask] + sqrt_disc) / (2 * a_valid[solvable_mask])\n",
    "                    t2 = (-b_valid[solvable_mask] - sqrt_disc) / (2 * a_valid[solvable_mask])\n",
    "                    \n",
    "                    # Choose the positive t value\n",
    "                    t_chosen = np.where(\n",
    "                        (t1 > 0) & (t2 > 0), np.minimum(t1, t2),\n",
    "                        np.where(t1 > 0, t1, \n",
    "                                np.where(t2 > 0, t2, np.maximum(t1, t2)))\n",
    "                    )\n",
    "                    \n",
    "                    # Calculate intersection points\n",
    "                    valid_indices = np.where(valid_mask)[0]\n",
    "                    solvable_indices = valid_indices[solvable_mask]\n",
    "                    \n",
    "                    result[solvable_indices] = (start_point[solvable_indices] + \n",
    "                                            t_chosen.reshape(-1, 1) * direction[solvable_indices])\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        # Extend endpoints in OPPOSITE directions along the LOR line\n",
    "        extended_endpoints1 = find_radius_intersection(endpoints1, -lor_unit_vectors, target_radius)\n",
    "        extended_endpoints2 = find_radius_intersection(endpoints2, lor_unit_vectors, target_radius)\n",
    "        \n",
    "        return extended_endpoints1, extended_endpoints2\n",
    "    \n",
    "    # Sample LORs if specified\n",
    "    if sample_lors is not None and sample_lors < coordinates.shape[0]:\n",
    "        indices = np.random.choice(coordinates.shape[0], sample_lors, replace=False)\n",
    "        coordinates_sample = coordinates[indices]\n",
    "        if verbose:\n",
    "            print(f\"Sampling {sample_lors} LORs out of {coordinates.shape[0]} total\")\n",
    "    else:\n",
    "        coordinates_sample = coordinates\n",
    "        if verbose:\n",
    "            print(f\"Visualizing all {coordinates.shape[0]} LORs\")\n",
    "    \n",
    "    # Extract LOR endpoints\n",
    "    n_lors = coordinates_sample.shape[0]\n",
    "    endpoint1 = coordinates_sample[:, :3]  # [x1, y1, z1]\n",
    "    endpoint2 = coordinates_sample[:, 3:]  # [x2, y2, z2]\n",
    "    \n",
    "    # Generate detector positions and IDs\n",
    "    radius = scanner_info['radius']\n",
    "    crystals_per_ring = scanner_info['NrCrystalsPerRing']\n",
    "    n_rings = scanner_info['NrRings']\n",
    "    crystal_axial_spacing = scanner_info['crystalAxialSpacing']\n",
    "    module_axial_spacing = scanner_info['moduleAxialSpacing']\n",
    "    module_axial_nr = scanner_info['moduleAxialNr']\n",
    "    crystals_axial_per_module = scanner_info['crystalAxialNr']\n",
    "    \n",
    "    # Calculate total axial extent\n",
    "    crystals_per_module_axial = crystals_axial_per_module\n",
    "    modules_span = (module_axial_nr - 1) * module_axial_spacing\n",
    "    crystals_within_modules_span = (crystals_per_module_axial - 1) * crystal_axial_spacing * module_axial_nr\n",
    "    total_axial_extent = modules_span + crystals_within_modules_span\n",
    "    \n",
    "    # Generate detector positions and IDs\n",
    "    detector_positions = []\n",
    "    detector_ids = []\n",
    "    \n",
    "    for ring in range(n_rings):\n",
    "        # Calculate z position for this ring\n",
    "        if n_rings == 1:\n",
    "            z_pos = 0.0\n",
    "        else:\n",
    "            z_pos = -total_axial_extent/2 + ring * (total_axial_extent / (n_rings - 1))\n",
    "        \n",
    "        for crystal in range(crystals_per_ring):\n",
    "            # Calculate angular position\n",
    "            angle = 2 * np.pi * crystal / crystals_per_ring\n",
    "            \n",
    "            # Convert to Cartesian coordinates\n",
    "            x_pos = radius * np.cos(angle)\n",
    "            y_pos = radius * np.sin(angle)\n",
    "            \n",
    "            detector_positions.append([x_pos, y_pos, z_pos])\n",
    "            detector_id = ring * crystals_per_ring + crystal\n",
    "            detector_ids.append(detector_id)\n",
    "    \n",
    "    detector_positions = np.array(detector_positions)\n",
    "    detector_ids = np.array(detector_ids)\n",
    "    \n",
    "    # Prepare detector colors\n",
    "    if highlight_detector_ids is not None:\n",
    "        highlight_set = set(highlight_detector_ids)\n",
    "        highlight_mask = np.isin(detector_ids, list(highlight_set))\n",
    "        regular_mask = ~highlight_mask\n",
    "        regular_positions = detector_positions[regular_mask]\n",
    "        highlight_positions = detector_positions[highlight_mask]\n",
    "        regular_ids = detector_ids[regular_mask]\n",
    "        highlight_ids = detector_ids[highlight_mask]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Highlighting {len(highlight_positions)} detectors: {sorted(highlight_set)}\")\n",
    "    else:\n",
    "        regular_positions = detector_positions\n",
    "        highlight_positions = np.array([]).reshape(0, 3)\n",
    "        regular_ids = detector_ids\n",
    "        highlight_ids = np.array([])\n",
    "    \n",
    "    # Calculate detector assignments for all LORs\n",
    "    extended_endpoint1, extended_endpoint2 = extend_endpoints_to_radius(endpoint1, endpoint2, radius)\n",
    "    \n",
    "    # Build KDTree for efficient nearest neighbor search\n",
    "    kdtree = cKDTree(detector_positions)\n",
    "    \n",
    "    # Find nearest detector for each extended endpoint\n",
    "    _, nearest_indices1 = kdtree.query(extended_endpoint1)\n",
    "    _, nearest_indices2 = kdtree.query(extended_endpoint2)\n",
    "    \n",
    "    # Convert to detector IDs\n",
    "    full_detector_id_pairs = np.column_stack([\n",
    "        detector_ids[nearest_indices1],\n",
    "        detector_ids[nearest_indices2]\n",
    "    ])\n",
    "    \n",
    "    # Calculate distances and apply filtering\n",
    "    distances1 = np.linalg.norm(extended_endpoint1 - detector_positions[nearest_indices1], axis=1)\n",
    "    distances2 = np.linalg.norm(extended_endpoint2 - detector_positions[nearest_indices2], axis=1)\n",
    "    valid_mask = (distances1 <= distance_threshold) & (distances2 <= distance_threshold)\n",
    "    \n",
    "    valid_detector_id_pairs = full_detector_id_pairs[valid_mask]\n",
    "    valid_lor_indices = np.where(valid_mask)[0]\n",
    "    \n",
    "    # Print initial statistics\n",
    "    if verbose:\n",
    "        print(f\"\\nDistance Filtering (threshold: {distance_threshold} mm):\")\n",
    "        print(f\"Original LORs: {len(full_detector_id_pairs)}\")\n",
    "        print(f\"Valid LORs: {len(valid_detector_id_pairs)}\")\n",
    "        print(f\"Filtered out: {len(full_detector_id_pairs) - len(valid_detector_id_pairs)}\")\n",
    "        print(f\"Filtering efficiency: {len(valid_detector_id_pairs)/len(full_detector_id_pairs)*100:.1f}%\")\n",
    "    \n",
    "    # Create the persistent FigureWidget\n",
    "    fig = FigureWidget()\n",
    "    \n",
    "    # Add static background elements that don't change with slider\n",
    "    all_lor_points = np.vstack([endpoint1, endpoint2])\n",
    "    bg_opacity = 0.3\n",
    "    detector_opacity = 0.4\n",
    "    \n",
    "    # Add ALL LOR endpoints (static background)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_lor_points[:, 0],\n",
    "        y=all_lor_points[:, 1],\n",
    "        z=all_lor_points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color='red',\n",
    "            opacity=bg_opacity,\n",
    "            line=dict(width=0)\n",
    "        ),\n",
    "        name=f'All LOR Endpoints',\n",
    "        hovertemplate='<b>LOR Endpoint</b><br>' +\n",
    "                      'X: %{x:.1f} mm<br>' +\n",
    "                      'Y: %{y:.1f} mm<br>' +\n",
    "                      'Z: %{z:.1f} mm<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Add regular detectors (static)\n",
    "    if len(regular_positions) > 0:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=regular_positions[:, 0],\n",
    "            y=regular_positions[:, 1],\n",
    "            z=regular_positions[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=3,\n",
    "                color='blue',\n",
    "                opacity=detector_opacity,\n",
    "                symbol='diamond',\n",
    "                line=dict(width=0)\n",
    "            ),\n",
    "            name='Regular Detectors',\n",
    "            customdata=regular_ids,\n",
    "            hovertemplate='<b>Detector ID: %{customdata}</b><br>' +\n",
    "                          'X: %{x:.1f} mm<br>' +\n",
    "                          'Y: %{y:.1f} mm<br>' +\n",
    "                          'Z: %{z:.1f} mm<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    # Add highlighted detectors (static)\n",
    "    if len(highlight_positions) > 0:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=highlight_positions[:, 0],\n",
    "            y=highlight_positions[:, 1],\n",
    "            z=highlight_positions[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=highlight_color,\n",
    "                opacity=1.0,\n",
    "                symbol='diamond',\n",
    "                line=dict(width=1, color='black')\n",
    "            ),\n",
    "            name=f'Highlighted Detectors ({highlight_color})',\n",
    "            customdata=highlight_ids,\n",
    "            hovertemplate='<b>Highlighted Detector ID: %{customdata}</b><br>' +\n",
    "                          'X: %{x:.1f} mm<br>' +\n",
    "                          'Y: %{y:.1f} mm<br>' +\n",
    "                          'Z: %{z:.1f} mm<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    # Add placeholder traces for dynamic LOR validation elements\n",
    "    # These will be updated by the slider function\n",
    "    trace_names = [\n",
    "        'LOR - Original Endpoints',\n",
    "        'LOR - Extended Endpoints', \n",
    "        'LOR - Assigned Detectors',\n",
    "        'LOR - Original Line',\n",
    "        'Extension Path 1',\n",
    "        'Extension Path 2', \n",
    "        'Detector Assignment 1',\n",
    "        'Detector Assignment 2'\n",
    "    ]\n",
    "    \n",
    "    # Add empty traces that will be populated by slider updates\n",
    "    for i, name in enumerate(trace_names):\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[], y=[], z=[],\n",
    "            mode='markers' if 'Endpoints' in name or 'Detectors' in name else 'lines',\n",
    "            name=name,\n",
    "            showlegend=True if 'Endpoints' in name or 'Detectors' in name else False\n",
    "        ))\n",
    "    \n",
    "    # Set initial layout\n",
    "    fig.update_layout(\n",
    "        title=f'3D LOR Validation with Persistent Camera View',\n",
    "        scene=dict(\n",
    "            xaxis_title='X (mm)',\n",
    "            yaxis_title='Y (mm)',\n",
    "            zaxis_title='Z (mm)',\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.5, y=1.5, z=1.5),\n",
    "                center=dict(x=0, y=0, z=0),\n",
    "                up=dict(x=0, y=0, z=1)\n",
    "            ),\n",
    "            aspectmode='cube'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        legend=dict(\n",
    "            x=0.02,\n",
    "            y=0.98,\n",
    "            bgcolor='rgba(255,255,255,0.8)'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def update_lor_visualization(lor_index):\n",
    "        \"\"\"Update only the LOR-specific traces without recreating the entire plot\"\"\"\n",
    "        \n",
    "        # Get validation data for the selected LOR\n",
    "        validation_data = None\n",
    "        if lor_index < coordinates_sample.shape[0]:\n",
    "            # Check if this LOR survived filtering\n",
    "            original_lor_survived = lor_index in valid_lor_indices\n",
    "            \n",
    "            # Get the specific LOR's data (regardless of whether it passed filtering)\n",
    "            val_endpoint1 = coordinates_sample[lor_index, :3]\n",
    "            val_endpoint2 = coordinates_sample[lor_index, 3:]\n",
    "            val_extended1 = extended_endpoint1[lor_index]\n",
    "            val_extended2 = extended_endpoint2[lor_index]\n",
    "            \n",
    "            # Get detector assignments\n",
    "            val_detector1_id = full_detector_id_pairs[lor_index, 0]\n",
    "            val_detector2_id = full_detector_id_pairs[lor_index, 1]\n",
    "            \n",
    "            # Find detector positions\n",
    "            det_idx1 = np.where(detector_ids == val_detector1_id)[0][0]\n",
    "            det_idx2 = np.where(detector_ids == val_detector2_id)[0][0]\n",
    "            val_detector1_pos = detector_positions[det_idx1]\n",
    "            val_detector2_pos = detector_positions[det_idx2]\n",
    "            \n",
    "            validation_data = {\n",
    "                'original_endpoints': [val_endpoint1, val_endpoint2],\n",
    "                'extended_endpoints': [val_extended1, val_extended2],\n",
    "                'detector_ids': [val_detector1_id, val_detector2_id],\n",
    "                'detector_positions': [val_detector1_pos, val_detector2_pos],\n",
    "                'distances': [distances1[lor_index], distances2[lor_index]],\n",
    "                'within_threshold': original_lor_survived\n",
    "            }\n",
    "        \n",
    "        # Update traces with new data\n",
    "        if validation_data:\n",
    "            orig_ep1, orig_ep2 = validation_data['original_endpoints']\n",
    "            ext_ep1, ext_ep2 = validation_data['extended_endpoints']\n",
    "            det_pos1, det_pos2 = validation_data['detector_positions']\n",
    "            det_id1, det_id2 = validation_data['detector_ids']\n",
    "            is_valid = validation_data['within_threshold']\n",
    "            dist1, dist2 = validation_data['distances']\n",
    "            \n",
    "            # Color coding based on validity\n",
    "            endpoint_color = 'orange' if is_valid else 'red'\n",
    "            extended_color = 'purple' if is_valid else 'magenta'\n",
    "            detector_color = 'yellow' if is_valid else 'pink'\n",
    "            line_color_1 = 'orange' if is_valid else 'red'\n",
    "            line_color_2 = 'purple' if is_valid else 'magenta'\n",
    "            \n",
    "            status_text = f\"VALID (≤{distance_threshold}mm)\" if is_valid else f\"FILTERED (>{distance_threshold}mm)\"\n",
    "            \n",
    "            # Update dynamic traces (starting from index after static traces)\n",
    "            static_traces = 3 if highlight_detector_ids is not None else 2\n",
    "            \n",
    "            # Original endpoints\n",
    "            with fig.batch_update():\n",
    "                fig.data[static_traces].update(\n",
    "                    x=[orig_ep1[0], orig_ep2[0]],\n",
    "                    y=[orig_ep1[1], orig_ep2[1]],\n",
    "                    z=[orig_ep1[2], orig_ep2[2]],\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=endpoint_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='circle',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Original Endpoints ({status_text})',\n",
    "                    hovertemplate='<b>Original Endpoint</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # Extended endpoints\n",
    "                fig.data[static_traces + 1].update(\n",
    "                    x=[ext_ep1[0], ext_ep2[0]],\n",
    "                    y=[ext_ep1[1], ext_ep2[1]],\n",
    "                    z=[ext_ep1[2], ext_ep2[2]],\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=extended_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='square',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Extended Endpoints',\n",
    "                    hovertemplate='<b>Extended Endpoint</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # Assigned detectors\n",
    "                fig.data[static_traces + 2].update(\n",
    "                    x=[det_pos1[0], det_pos2[0]],\n",
    "                    y=[det_pos1[1], det_pos2[1]],\n",
    "                    z=[det_pos1[2], det_pos2[2]],\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=detector_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='diamond-open',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Assigned Detectors (d1:{dist1:.1f}mm, d2:{dist2:.1f}mm)',\n",
    "                    customdata=[det_id1, det_id2],\n",
    "                    hovertemplate='<b>Assigned Detector ID: %{customdata}</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # Original LOR line\n",
    "                fig.data[static_traces + 3].update(\n",
    "                    x=[orig_ep1[0], orig_ep2[0]],\n",
    "                    y=[orig_ep1[1], orig_ep2[1]],\n",
    "                    z=[orig_ep1[2], orig_ep2[2]],\n",
    "                    line=dict(color='black', width=6),\n",
    "                    name=f'LOR {lor_index} - Original LOR Line'\n",
    "                )\n",
    "                \n",
    "                # Extension paths\n",
    "                fig.data[static_traces + 4].update(\n",
    "                    x=[orig_ep1[0], ext_ep1[0]],\n",
    "                    y=[orig_ep1[1], ext_ep1[1]],\n",
    "                    z=[orig_ep1[2], ext_ep1[2]],\n",
    "                    line=dict(color=line_color_1, width=4, dash='dash')\n",
    "                )\n",
    "                \n",
    "                fig.data[static_traces + 5].update(\n",
    "                    x=[orig_ep2[0], ext_ep2[0]],\n",
    "                    y=[orig_ep2[1], ext_ep2[1]],\n",
    "                    z=[orig_ep2[2], ext_ep2[2]],\n",
    "                    line=dict(color=line_color_1, width=4, dash='dash')\n",
    "                )\n",
    "                \n",
    "                # Detector assignment paths\n",
    "                fig.data[static_traces + 6].update(\n",
    "                    x=[ext_ep1[0], det_pos1[0]],\n",
    "                    y=[ext_ep1[1], det_pos1[1]],\n",
    "                    z=[ext_ep1[2], det_pos1[2]],\n",
    "                    line=dict(color=line_color_2, width=4, dash='dot')\n",
    "                )\n",
    "                \n",
    "                fig.data[static_traces + 7].update(\n",
    "                    x=[ext_ep2[0], det_pos2[0]],\n",
    "                    y=[ext_ep2[1], det_pos2[1]],\n",
    "                    z=[ext_ep2[2], det_pos2[2]],\n",
    "                    line=dict(color=line_color_2, width=4, dash='dot')\n",
    "                )\n",
    "                \n",
    "                # Update title\n",
    "                fig.layout.title.text = f'3D LOR Validation: LOR {lor_index} ({status_text})'\n",
    "        \n",
    "        else:\n",
    "            # Clear dynamic traces if no validation data\n",
    "            static_traces = 3 if highlight_detector_ids is not None else 2\n",
    "            with fig.batch_update():\n",
    "                for i in range(len(trace_names)):\n",
    "                    fig.data[static_traces + i].update(x=[], y=[], z=[])\n",
    "                fig.layout.title.text = f'3D LOR Validation: LOR {lor_index} (INVALID INDEX)'\n",
    "    \n",
    "    # Set up the interactive slider\n",
    "    max_lor_index = coordinates_sample.shape[0] - 1\n",
    "    initial_lor_index = validate_lor_index if validate_lor_index is not None else 0\n",
    "    \n",
    "    slider = IntSlider(\n",
    "        value=initial_lor_index,\n",
    "        min=0,\n",
    "        max=max_lor_index,\n",
    "        step=1,\n",
    "        description='LOR Index:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nInteractive slider created for LOR indices 0-{max_lor_index}\")\n",
    "        print(f\"Distance threshold: {distance_threshold} mm\")\n",
    "        print(\"Camera orientation will persist during slider interactions!\")\n",
    "    \n",
    "    # Connect slider to update function\n",
    "    def on_slider_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            update_lor_visualization(change['new'])\n",
    "    \n",
    "    slider.observe(on_slider_change)\n",
    "    \n",
    "    # Initialize with the starting LOR\n",
    "    update_lor_visualization(initial_lor_index)\n",
    "    \n",
    "    # Display the widget and figure\n",
    "    display(VBox([slider, fig]))\n",
    "    \n",
    "    return full_detector_id_pairs, valid_detector_id_pairs, valid_lor_indices\n",
    "\n",
    "\n",
    "\n",
    "# Silent mode with 5mm distance filtering (default):\n",
    "# fig, full_detector_ids, valid_detector_ids, valid_indices = visualize_lors_and_detectors_3d(\n",
    "#     filtered_coordinates.numpy(), info, verbose=False)\n",
    "\n",
    "# Custom distance threshold with verbose output:\n",
    "# fig, full_detector_ids, valid_detector_ids, valid_indices = visualize_lors_and_detectors_3d(\n",
    "#     filtered_coordinates.numpy(), info, distance_threshold=3.0, verbose=True)\n",
    "\n",
    "# Interactive slider mode with distance filtering:\n",
    "# fig, full_detector_ids, valid_detector_ids, valid_indices = visualize_lors_and_detectors_3d(\n",
    "#     filtered_coordinates.numpy(), info, interactive_slider=True, \n",
    "#     distance_threshold=5.0, verbose=True)\n",
    "\n",
    "# Validate specific LOR silently with custom threshold:\n",
    "# fig, full_detector_ids, valid_detector_ids, valid_indices = visualize_lors_and_detectors_3d(\n",
    "#     filtered_coordinates.numpy(), info, validate_lor_index=1, \n",
    "#     distance_threshold=2.0, verbose=False)\n",
    "\n",
    "full_detector_ids, valid_detector_ids, valid_indices = visualize_lors_and_detectors_3d(filtered_coordinates.numpy(), info,\n",
    "                                                    #  highlight_detector_ids=[0, 1, 5, 4370],\n",
    "                                                     verbose=True,\n",
    "                                                    #  verbose=False,\n",
    "                                                     validate_lor_index=1,\n",
    "                                                     distance_threshold=5.0,)\n",
    "\n",
    "print(full_detector_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bb1e4be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detector IDs shape: torch.Size([3987, 2])\n",
      "Detector ID range: 0 to 28670\n",
      "Unique detector IDs: 6945\n",
      "Expected total detectors: 28672\n"
     ]
    }
   ],
   "source": [
    "print(f\"Detector IDs shape: {detector_ids.shape}\")\n",
    "print(f\"Detector ID range: {detector_ids.min()} to {detector_ids.max()}\")\n",
    "print(f\"Unique detector IDs: {len(torch.unique(detector_ids))}\")\n",
    "print(f\"Expected total detectors: {info['NrCrystalsPerRing'] * info['NrRings']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cd584e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional detector assignment along the axial plane first, insead of the circumferencial plane first\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.graph_objs import FigureWidget\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from ipywidgets import interact, IntSlider, VBox\n",
    "from IPython.display import display\n",
    "\n",
    "def visualize_lors_and_detectors_3d_axial_ids(coordinates, scanner_info, sample_lors=None, \n",
    "                                             highlight_detector_ids=None, highlight_color='green',\n",
    "                                             validate_lor_index=None, verbose=True, \n",
    "                                             distance_threshold=5.0):\n",
    "    \"\"\"\n",
    "    3D visualization of LOR endpoints and PET detector positions with interactive slider for LOR validation.\n",
    "    Camera orientation is preserved during slider interactions.\n",
    "    \n",
    "    DETECTOR ID ORDERING: Axial-first (same angular position across rings, then next angular position)\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    coordinates : numpy.ndarray\n",
    "        Shape (n_lors, 6) containing [x1, y1, z1, x2, y2, z2] for each LOR\n",
    "    scanner_info : dict\n",
    "        Dictionary containing scanner geometry parameters\n",
    "    sample_lors : int, optional\n",
    "        Number of LORs to sample for visualization (default: all)\n",
    "    highlight_detector_ids : list or set, optional\n",
    "        Detector IDs to highlight with different color\n",
    "    highlight_color : str, optional\n",
    "        Color for highlighted detectors (default: 'green')\n",
    "    validate_lor_index : int, optional\n",
    "        Initial LOR index to display in the slider (default: 0)\n",
    "    verbose : bool, optional\n",
    "        If False, suppresses all print outputs (default: True)\n",
    "    distance_threshold : float, optional\n",
    "        Maximum allowed distance (in mm) between extended endpoints and assigned detectors.\n",
    "        LOR pairs where either endpoint exceeds this distance are excluded (default: 5.0)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (full_detector_id_pairs, valid_detector_id_pairs, valid_lor_indices)\n",
    "    \"\"\"\n",
    "    \n",
    "    def extend_endpoints_to_radius(endpoints1, endpoints2, target_radius):\n",
    "        \"\"\"\n",
    "        Extend LOR endpoints along the LOR direction until they reach the target radius.\n",
    "        \"\"\"\n",
    "        # Calculate LOR direction vectors (from endpoint1 to endpoint2)\n",
    "        lor_directions = endpoints2 - endpoints1\n",
    "        lor_lengths = np.linalg.norm(lor_directions, axis=1, keepdims=True)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        lor_lengths = np.where(lor_lengths == 0, 1e-10, lor_lengths)\n",
    "        lor_unit_vectors = lor_directions / lor_lengths\n",
    "        \n",
    "        def find_radius_intersection(start_point, direction, target_radius):\n",
    "            \"\"\"Find where a ray intersects the cylinder at target_radius.\"\"\"\n",
    "            x0, y0, z0 = start_point.T\n",
    "            dx, dy, dz = direction.T\n",
    "            \n",
    "            # Quadratic equation coefficients: at² + bt + c = 0\n",
    "            a = dx**2 + dy**2\n",
    "            b = 2 * (x0 * dx + y0 * dy)\n",
    "            c = x0**2 + y0**2 - target_radius**2\n",
    "            \n",
    "            # Solve quadratic equation\n",
    "            valid_mask = np.abs(a) > 1e-10  # Direction has xy component\n",
    "            result = start_point.copy()\n",
    "            \n",
    "            if np.any(valid_mask):\n",
    "                a_valid = a[valid_mask]\n",
    "                b_valid = b[valid_mask]\n",
    "                c_valid = c[valid_mask]\n",
    "                \n",
    "                discriminant = b_valid**2 - 4 * a_valid * c_valid\n",
    "                solvable_mask = discriminant >= 0\n",
    "                \n",
    "                if np.any(solvable_mask):\n",
    "                    sqrt_disc = np.sqrt(discriminant[solvable_mask])\n",
    "                    t1 = (-b_valid[solvable_mask] + sqrt_disc) / (2 * a_valid[solvable_mask])\n",
    "                    t2 = (-b_valid[solvable_mask] - sqrt_disc) / (2 * a_valid[solvable_mask])\n",
    "                    \n",
    "                    # Choose the positive t value\n",
    "                    t_chosen = np.where(\n",
    "                        (t1 > 0) & (t2 > 0), np.minimum(t1, t2),\n",
    "                        np.where(t1 > 0, t1, \n",
    "                                np.where(t2 > 0, t2, np.maximum(t1, t2)))\n",
    "                    )\n",
    "                    \n",
    "                    # Calculate intersection points\n",
    "                    valid_indices = np.where(valid_mask)[0]\n",
    "                    solvable_indices = valid_indices[solvable_mask]\n",
    "                    \n",
    "                    result[solvable_indices] = (start_point[solvable_indices] + \n",
    "                                            t_chosen.reshape(-1, 1) * direction[solvable_indices])\n",
    "            \n",
    "            return result\n",
    "        \n",
    "        # Extend endpoints in OPPOSITE directions along the LOR line\n",
    "        extended_endpoints1 = find_radius_intersection(endpoints1, -lor_unit_vectors, target_radius)\n",
    "        extended_endpoints2 = find_radius_intersection(endpoints2, lor_unit_vectors, target_radius)\n",
    "        \n",
    "        return extended_endpoints1, extended_endpoints2\n",
    "    \n",
    "    # Sample LORs if specified\n",
    "    if sample_lors is not None and sample_lors < coordinates.shape[0]:\n",
    "        indices = np.random.choice(coordinates.shape[0], sample_lors, replace=False)\n",
    "        coordinates_sample = coordinates[indices]\n",
    "        if verbose:\n",
    "            print(f\"Sampling {sample_lors} LORs out of {coordinates.shape[0]} total\")\n",
    "    else:\n",
    "        coordinates_sample = coordinates\n",
    "        if verbose:\n",
    "            print(f\"Visualizing all {coordinates.shape[0]} LORs\")\n",
    "    \n",
    "    # Extract LOR endpoints\n",
    "    n_lors = coordinates_sample.shape[0]\n",
    "    endpoint1 = coordinates_sample[:, :3]  # [x1, y1, z1]\n",
    "    endpoint2 = coordinates_sample[:, 3:]  # [x2, y2, z2]\n",
    "    \n",
    "    # Generate detector positions and IDs with AXIAL-FIRST ordering\n",
    "    radius = scanner_info['radius']\n",
    "    crystals_per_ring = scanner_info['NrCrystalsPerRing']\n",
    "    n_rings = scanner_info['NrRings']\n",
    "    crystal_axial_spacing = scanner_info['crystalAxialSpacing']\n",
    "    module_axial_spacing = scanner_info['moduleAxialSpacing']\n",
    "    module_axial_nr = scanner_info['moduleAxialNr']\n",
    "    crystals_axial_per_module = scanner_info['crystalAxialNr']\n",
    "    \n",
    "    # Calculate total axial extent\n",
    "    crystals_per_module_axial = crystals_axial_per_module\n",
    "    modules_span = (module_axial_nr - 1) * module_axial_spacing\n",
    "    crystals_within_modules_span = (crystals_per_module_axial - 1) * crystal_axial_spacing * module_axial_nr\n",
    "    total_axial_extent = modules_span + crystals_within_modules_span\n",
    "    \n",
    "    # Generate detector positions and IDs with AXIAL-FIRST ordering\n",
    "    detector_positions = []\n",
    "    detector_ids = []\n",
    "    \n",
    "    # CHANGED: Loop over crystals (angular positions) first, then rings (axial positions)\n",
    "    for crystal in range(crystals_per_ring):\n",
    "        # Calculate angular position\n",
    "        angle = 2 * np.pi * crystal / crystals_per_ring\n",
    "        x_base = radius * np.cos(angle)\n",
    "        y_base = radius * np.sin(angle)\n",
    "        \n",
    "        for ring in range(n_rings):\n",
    "            # Calculate z position for this ring\n",
    "            if n_rings == 1:\n",
    "                z_pos = 0.0\n",
    "            else:\n",
    "                z_pos = -total_axial_extent/2 + ring * (total_axial_extent / (n_rings - 1))\n",
    "            \n",
    "            detector_positions.append([x_base, y_base, z_pos])\n",
    "            # CHANGED: ID assignment is now crystal * n_rings + ring (axial-first)\n",
    "            detector_id = crystal * n_rings + ring\n",
    "            detector_ids.append(detector_id)\n",
    "    \n",
    "    detector_positions = np.array(detector_positions)\n",
    "    detector_ids = np.array(detector_ids)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nDetector ID Ordering: AXIAL-FIRST\")\n",
    "        print(f\"Example: Angular position 0 has detector IDs: {list(range(0, n_rings))}\")\n",
    "        print(f\"Example: Angular position 1 has detector IDs: {list(range(n_rings, 2*n_rings))}\")\n",
    "    \n",
    "    # Prepare detector colors\n",
    "    if highlight_detector_ids is not None:\n",
    "        highlight_set = set(highlight_detector_ids)\n",
    "        highlight_mask = np.isin(detector_ids, list(highlight_set))\n",
    "        regular_mask = ~highlight_mask\n",
    "        regular_positions = detector_positions[regular_mask]\n",
    "        highlight_positions = detector_positions[highlight_mask]\n",
    "        regular_ids = detector_ids[regular_mask]\n",
    "        highlight_ids = detector_ids[highlight_mask]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Highlighting {len(highlight_positions)} detectors: {sorted(highlight_set)}\")\n",
    "    else:\n",
    "        regular_positions = detector_positions\n",
    "        highlight_positions = np.array([]).reshape(0, 3)\n",
    "        regular_ids = detector_ids\n",
    "        highlight_ids = np.array([])\n",
    "    \n",
    "    # Calculate detector assignments for all LORs\n",
    "    extended_endpoint1, extended_endpoint2 = extend_endpoints_to_radius(endpoint1, endpoint2, radius)\n",
    "    \n",
    "    # Build KDTree for efficient nearest neighbor search\n",
    "    kdtree = cKDTree(detector_positions)\n",
    "    \n",
    "    # Find nearest detector for each extended endpoint\n",
    "    _, nearest_indices1 = kdtree.query(extended_endpoint1)\n",
    "    _, nearest_indices2 = kdtree.query(extended_endpoint2)\n",
    "    \n",
    "    # Convert to detector IDs\n",
    "    full_detector_id_pairs = np.column_stack([\n",
    "        detector_ids[nearest_indices1],\n",
    "        detector_ids[nearest_indices2]\n",
    "    ])\n",
    "    \n",
    "    # Calculate distances and apply filtering\n",
    "    distances1 = np.linalg.norm(extended_endpoint1 - detector_positions[nearest_indices1], axis=1)\n",
    "    distances2 = np.linalg.norm(extended_endpoint2 - detector_positions[nearest_indices2], axis=1)\n",
    "    valid_mask = (distances1 <= distance_threshold) & (distances2 <= distance_threshold)\n",
    "    \n",
    "    valid_detector_id_pairs = full_detector_id_pairs[valid_mask]\n",
    "    valid_lor_indices = np.where(valid_mask)[0]\n",
    "    \n",
    "    # Print initial statistics\n",
    "    if verbose:\n",
    "        print(f\"\\nDistance Filtering (threshold: {distance_threshold} mm):\")\n",
    "        print(f\"Original LORs: {len(full_detector_id_pairs)}\")\n",
    "        print(f\"Valid LORs: {len(valid_detector_id_pairs)}\")\n",
    "        print(f\"Filtered out: {len(full_detector_id_pairs) - len(valid_detector_id_pairs)}\")\n",
    "        print(f\"Filtering efficiency: {len(valid_detector_id_pairs)/len(full_detector_id_pairs)*100:.1f}%\")\n",
    "    \n",
    "    # Create the persistent FigureWidget\n",
    "    fig = FigureWidget()\n",
    "    \n",
    "    # Add static background elements that don't change with slider\n",
    "    all_lor_points = np.vstack([endpoint1, endpoint2])\n",
    "    bg_opacity = 0.3\n",
    "    detector_opacity = 0.4\n",
    "    \n",
    "    # Add ALL LOR endpoints (static background)\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=all_lor_points[:, 0],\n",
    "        y=all_lor_points[:, 1],\n",
    "        z=all_lor_points[:, 2],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,\n",
    "            color='red',\n",
    "            opacity=bg_opacity,\n",
    "            line=dict(width=0)\n",
    "        ),\n",
    "        name=f'All LOR Endpoints',\n",
    "        hovertemplate='<b>LOR Endpoint</b><br>' +\n",
    "                      'X: %{x:.1f} mm<br>' +\n",
    "                      'Y: %{y:.1f} mm<br>' +\n",
    "                      'Z: %{z:.1f} mm<extra></extra>'\n",
    "    ))\n",
    "    \n",
    "    # Add regular detectors (static)\n",
    "    if len(regular_positions) > 0:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=regular_positions[:, 0],\n",
    "            y=regular_positions[:, 1],\n",
    "            z=regular_positions[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=3,\n",
    "                color='blue',\n",
    "                opacity=detector_opacity,\n",
    "                symbol='diamond',\n",
    "                line=dict(width=0)\n",
    "            ),\n",
    "            name='Regular Detectors',\n",
    "            customdata=regular_ids,\n",
    "            hovertemplate='<b>Detector ID: %{customdata}</b><br>' +\n",
    "                          'X: %{x:.1f} mm<br>' +\n",
    "                          'Y: %{y:.1f} mm<br>' +\n",
    "                          'Z: %{z:.1f} mm<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    # Add highlighted detectors (static)\n",
    "    if len(highlight_positions) > 0:\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=highlight_positions[:, 0],\n",
    "            y=highlight_positions[:, 1],\n",
    "            z=highlight_positions[:, 2],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=highlight_color,\n",
    "                opacity=1.0,\n",
    "                symbol='diamond',\n",
    "                line=dict(width=1, color='black')\n",
    "            ),\n",
    "            name=f'Highlighted Detectors ({highlight_color})',\n",
    "            customdata=highlight_ids,\n",
    "            hovertemplate='<b>Highlighted Detector ID: %{customdata}</b><br>' +\n",
    "                          'X: %{x:.1f} mm<br>' +\n",
    "                          'Y: %{y:.1f} mm<br>' +\n",
    "                          'Z: %{z:.1f} mm<extra></extra>'\n",
    "        ))\n",
    "    \n",
    "    # Add placeholder traces for dynamic LOR validation elements\n",
    "    # These will be updated by the slider function\n",
    "    trace_names = [\n",
    "        'LOR - Original Endpoints',\n",
    "        'LOR - Extended Endpoints', \n",
    "        'LOR - Assigned Detectors',\n",
    "        'LOR - Original Line',\n",
    "        'Extension Path 1',\n",
    "        'Extension Path 2', \n",
    "        'Detector Assignment 1',\n",
    "        'Detector Assignment 2'\n",
    "    ]\n",
    "    \n",
    "    # Add empty traces that will be populated by slider updates\n",
    "    for i, name in enumerate(trace_names):\n",
    "        fig.add_trace(go.Scatter3d(\n",
    "            x=[], y=[], z=[],\n",
    "            mode='markers' if 'Endpoints' in name or 'Detectors' in name else 'lines',\n",
    "            name=name,\n",
    "            showlegend=True if 'Endpoints' in name or 'Detectors' in name else False\n",
    "        ))\n",
    "    \n",
    "    # Set initial layout\n",
    "    fig.update_layout(\n",
    "        title=f'3D LOR Validation with Persistent Camera View (Axial ID Ordering)',\n",
    "        scene=dict(\n",
    "            xaxis_title='X (mm)',\n",
    "            yaxis_title='Y (mm)',\n",
    "            zaxis_title='Z (mm)',\n",
    "            camera=dict(\n",
    "                eye=dict(x=1.5, y=1.5, z=1.5),\n",
    "                center=dict(x=0, y=0, z=0),\n",
    "                up=dict(x=0, y=0, z=1)\n",
    "            ),\n",
    "            aspectmode='cube'\n",
    "        ),\n",
    "        width=900,\n",
    "        height=700,\n",
    "        legend=dict(\n",
    "            x=0.02,\n",
    "            y=0.98,\n",
    "            bgcolor='rgba(255,255,255,0.8)'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    def update_lor_visualization(lor_index):\n",
    "        \"\"\"Update only the LOR-specific traces without recreating the entire plot\"\"\"\n",
    "        \n",
    "        # Get validation data for the selected LOR\n",
    "        validation_data = None\n",
    "        if lor_index < coordinates_sample.shape[0]:\n",
    "            # Check if this LOR survived filtering\n",
    "            original_lor_survived = lor_index in valid_lor_indices\n",
    "            \n",
    "            # Get the specific LOR's data (regardless of whether it passed filtering)\n",
    "            val_endpoint1 = coordinates_sample[lor_index, :3]\n",
    "            val_endpoint2 = coordinates_sample[lor_index, 3:]\n",
    "            val_extended1 = extended_endpoint1[lor_index]\n",
    "            val_extended2 = extended_endpoint2[lor_index]\n",
    "            \n",
    "            # Get detector assignments\n",
    "            val_detector1_id = full_detector_id_pairs[lor_index, 0]\n",
    "            val_detector2_id = full_detector_id_pairs[lor_index, 1]\n",
    "            \n",
    "            # Find detector positions\n",
    "            det_idx1 = np.where(detector_ids == val_detector1_id)[0][0]\n",
    "            det_idx2 = np.where(detector_ids == val_detector2_id)[0][0]\n",
    "            val_detector1_pos = detector_positions[det_idx1]\n",
    "            val_detector2_pos = detector_positions[det_idx2]\n",
    "            \n",
    "            validation_data = {\n",
    "                'original_endpoints': [val_endpoint1, val_endpoint2],\n",
    "                'extended_endpoints': [val_extended1, val_extended2],\n",
    "                'detector_ids': [val_detector1_id, val_detector2_id],\n",
    "                'detector_positions': [val_detector1_pos, val_detector2_pos],\n",
    "                'distances': [distances1[lor_index], distances2[lor_index]],\n",
    "                'within_threshold': original_lor_survived\n",
    "            }\n",
    "        \n",
    "        # Update traces with new data\n",
    "        if validation_data:\n",
    "            orig_ep1, orig_ep2 = validation_data['original_endpoints']\n",
    "            ext_ep1, ext_ep2 = validation_data['extended_endpoints']\n",
    "            det_pos1, det_pos2 = validation_data['detector_positions']\n",
    "            det_id1, det_id2 = validation_data['detector_ids']\n",
    "            is_valid = validation_data['within_threshold']\n",
    "            dist1, dist2 = validation_data['distances']\n",
    "            \n",
    "            # Color coding based on validity\n",
    "            endpoint_color = 'orange' if is_valid else 'red'\n",
    "            extended_color = 'purple' if is_valid else 'magenta'\n",
    "            detector_color = 'yellow' if is_valid else 'pink'\n",
    "            line_color_1 = 'orange' if is_valid else 'red'\n",
    "            line_color_2 = 'purple' if is_valid else 'magenta'\n",
    "            \n",
    "            status_text = f\"VALID (≤{distance_threshold}mm)\" if is_valid else f\"FILTERED (>{distance_threshold}mm)\"\n",
    "            \n",
    "            # Update dynamic traces (starting from index after static traces)\n",
    "            static_traces = 3 if highlight_detector_ids is not None else 2\n",
    "            \n",
    "            # Original endpoints\n",
    "            with fig.batch_update():\n",
    "                fig.data[static_traces].update(\n",
    "                    x=[orig_ep1[0], orig_ep2[0]],\n",
    "                    y=[orig_ep1[1], orig_ep2[1]],\n",
    "                    z=[orig_ep1[2], orig_ep2[2]],\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=endpoint_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='circle',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Original Endpoints ({status_text})',\n",
    "                    hovertemplate='<b>Original Endpoint</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # Extended endpoints\n",
    "                fig.data[static_traces + 1].update(\n",
    "                    x=[ext_ep1[0], ext_ep2[0]],\n",
    "                    y=[ext_ep1[1], ext_ep2[1]],\n",
    "                    z=[ext_ep1[2], ext_ep2[2]],\n",
    "                    marker=dict(\n",
    "                        size=6,\n",
    "                        color=extended_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='square',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Extended Endpoints',\n",
    "                    hovertemplate='<b>Extended Endpoint</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # Assigned detectors\n",
    "                fig.data[static_traces + 2].update(\n",
    "                    x=[det_pos1[0], det_pos2[0]],\n",
    "                    y=[det_pos1[1], det_pos2[1]],\n",
    "                    z=[det_pos1[2], det_pos2[2]],\n",
    "                    marker=dict(\n",
    "                        size=8,\n",
    "                        color=detector_color,\n",
    "                        opacity=1.0,\n",
    "                        symbol='diamond-open',\n",
    "                        line=dict(width=2, color='black')\n",
    "                    ),\n",
    "                    name=f'LOR {lor_index} - Assigned Detectors (d1:{dist1:.1f}mm, d2:{dist2:.1f}mm)',\n",
    "                    customdata=[det_id1, det_id2],\n",
    "                    hovertemplate='<b>Assigned Detector ID: %{customdata}</b><br>' +\n",
    "                                  'X: %{x:.1f} mm<br>' +\n",
    "                                  'Y: %{y:.1f} mm<br>' +\n",
    "                                  'Z: %{z:.1f} mm<extra></extra>'\n",
    "                )\n",
    "                \n",
    "                # Original LOR line\n",
    "                fig.data[static_traces + 3].update(\n",
    "                    x=[orig_ep1[0], orig_ep2[0]],\n",
    "                    y=[orig_ep1[1], orig_ep2[1]],\n",
    "                    z=[orig_ep1[2], orig_ep2[2]],\n",
    "                    line=dict(color='black', width=6),\n",
    "                    name=f'LOR {lor_index} - Original LOR Line'\n",
    "                )\n",
    "                \n",
    "                # Extension paths\n",
    "                fig.data[static_traces + 4].update(\n",
    "                    x=[orig_ep1[0], ext_ep1[0]],\n",
    "                    y=[orig_ep1[1], ext_ep1[1]],\n",
    "                    z=[orig_ep1[2], ext_ep1[2]],\n",
    "                    line=dict(color=line_color_1, width=4, dash='dash')\n",
    "                )\n",
    "                \n",
    "                fig.data[static_traces + 5].update(\n",
    "                    x=[orig_ep2[0], ext_ep2[0]],\n",
    "                    y=[orig_ep2[1], ext_ep2[1]],\n",
    "                    z=[orig_ep2[2], ext_ep2[2]],\n",
    "                    line=dict(color=line_color_1, width=4, dash='dash')\n",
    "                )\n",
    "                \n",
    "                # Detector assignment paths\n",
    "                fig.data[static_traces + 6].update(\n",
    "                    x=[ext_ep1[0], det_pos1[0]],\n",
    "                    y=[ext_ep1[1], det_pos1[1]],\n",
    "                    z=[ext_ep1[2], det_pos1[2]],\n",
    "                    line=dict(color=line_color_2, width=4, dash='dot')\n",
    "                )\n",
    "                \n",
    "                fig.data[static_traces + 7].update(\n",
    "                    x=[ext_ep2[0], det_pos2[0]],\n",
    "                    y=[ext_ep2[1], det_pos2[1]],\n",
    "                    z=[ext_ep2[2], det_pos2[2]],\n",
    "                    line=dict(color=line_color_2, width=4, dash='dot')\n",
    "                )\n",
    "                \n",
    "                # Update title\n",
    "                fig.layout.title.text = f'3D LOR Validation: LOR {lor_index} ({status_text}) - Axial ID Ordering'\n",
    "        \n",
    "        else:\n",
    "            # Clear dynamic traces if no validation data\n",
    "            static_traces = 3 if highlight_detector_ids is not None else 2\n",
    "            with fig.batch_update():\n",
    "                for i in range(len(trace_names)):\n",
    "                    fig.data[static_traces + i].update(x=[], y=[], z=[])\n",
    "                fig.layout.title.text = f'3D LOR Validation: LOR {lor_index} (INVALID INDEX) - Axial ID Ordering'\n",
    "    \n",
    "    # Set up the interactive slider\n",
    "    max_lor_index = coordinates_sample.shape[0] - 1\n",
    "    initial_lor_index = validate_lor_index if validate_lor_index is not None else 0\n",
    "    \n",
    "    slider = IntSlider(\n",
    "        value=initial_lor_index,\n",
    "        min=0,\n",
    "        max=max_lor_index,\n",
    "        step=1,\n",
    "        description='LOR Index:',\n",
    "        style={'description_width': 'initial'},\n",
    "        layout={'width': '400px'}\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nInteractive slider created for LOR indices 0-{max_lor_index}\")\n",
    "        print(f\"Distance threshold: {distance_threshold} mm\")\n",
    "        print(\"Camera orientation will persist during slider interactions!\")\n",
    "    \n",
    "    # Connect slider to update function\n",
    "    def on_slider_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            update_lor_visualization(change['new'])\n",
    "    \n",
    "    slider.observe(on_slider_change)\n",
    "    \n",
    "    # Initialize with the starting LOR\n",
    "    update_lor_visualization(initial_lor_index)\n",
    "    \n",
    "    # Display the widget and figure\n",
    "    display(VBox([slider, fig]))\n",
    "    \n",
    "    return full_detector_id_pairs, valid_detector_id_pairs, valid_lor_indices\n",
    "\n",
    "# full_detector_ids, valid_detector_ids, valid_indices = visualize_lors_and_detectors_3d_axial_ids(filtered_coordinates.numpy(), info,\n",
    "#                                              highlight_detector_ids=[0, 1, 5, 4370],\n",
    "#                                                 validate_lor_index=1,\n",
    "#                                                 verbose=False,\n",
    "#                                                 distance_threshold=20.0,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd8960c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3987, 2])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector_ids = torch.tensor(valid_detector_ids)\n",
    "detector_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7ac1034",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_meta = ObjectMeta(\n",
    "    dr=(voxel_size,voxel_size,voxel_size), #mm\n",
    "    shape=voxel_space #voxels\n",
    "    # shape=(128,128,96) #voxels\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1139c5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or Create attenuation maps\n",
    "\n",
    "# atten_map = gate.get_aligned_attenuation_map(os.path.join(path, 'gate_simulation/simple_phantom/umap_mMR_brainSimplePhantom.hv'), object_meta).to(pytomography.device)\n",
    "\n",
    "ones_atten_map = torch.ones(voxel_space)\n",
    "zeros_atten_map = torch.zeros(voxel_space)\n",
    "\n",
    "# Create a half-rectangular attenuation map\n",
    "half_rect_atten_map = torch.zeros(voxel_space)\n",
    "mid_x = voxel_space[0] // 2\n",
    "half_rect_atten_map[:mid_x, :, :] = torch.linspace(0, 0.1, mid_x).view(-1, 1, 1)\n",
    "\n",
    "# Create a gradient attenuation map\n",
    "coords = torch.stack(torch.meshgrid(\n",
    "    torch.arange(voxel_space[0]),\n",
    "    torch.arange(voxel_space[1]),\n",
    "    torch.arange(voxel_space[2]),\n",
    "    indexing='ij'\n",
    "), dim=-1).float()\n",
    "gradient_atten_map = coords.mean(dim=-1)\n",
    "gradient_atten_map = gradient_atten_map / gradient_atten_map.max()\n",
    "\n",
    "# Create a cylindrical attenuation map with radial gradient\n",
    "radius_mm = 278  # cylinder radius in mm\n",
    "height = voxel_space[2] * voxel_size  # cylinder height in mm\n",
    "center_x = voxel_space[0] // 2\n",
    "center_y = voxel_space[1] // 2\n",
    "center_z = voxel_space[2] // 2\n",
    "radius_vox = radius_mm / voxel_size\n",
    "\n",
    "# Generate grid of voxel indices\n",
    "x = torch.arange(voxel_space[0]).float()\n",
    "y = torch.arange(voxel_space[1]).float()\n",
    "z = torch.arange(voxel_space[2]).float()\n",
    "xx, yy, zz = torch.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "# Compute distance from central axis for each voxel\n",
    "dist_from_axis = torch.sqrt((xx - center_x)**2 + (yy - center_y)**2)\n",
    "\n",
    "# Create gradient cylinder attenuation map\n",
    "gradient_cylindrical_atten_map = torch.ones(voxel_space)\n",
    "normalized_dist = dist_from_axis / radius_vox  # Normalize distances to [0,1]\n",
    "\n",
    "# Create radial gradient: high attenuation (1.0) at center, decreasing outward\n",
    "gradient_cylindrical_atten_map = 1.0 - normalized_dist.clone()  # Invert the gradient\n",
    "gradient_cylindrical_atten_map[gradient_cylindrical_atten_map < 0] = 0  # Clip negative values\n",
    "gradient_cylindrical_atten_map[dist_from_axis > radius_vox] = 0  # Set outside cylinder to 0\n",
    "gradient_cylindrical_atten_map /= 100\n",
    "\n",
    "# Also create a solid cylinder for comparison\n",
    "cylindrical_atten_map = torch.zeros(voxel_space)\n",
    "cylindrical_atten_map[dist_from_axis <= radius_vox] = 0.01 # 0.14  cm⁻¹ is the attenuation for dense bone apparently\n",
    "\n",
    "\n",
    "# Create a spherical attenuation map centered at origin\n",
    "def create_spherical_atten_map(voxel_space, voxel_size, radius_mm=None, atten_value=0.1):\n",
    "    \"\"\"\n",
    "    Create a spherical attenuation map centered at the midpoint of voxel space.\n",
    "    \n",
    "    Args:\n",
    "        voxel_space: tuple (x, y, z) dimensions of the voxel grid\n",
    "        voxel_size: size of each voxel in mm\n",
    "        radius_mm: sphere radius in mm. If None, defaults to 1/4 of smallest axis\n",
    "        atten_value: attenuation value inside the sphere (default 0.1)\n",
    "    \n",
    "    Returns:\n",
    "        torch.Tensor: spherical attenuation map with shape voxel_space\n",
    "    \"\"\"\n",
    "    # Calculate default radius if not specified\n",
    "    if radius_mm is None:\n",
    "        min_axis_mm = min(voxel_space) * voxel_size\n",
    "        radius_mm = min_axis_mm / 4\n",
    "    \n",
    "    # Convert radius to voxel units\n",
    "    radius_vox = radius_mm / voxel_size\n",
    "    \n",
    "    # Calculate center coordinates\n",
    "    center_x = voxel_space[0] // 2\n",
    "    center_y = voxel_space[1] // 2\n",
    "    center_z = voxel_space[2] // 2\n",
    "    \n",
    "    # Generate grid of voxel indices\n",
    "    x = torch.arange(voxel_space[0]).float()\n",
    "    y = torch.arange(voxel_space[1]).float()\n",
    "    z = torch.arange(voxel_space[2]).float()\n",
    "    xx, yy, zz = torch.meshgrid(x, y, z, indexing='ij')\n",
    "    \n",
    "    # Compute distance from center for each voxel\n",
    "    dist_from_center = torch.sqrt((xx - center_x)**2 + (yy - center_y)**2 + (zz - center_z)**2)\n",
    "    \n",
    "    # Create spherical attenuation map\n",
    "    spherical_atten_map = torch.zeros(voxel_space)\n",
    "    spherical_atten_map[dist_from_center <= radius_vox] = atten_value\n",
    "    \n",
    "    return spherical_atten_map\n",
    "\n",
    "# Usage example with your existing variables:\n",
    "spherical_atten_map = create_spherical_atten_map(voxel_space, voxel_size, atten_value=0.01)\n",
    "# spherical_atten_map = create_spherical_atten_map(voxel_space, voxel_size, radius_mm=100, atten_value=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c409f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation Weights if Applicable\n",
    "# normalisation_weights = torch.ones((411027456,), dtype=torch.float32).to(pytomography.device)\n",
    "# normalisation_weights = torch.load(os.path.join(path, 'normalization_weights.pt'))\n",
    "# normalisation_weights = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9812bc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input image shape: torch.Size([140, 140, 74])\n",
      "Projections shape: torch.Size([3987])\n",
      "Back projected shape: torch.Size([140, 140, 74])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0139e9c4544de2b3f9239fc03f2b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=70, description='X index', max=139), IntSlider(value=70, description='Y …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# atten_map = half_rect_atten_map.to(pytomography.device)\n",
    "# atten_map = gradient_atten_map.to(pytomography.device)\n",
    "atten_map = cylindrical_atten_map.to(pytomography.device)\n",
    "# atten_map = gradient_cylindrical_atten_map.to(pytomography.device)\n",
    "# atten_map = ones_atten_map.to(pytomography.device)\n",
    "# atten_map = zeros_atten_map.to(pytomography.device)\n",
    "# atten_map = spherical_atten_map.to(pytomography.device)\n",
    "# atten_map = None\n",
    "\n",
    "proj_meta = PETLMProjMeta(\n",
    "    detector_ids,\n",
    "    info,\n",
    "    # weights_sensitivity=normalisation_weights,\n",
    "    )\n",
    "\n",
    "psf_transform = GaussianFilter(3.)\n",
    "\n",
    "system_matrix = PETLMSystemMatrix(\n",
    "       object_meta,\n",
    "       proj_meta,\n",
    "       obj2obj_transforms = [psf_transform],\n",
    "       N_splits=1,\n",
    "       device=pytomography.device,\n",
    "       attenuation_map=atten_map,\n",
    ")\n",
    "\n",
    "initial_image = torch.ones(object_meta.shape)\n",
    "\n",
    "# Forward projection\n",
    "projections = system_matrix.forward(initial_image)\n",
    "\n",
    "# Back projection\n",
    "back_projected = system_matrix.backward(projections)\n",
    "\n",
    "print(f\"Input image shape: {initial_image.shape}\")\n",
    "print(f\"Projections shape: {projections.shape}\")\n",
    "print(f\"Back projected shape: {back_projected.shape}\")\n",
    "\n",
    "plot_cross_sections_interactive(back_projected.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4dfd7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "sinogram_delays  = gate.listmode_to_sinogram(detector_ids, info)\n",
    "sinogram_delays  = gate.smooth_randoms_sinogram(sinogram_delays , info, sigma_r=4, sigma_theta=4, sigma_z=4)\n",
    "lm_delays = shared.sinogram_to_listmode(detector_ids, sinogram_delays , info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d9256f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb6b8fa6c6c4612b48de6ad2887e4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=70, description='X index', max=139), IntSlider(value=70, description='Y …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get additive term (without scatter term):\n",
    "lm_sensitivity = system_matrix._compute_sensitivity_projection(all_ids=False)\n",
    "additive_term = lm_delays / lm_sensitivity\n",
    "additive_term[additive_term.isnan()] = 0 # remove NaN values\n",
    "\n",
    "# Recon\n",
    "likelihood = PoissonLogLikelihood(\n",
    "        system_matrix,\n",
    "        projections=projections,\n",
    "        additive_term = additive_term\n",
    "    )\n",
    "\n",
    "recon_algorithm = OSEM(likelihood, object_initial=back_projected)\n",
    "recon_without_scatter_estimation = recon_algorithm(4,14)\n",
    "\n",
    "plot_cross_sections_interactive(recon_without_scatter_estimation.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01688d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0966645e-06\n",
      "2.0966645e-06\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(back_projected.cpu().numpy().mean())\n",
    "print(recon_without_scatter_estimation.cpu().numpy().mean())\n",
    "diff = back_projected.cpu().numpy() - recon_without_scatter_estimation.cpu().numpy()\n",
    "print(diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33729be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sinogram_scatter = sss.get_sss_scatter_estimate(\n",
    "#     object_meta = object_meta,\n",
    "#     proj_meta = proj_meta,\n",
    "#     pet_image = recon_without_scatter_estimation,\n",
    "#     attenuation_image = atten_map,\n",
    "#     system_matrix = system_matrix,\n",
    "#     # proj_data = None, # assumes listmode\n",
    "#     image_stepsize = 4,\n",
    "#     attenuation_cutoff = 0.004,\n",
    "#     sinogram_interring_stepsize = 4,\n",
    "#     sinogram_intraring_stepsize = 4,\n",
    "#     sinogram_random = sinogram_delays\n",
    "#     )\n",
    "\n",
    "# # Now convert to listmode and make additive term\n",
    "# lm_scatter = shared.sinogram_to_listmode(proj_meta.detector_ids, sinogram_scatter, proj_meta.info)\n",
    "# additive_term = (lm_scatter + lm_delays) / lm_sensitivity\n",
    "# additive_term[additive_term.isnan()] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4ddc0c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = PoissonLogLikelihood(\n",
    "        system_matrix,\n",
    "        additive_term = additive_term\n",
    "    )\n",
    "recon_algorithm = OSEM(likelihood)\n",
    "recon_lm_nontof = recon_algorithm(4,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38853537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff3b13c5bb74539868527f1941009f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=70, description='X index', max=139), IntSlider(value=70, description='Y …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_cross_sections_interactive(recon_lm_nontof.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1f6b905a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxel value range: 1.401298464324817e-45 to 1.829294354882549e-11\n",
      "Total non-zero voxels: 47665\n",
      "Initial thresholds: 1.401298464324817e-45 to 1.829294354882549e-11\n",
      "Slider range: 1.401298464324817e-45 to 1.829294354882549e-11\n",
      "Voxel resolution: 4.0mm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b43f020eb7354cb3aae5f5aa10c4c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.401298464324817e-45, continuous_update=False, description='Min Thres…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize_voxel_tensor_3d(recon_without_scatter_estimation.cpu().numpy(), voxel_size_mm=voxel_size)\n",
    "visualize_voxel_tensor_3d(recon_lm_nontof.cpu().numpy(), voxel_size_mm=voxel_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytomography_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
