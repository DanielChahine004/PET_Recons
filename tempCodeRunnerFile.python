import torch
import torch.nn as nn
import math
import time

###############################################################################
# Global Attention Module & Residual Block (Unchanged from previous version)
###############################################################################
class GlobalAttention3D(nn.Module):
    def __init__(self, in_channels=64, embed_dim=128, output_dim=64, num_heads=8, dropout_rate=0.1):
        super(GlobalAttention3D, self).__init__()
        self.in_channels, self.embed_dim, self.num_heads, self.output_dim = in_channels, embed_dim, num_heads, output_dim
        self.head_dim = embed_dim // num_heads
        assert self.head_dim * num_heads == self.embed_dim, "embed_dim must be divisible by num_heads"
        self.channel_proj, self.q_proj, self.k_proj, self.v_proj = nn.Linear(in_channels, embed_dim), nn.Linear(embed_dim, embed_dim, bias=False), nn.Linear(embed_dim, embed_dim, bias=False), nn.Linear(embed_dim, embed_dim, bias=False)
        self.out_proj, self.output_proj = nn.Linear(embed_dim, embed_dim), nn.Linear(embed_dim, output_dim)
        self.norm, self.attn_dropout, self.scale = nn.LayerNorm(embed_dim), nn.Dropout(dropout_rate), self.head_dim ** -0.5

    def _generate_sinusoidal_pe(self, D, H, W, device):
        pe_embed_dim = self.embed_dim
        if pe_embed_dim % 6 != 0: pe_embed_dim = (pe_embed_dim // 6 + 1) * 6
        dim_t = pe_embed_dim // 3
        pe_d, pe_h, pe_w = torch.zeros(D, dim_t, device=device), torch.zeros(H, dim_t, device=device), torch.zeros(W, dim_t, device=device)
        pos_d, pos_h, pos_w = torch.arange(0, D, dtype=torch.float, device=device).unsqueeze(1), torch.arange(0, H, dtype=torch.float, device=device).unsqueeze(1), torch.arange(0, W, dtype=torch.float, device=device).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, dim_t, 2, dtype=torch.float, device=device) * -(math.log(10000.0) / dim_t))
        pe_d[:, 0::2], pe_d[:, 1::2] = torch.sin(pos_d * div_term), torch.cos(pos_d * div_term)
        pe_h[:, 0::2], pe_h[:, 1::2] = torch.sin(pos_h * div_term), torch.cos(pos_h * div_term)
        pe_w[:, 0::2], pe_w[:, 1::2] = torch.sin(pos_w * div_term), torch.cos(pos_w * div_term)
        pe_d, pe_h, pe_w = pe_d.unsqueeze(1).unsqueeze(2).expand(-1, H, W, -1), pe_h.unsqueeze(0).unsqueeze(2).expand(D, -1, W, -1), pe_w.unsqueeze(0).unsqueeze(1).expand(D, H, -1, -1)
        pe = torch.cat([pe_d, pe_h, pe_w], dim=-1)
        if pe.shape[-1] != self.embed_dim: pe = pe[:, :, :, :self.embed_dim]
        return pe.view(1, D * H * W, self.embed_dim)

    def forward(self, x):
        batch_size, _, D, H, W = x.shape
        seq_len = D * H * W
        x_flat = x.permute(0, 2, 3, 4, 1).contiguous().view(batch_size, seq_len, self.in_channels)
        x_flat = self.channel_proj(x_flat) + self._generate_sinusoidal_pe(D, H, W, x.device)
        residual, x_norm = x_flat, self.norm(x_flat)
        q, k, v = self.q_proj(x_norm).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2), self.k_proj(x_norm).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2), self.v_proj(x_norm).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        attn_weights = self.attn_dropout(torch.softmax(torch.matmul(q, k.transpose(-2, -1)) * self.scale, dim=-1))
        attn_output = self.out_proj(torch.matmul(attn_weights, v).transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim))
        x_flat = residual + attn_output
        output = self.output_proj(x_flat)
        return output.permute(0, 2, 1).view(batch_size, self.output_dim, D, H, W)

class ResidualBlock3D(nn.Module):
    def __init__(self, in_channels, out_channels, stride=(1, 2, 2)):
        super(ResidualBlock3D, self).__init__()
        self.conv1, self.bn1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, stride=stride, padding=0, bias=False), nn.BatchNorm3d(out_channels)
        self.conv2, self.bn2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=False), nn.BatchNorm3d(out_channels)
        self.conv_post, self.bn_post = nn.Conv3d(out_channels, out_channels, kernel_size=3, stride=1, padding=0, bias=False), nn.BatchNorm3d(out_channels)
        self.activation = nn.GELU()
        self.shortcut = nn.Sequential()
        if stride != (1, 1, 1) or in_channels != out_channels:
            self.shortcut = nn.Sequential(nn.Conv3d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False), nn.BatchNorm3d(out_channels))

    def _apply_circular_padding(self, x):
        x = torch.nn.functional.pad(x, (1, 1, 0, 0, 0, 0), mode='circular')
        x = torch.nn.functional.pad(x, (0, 0, 1, 1, 1, 1), mode='constant', value=0)
        return x

    def forward(self, x):
        identity = self.shortcut(x)
        out = self.activation(self.bn1(self.conv1(self._apply_circular_padding(x))))
        out = self.bn2(self.conv2(self._apply_circular_padding(out)))
        out += identity
        out = self.activation(self.bn_post(self.conv_post(self._apply_circular_padding(out))))
        return out


###############################################################################
# PetNetImproved3D with Concatenated GAP and GMP
###############################################################################
class PetNetImproved3D(nn.Module):
    def __init__(self, num_classes=6):
        print("Loading PetnetImproved3D Model with Concatenated GAP+GMP...")
        super(PetNetImproved3D, self).__init__()

        self.conv_in = nn.Conv3d(2, 16, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn_in = nn.BatchNorm3d(16)
        self.activation = nn.GELU()

        self.layer1 = ResidualBlock3D(16, 32, stride=(1, 2, 1))
        self.layer2 = ResidualBlock3D(32, 64, stride=(1, 1, 2))
        self.layer3 = ResidualBlock3D(64, 128, stride=(1, 2, 2))
        self.layer4 = ResidualBlock3D(128, 256, stride=(1, 2, 2))
        self.global_attention = GlobalAttention3D(in_channels=256, embed_dim=256, output_dim=256, num_heads=8)
        self.layer5 = ResidualBlock3D(256, 512, stride=(1, 2, 2))

        self.dropout = nn.Dropout(0.3)
        
        # This will now dynamically compute the doubled feature size
        fc_in_features = self._compute_fc_input_size()
        
        self.fc1 = nn.Linear(fc_in_features, 512, bias=True)
        self.fc2 = nn.Linear(512, num_classes, bias=True)

        self._initialize_weights()

    def _compute_fc_input_size(self, C=2, T=3, H=207, W=41):
        with torch.no_grad():
            dummy = torch.zeros(1, C, T, H, W)
            out = self.conv_in(dummy)
            out = self.bn_in(out)
            out = self.activation(out)
            out = self.layer1(out)
            out = self.layer2(out)
            out = self.layer3(out)
            out = self.layer4(out)
            out = self.global_attention(out)
            out = self.layer5(out)
            
            # --- MODIFIED PART ---
            # Apply both pooling operations and concatenate
            avg_pool = torch.mean(out, dim=(2, 3, 4))
            max_pool = torch.amax(out, dim=(2, 3, 4))
            out = torch.cat([avg_pool, max_pool], dim=1)
            # ---------------------
            
            return out.shape[1]

    def forward(self, x, debug=False):
        if debug: print(f"{x.shape} Input shape")
        x = self.activation(self.bn_in(self.conv_in(x)))
        if debug: print(f"{x.shape} After conv_in")

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)
        if debug: print(f"{x.shape} Before global attention")
        
        x = self.global_attention(x)
        if debug: print(f"{x.shape} After global attention")
        
        x = self.layer5(x)
        if debug: print(f"{x.shape} After layer 5")

        # --- MODIFIED PART ---
        # Apply both pooling operations and concatenate
        avg_pool = torch.mean(x, dim=(2, 3, 4))
        max_pool = torch.amax(x, dim=(2, 3, 4))
        x = torch.cat([avg_pool, max_pool], dim=1)
        # ---------------------
        if debug: print(f"{x.shape} After GAP+GMP concatenation")

        x = self.fc1(x)
        x = self.activation(x)
        x = self.dropout(x)
        x = self.fc2(x)
        if debug: print(f"{x.shape} After fc layer 2 (output)")

        return x

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, (nn.Conv3d, nn.Linear)):
                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')
                if m.bias is not None: nn.init.constant_(m.bias, 0)


if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")

    B, C, T, H, W = 8, 2, 3, 207, 41
    CLASSES = 6

    model = PetNetImproved3D(num_classes=CLASSES).to(device)
    param_count = sum(p.numel() for p in model.parameters())
    print(f"Total parameters: {param_count:,}")
    
    dummy_input = torch.randn(B, C, T, H, W).to(device)
    dummy_target = torch.randn(B, CLASSES).to(device)
    print("\n--- Running a test forward pass with debug prints ---")
    model.forward(dummy_input, debug=True)

    print("\n--- Running the original dummy training loop ---")
    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
    criterion = nn.MSELoss()

    total_time = 0.0
    epochs = 500

    for epoch in range(epochs):
        optimizer.zero_grad()
        start_time = time.time()
        
        model.train()
        output = model(dummy_input)
        
        end_time = time.time()
        forward_time = end_time - start_time
        total_time += forward_time

        loss = criterion(output, dummy_target)
        loss.backward()
        optimizer.step()
        
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}, Forward Time: {forward_time:.6f}s")

    average_time = total_time / epochs
    print(f"\nAverage Forward Pass Time: {average_time:.6f}s")